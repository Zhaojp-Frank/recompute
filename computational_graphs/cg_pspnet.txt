727 770
0 8294400 _
1 33177600 _
2 262144 /model/extractor/res3/b2/conv3/conv/W
3 68 /aux_conv2/b
4 8294400 _
5 2048 /model/extractor/res3/b2/conv3/bn/gamma
6 4147200 _
7 2048 /model/extractor/res3/b2/conv3/bn/beta
8 33177600 _
9 16588800 _
10 6100428 0
11 8294400 _
12 33177600 _
13 4147200 _
14 33177600 _
15 2033476 1
16 8294400 _
17 8294400 _
18 8294400 _
19 262144 /model/extractor/res3/b3/conv1/conv/W
20 4096 /model/extractor/res4/b12/conv3/bn/beta
21 16588800 _
22 16588800 _
23 32626944 _
24 512 /model/extractor/res3/b3/conv1/bn/gamma
25 8294400 _
26 512 /model/extractor/res3/b3/conv1/bn/beta
27 8294400 _
28 4147200 _
29 33177600 _
30 8294400 _
31 8294400 _
32 8294400 _
33 16588800 _
34 589824 /model/extractor/res3/b3/conv2/conv/W
35 16588800 _
36 32626944 _
37 16588800 _
38 512 /model/extractor/res3/b3/conv2/bn/gamma
39 32626944 _
40 33177600 _
41 8294400 _
42 32626944 _
43 33177600 _
44 8294400 _
45 512 /model/extractor/res3/b3/conv2/bn/beta
46 33177600 _
47 8294400 _
48 33177600 _
49 8294400 _
50 4147200 _
51 33177600 _
52 262144 /model/extractor/res3/b3/conv3/conv/W
53 32626944 _
54 4147200 _
55 4147200 _
56 16404992 _
57 65253888 _
58 33177600 _
59 2048 /model/extractor/res3/b3/conv3/bn/gamma
60 32626944 _
61 8294400 _
62 33177600 _
63 4194304 /model/extractor/res5/a/conv3/conv/W
64 8294400 _
65 33177600 _
66 16588800 _
67 2359296 /model/extractor/res4/b15/conv2/conv/W
68 8294400 _
69 4096 /model/extractor/res4/b6/conv3/bn/beta
70 8294400 _
71 8294400 _
72 8294400 _
73 8192 /model/extractor/res5/a/conv3/bn/gamma
74 550800 _
75 1048576 /model/extractor/res4/b19/conv1/conv/W
76 8294400 _
77 16588800 _
78 8294400 _
79 8192 /model/extractor/res5/a/conv3/bn/beta
80 1024 /model/extractor/res4/b15/conv2/bn/gamma
81 1048576 /model/extractor/res4/b7/conv1/conv/W
82 16588800 _
83 33177600 _
84 1024 /model/extractor/res4/b15/conv2/bn/beta
85 294912 _
86 16588800 _
87 1024 /model/extractor/res4/b19/conv1/bn/gamma
88 33177600 _
89 8294400 _
90 8294400 _
91 8388608 /model/extractor/res5/a/residual_conv/conv/W
92 33177600 _
93 1024 /model/extractor/res4/b19/conv1/bn/beta
94 1024 /model/extractor/res4/b7/conv1/bn/gamma
95 34569092 _
96 8294400 _
97 33177600 _
98 8294400 _
99 1048576 /model/extractor/res4/b15/conv3/conv/W
100 8294400 _
101 8294400 _
102 1024 /model/extractor/res4/b7/conv1/bn/beta
103 8294400 _
104 8192 /model/extractor/res5/a/residual_conv/bn/gamma
105 33177600 _
106 2359296 /model/extractor/res4/b19/conv2/conv/W
107 8294400 _
108 16588800 _
109 8192 /model/extractor/res5/a/residual_conv/bn/beta
110 4096 /model/extractor/res4/b15/conv3/bn/gamma
111 33177600 _
112 73728 _
113 2359296 /model/extractor/res4/b7/conv2/conv/W
114 66355200 _
115 16588800 _
116 4096 /model/extractor/res4/b15/conv3/bn/beta
117 1024 /model/extractor/res4/b19/conv2/bn/gamma
118 8294400 _
119 33177600 _
120 33177600 _
121 8294400 _
122 33177600 _
123 33177600 _
124 1024 /model/extractor/res4/b19/conv2/bn/beta
125 1024 /model/extractor/res4/b7/conv2/bn/gamma
126 8294400 _
127 8294400 _
128 33177600 _
129 4194304 /model/extractor/res5/b1/conv1/conv/W
130 8294400 _
131 8294400 _
132 16588800 _
133 33177600 _
134 73728 _
135 1024 /model/extractor/res4/b7/conv2/bn/beta
136 66355200 _
137 1048576 /model/extractor/res4/b16/conv1/conv/W
138 66355200 _
139 8294400 _
140 1048576 /model/extractor/res4/b19/conv3/conv/W
141 66355200 _
142 73728 _
143 2048 /model/extractor/res5/b1/conv1/bn/gamma
144 73728 _
145 147456 /model/extractor/res2/a/conv2/conv/W
146 16588800 _
147 8294400 _
148 16588800 _
149 2048 /model/extractor/res5/b1/conv1/bn/beta
150 1024 /model/extractor/res4/b16/conv1/bn/gamma
151 8294400 _
152 4096 /model/extractor/res4/b19/conv3/bn/gamma
153 8294400 _
154 33177600 _
155 33177600 _
156 16588800 _
157 1024 /model/extractor/res4/b16/conv1/bn/beta
158 33177600 _
159 4096 /model/extractor/res4/b19/conv3/bn/beta
160 8294400 _
161 8294400 _
162 9437184 /model/extractor/res5/b1/conv2/conv/W
163 16588800 _
164 8294400 _
165 33177600 _
166 4096 /model/extractor/res4/b7/conv3/bn/beta
167 18432 _
168 2359296 /model/extractor/res4/b16/conv2/conv/W
169 16588800 _
170 2048 /model/extractor/res5/b1/conv2/bn/gamma
171 1048576 /model/extractor/res4/b20/conv1/conv/W
172 33177600 _
173 33177600 _
174 2048 /model/extractor/res5/b1/conv2/bn/beta
175 33177600 _
176 1024 /model/extractor/res4/b16/conv2/bn/gamma
177 8294400 _
178 8294400 _
179 1024 /model/extractor/res4/b10/conv2/bn/gamma
180 18432 _
181 256 /model/extractor/res2/b1/conv1/bn/gamma
182 1024 /model/extractor/res4/b10/conv2/bn/beta
183 8294400 _
184 16588800 _
185 8294400 _
186 18432 _
187 1048576 /model/extractor/res4/b2/conv1/conv/W
188 16588800 _
189 256 /model/extractor/res2/b1/conv1/bn/beta
190 16588800 _
191 32768 /model/extractor/res2/a/conv1/conv/W
192 4147200 _
193 32768 _
194 1048576 /model/extractor/res4/b10/conv3/conv/W
195 1024 /model/extractor/res4/b2/conv1/bn/gamma
196 147456 /model/extractor/res2/b1/conv2/conv/W
197 1024 /model/extractor/res4/b2/conv1/bn/beta
198 8294400 _
199 256 /model/extractor/res2/a/conv1/bn/gamma
200 4096 /model/extractor/res4/b10/conv3/bn/gamma
201 256 /model/extractor/res2/a/conv1/bn/beta
202 8192 _
203 33177600 _
204 256 /model/extractor/res2/b1/conv2/bn/gamma
205 4096 /model/extractor/res4/b10/conv3/bn/beta
206 8294400 _
207 4147200 _
208 2359296 /model/extractor/res4/b2/conv2/conv/W
209 256 /model/extractor/res2/b1/conv2/bn/beta
210 65536 /model/extractor/res2/a/conv3/conv/W
211 4147200 _
212 4147200 _
213 8192 _
214 1024 /model/extractor/res4/b2/conv2/bn/gamma
215 1048576 /model/extractor/res4/b11/conv1/conv/W
216 33177600 _
217 65536 /model/extractor/res2/b1/conv3/conv/W
218 1024 /model/extractor/res2/a/conv3/bn/gamma
219 33177600 _
220 8192 _
221 1024 /model/extractor/res4/b2/conv2/bn/beta
222 8192 _
223 33177600 _
224 1024 /model/extractor/res2/a/conv3/bn/beta
225 1024 /model/extractor/res4/b11/conv1/bn/gamma
226 8294400 _
227 1024 /model/extractor/res2/b1/conv3/bn/gamma
228 4147200 _
229 16588800 _
230 1024 /model/extractor/res4/b11/conv1/bn/beta
231 1048576 /model/extractor/res4/b2/conv3/conv/W
232 1024 /model/extractor/res2/b1/conv3/bn/beta
233 131072 /model/extractor/res2/a/residual_conv/conv/W
234 16588800 _
235 4147200 _
236 4096 /model/extractor/res4/b2/conv3/bn/gamma
237 2048 _
238 2359296 /model/extractor/res4/b11/conv2/conv/W
239 8294400 _
240 1024 /model/extractor/res2/a/residual_conv/bn/gamma
241 8294400 _
242 4096 /model/extractor/res4/b2/conv3/bn/beta
243 65536 /model/extractor/res2/b2/conv1/conv/W
244 1024 /model/extractor/res2/a/residual_conv/bn/beta
245 8294400 _
246 16588800 _
247 1024 /model/extractor/res4/b11/conv2/bn/gamma
248 8294400 _
249 16588800 _
250 2048 _
251 16588800 _
252 256 /model/extractor/res2/b2/conv1/bn/gamma
253 1024 /model/extractor/res4/b11/conv2/bn/beta
254 1048576 /model/extractor/res4/b3/conv1/conv/W
255 2048 _
256 256 /model/extractor/res2/b2/conv1/bn/beta
257 16588800 _
258 65536 /model/extractor/res2/b1/conv1/conv/W
259 33177600 _
260 132710400 _
261 1048576 /model/extractor/res4/b11/conv3/conv/W
262 33177600 _
263 2048 /model/ppm/3/bn/gamma
264 1024 /model/extractor/res4/b22/conv2/bn/beta
265 1048576 /model/extractor/res4/b5/conv3/conv/W
266 2048 /model/ppm/3/bn/beta
267 65253888 _
268 1048576 /model/extractor/res4/b22/conv3/conv/W
269 4096 /model/extractor/res4/b5/conv3/bn/gamma
270 65253888 _
271 4096 /model/extractor/res4/b5/conv3/bn/beta
272 8294400 _
273 4096 /model/extractor/res4/b22/conv3/bn/gamma
274 75497472 /model/head_conv1/conv/W
275 4096 /model/extractor/res4/b22/conv3/bn/beta
276 8294400 _
277 8294400 _
278 8202496 _
279 1048576 /model/extractor/res4/b6/conv1/conv/W
280 2048 /model/head_conv1/bn/gamma
281 2048 /model/head_conv1/bn/beta
282 1024 /model/extractor/res4/b6/conv1/bn/gamma
283 2097152 /model/extractor/res5/a/conv1/conv/W
284 34816 /model/head_conv2/W
285 8294400 _
286 8202496 _
287 1024 /model/extractor/res4/b6/conv1/bn/beta
288 33177600 _
289 68 /model/head_conv2/b
290 2048 /model/extractor/res5/a/conv1/bn/gamma
291 8294400 _
292 8202496 _
293 8202496 _
294 2048 /model/extractor/res5/a/conv1/bn/beta
295 2359296 /model/extractor/res4/b6/conv2/conv/W
296 8202496 _
297 33177600 _
298 1024 /model/extractor/res4/b6/conv2/bn/gamma
299 9437184 /model/extractor/res5/a/conv2/conv/W
300 33177600 _
301 18874368 /aux_conv1/conv/W
302 33177600 _
303 8202496 _
304 1024 /model/extractor/res4/b6/conv2/bn/beta
305 8294400 _
306 32809984 _
307 2048 /model/extractor/res5/a/conv2/bn/gamma
308 8202496 _
309 2048 /aux_conv1/bn/gamma
310 2048 /model/extractor/res5/a/conv2/bn/beta
311 1048576 /model/extractor/res4/b6/conv3/conv/W
312 2048 /aux_conv1/bn/beta
313 32809984 _
314 313344 /aux_conv2/W
315 4096 /model/extractor/res4/b6/conv3/bn/gamma
316 8294400 _
317 8294400 _
318 8294400 _
319 16588800 _
320 6912 /model/extractor/conv1_1/conv/W
321 8294400 _
322 1024 /model/extractor/res4/b14/conv1/bn/gamma
323 512 /model/extractor/res3/b1/conv2/bn/gamma
324 8294400 _
325 8294400 _
326 8294400 _
327 4147200 _
328 1024 /model/extractor/res4/b14/conv1/bn/beta
329 512 /model/extractor/res3/b1/conv2/bn/beta
330 66355200 _
331 16588800 _
332 16588800 _
333 4147200 _
334 66355200 _
335 66355200 _
336 33177600 _
337 2359296 /model/extractor/res4/b14/conv2/conv/W
338 33177600 _
339 33177600 _
340 33177600 _
341 8294400 _
342 262144 /model/extractor/res3/b1/conv3/conv/W
343 33177600 _
344 33177600 _
345 33177600 _
346 8294400 _
347 16588800 _
348 8294400 _
349 1024 /model/extractor/res4/b14/conv2/bn/gamma
350 16588800 _
351 2048 /model/extractor/res3/b1/conv3/bn/gamma
352 16588800 _
353 1024 /model/extractor/res4/b14/conv2/bn/beta
354 2048 /model/extractor/res3/b1/conv3/bn/beta
355 16588800 _
356 4147200 _
357 16588800 _
358 16588800 _
359 33177600 _
360 16588800 _
361 33177600 _
362 1048576 /model/extractor/res4/b14/conv3/conv/W
363 8294400 _
364 33177600 _
365 16588800 _
366 262144 /model/extractor/res3/b2/conv1/conv/W
367 16588800 _
368 8294400 _
369 8294400 _
370 8294400 _
371 4096 /model/extractor/res4/b14/conv3/bn/gamma
372 4147200 _
373 512 /model/extractor/res3/b2/conv1/bn/gamma
374 4096 /model/extractor/res4/b14/conv3/bn/beta
375 16588800 _
376 4147200 _
377 4147200 _
378 512 /model/extractor/res3/b2/conv1/bn/beta
379 66355200 _
380 16588800 _
381 16588800 _
382 8294400 _
383 8294400 _
384 8294400 _
385 66355200 _
386 589824 /model/extractor/res3/b2/conv2/conv/W
387 16588800 _
388 1048576 /model/extractor/res4/b15/conv1/conv/W
389 8294400 _
390 33177600 _
391 8294400 _
392 8294400 _
393 256 /model/extractor/res2/a/conv2/bn/beta
394 4147200 _
395 66355200 _
396 66355200 _
397 1024 /model/extractor/res4/b15/conv1/bn/gamma
398 512 /model/extractor/res3/b2/conv2/bn/gamma
399 16588800 _
400 66355200 _
401 4147200 _
402 66355200 _
403 512 /model/extractor/res3/b2/conv2/bn/beta
404 1024 /model/extractor/res4/b15/conv1/bn/beta
405 16588800 _
406 66355200 _
407 33177600 _
408 33177600 _
409 33177600 _
410 8294400 _
411 8192 /model/extractor/res5/b2/conv3/bn/gamma
412 33177600 _
413 8294400 _
414 4096 /model/extractor/res4/a/residual_conv/bn/gamma
415 8192 /model/extractor/res5/b2/conv3/bn/beta
416 8294400 _
417 8294400 _
418 4096 /model/extractor/res4/b17/conv3/bn/gamma
419 2359296 /model/extractor/res4/b9/conv2/conv/W
420 1024 /model/extractor/res4/b4/conv2/bn/gamma
421 4096 /model/extractor/res4/a/residual_conv/bn/beta
422 1048576 /model/extractor/res4/b13/conv1/conv/W
423 4096 /model/extractor/res4/b17/conv3/bn/beta
424 1024 /model/extractor/res4/b4/conv2/bn/beta
425 4194304 /model/ppm/0/conv/W
426 2359296 /model/extractor/res4/b4/conv2/conv/W
427 1024 /model/extractor/res4/b9/conv2/bn/gamma
428 33177600 _
429 1024 /model/extractor/res4/b13/conv1/bn/gamma
430 8294400 _
431 1024 /model/extractor/res4/b9/conv2/bn/beta
432 2048 /model/ppm/0/bn/gamma
433 8294400 _
434 1048576 /model/extractor/res4/b4/conv3/conv/W
435 33177600 _
436 33177600 _
437 1048576 /model/extractor/res4/b1/conv1/conv/W
438 1024 /model/extractor/res4/b13/conv1/bn/beta
439 1048576 /model/extractor/res4/b18/conv1/conv/W
440 2048 /model/ppm/0/bn/beta
441 33177600 _
442 8294400 _
443 8294400 _
444 8294400 _
445 8294400 _
446 1048576 /model/extractor/res4/b9/conv3/conv/W
447 4096 /model/extractor/res4/b4/conv3/bn/gamma
448 1024 /model/extractor/res4/b1/conv1/bn/gamma
449 1024 /model/extractor/res4/b18/conv1/bn/gamma
450 2359296 /model/extractor/res4/b13/conv2/conv/W
451 4194304 /model/ppm/1/conv/W
452 4096 /model/extractor/res4/b4/conv3/bn/beta
453 1024 /model/extractor/res4/b1/conv1/bn/beta
454 1024 /model/extractor/res4/b18/conv1/bn/beta
455 4096 /model/extractor/res4/b9/conv3/bn/gamma
456 33177600 _
457 33177600 _
458 1024 /model/extractor/res4/b13/conv2/bn/gamma
459 2048 /model/ppm/1/bn/gamma
460 8294400 _
461 4096 /model/extractor/res4/b9/conv3/bn/beta
462 8294400 _
463 33177600 _
464 2359296 /model/extractor/res4/b1/conv2/conv/W
465 1024 /model/extractor/res4/b13/conv2/bn/beta
466 1048576 /model/extractor/res4/b5/conv1/conv/W
467 2359296 /model/extractor/res4/b18/conv2/conv/W
468 2048 /model/ppm/1/bn/beta
469 8294400 _
470 33177600 _
471 8294400 _
472 8294400 _
473 8294400 _
474 1024 /model/extractor/res4/b1/conv2/bn/gamma
475 1048576 /model/extractor/res4/b10/conv1/conv/W
476 1024 /model/extractor/res4/b5/conv1/bn/gamma
477 1024 /model/extractor/res4/b18/conv2/bn/gamma
478 1048576 /model/extractor/res4/b13/conv3/conv/W
479 4194304 /model/ppm/2/conv/W
480 1024 /model/extractor/res4/b1/conv2/bn/beta
481 1024 /model/extractor/res4/b5/conv1/bn/beta
482 1024 /model/extractor/res4/b18/conv2/bn/beta
483 33177600 _
484 8294400 _
485 8294400 _
486 33177600 _
487 1024 /model/extractor/res4/b10/conv1/bn/gamma
488 4096 /model/extractor/res4/b13/conv3/bn/gamma
489 8294400 _
490 2048 /model/ppm/2/bn/gamma
491 33177600 _
492 1024 /model/extractor/res4/b10/conv1/bn/beta
493 1048576 /model/extractor/res4/b1/conv3/conv/W
494 8294400 _
495 8294400 _
496 4096 /model/extractor/res4/b13/conv3/bn/beta
497 2359296 /model/extractor/res4/b5/conv2/conv/W
498 2048 /model/ppm/2/bn/beta
499 8294400 _
500 1048576 /model/extractor/res4/b18/conv3/conv/W
501 33177600 _
502 8294400 _
503 1024 /model/extractor/res4/b9/conv1/bn/beta
504 4096 /model/extractor/res4/b1/conv3/bn/gamma
505 2359296 /model/extractor/res4/b10/conv2/conv/W
506 1024 /model/extractor/res4/b5/conv2/bn/gamma
507 4096 /model/extractor/res4/b18/conv3/bn/gamma
508 4194304 /model/ppm/3/conv/W
509 4096 /model/extractor/res4/b1/conv3/bn/beta
510 1048576 /model/extractor/res4/b14/conv1/conv/W
511 4096 /model/extractor/res4/b18/conv3/bn/beta
512 33177600 _
513 1024 /model/extractor/res4/b5/conv2/bn/beta
514 8294400 _
515 33177600 _
516 33177600 _
517 33177600 _
518 512 /model/extractor/res3/a/conv2/bn/beta
519 147456 /model/extractor/res2/b2/conv2/conv/W
520 2359296 /model/extractor/res4/b21/conv2/conv/W
521 1024 /model/extractor/res4/b20/conv1/bn/gamma
522 8294400 _
523 8294400 _
524 4194304 /model/extractor/res5/b1/conv3/conv/W
525 1024 /model/extractor/res4/b20/conv1/bn/beta
526 262144 /model/extractor/res3/a/conv3/conv/W
527 256 /model/extractor/res2/b2/conv2/bn/gamma
528 256 /model/extractor/res2/a/conv2/bn/gamma
529 1024 /model/extractor/res4/b21/conv2/bn/gamma
530 256 /model/extractor/res2/b2/conv2/bn/beta
531 8202496 _
532 8192 /model/extractor/res5/b1/conv3/bn/gamma
533 1024 /model/extractor/res4/b21/conv2/bn/beta
534 2359296 /model/extractor/res4/b20/conv2/conv/W
535 2048 /model/extractor/res3/a/conv3/bn/gamma
536 8294400 _
537 8192 /model/extractor/res5/b1/conv3/bn/beta
538 8294400 _
539 8202496 _
540 8202496 _
541 2048 /model/extractor/res3/a/conv3/bn/beta
542 65536 /model/extractor/res2/b2/conv3/conv/W
543 33177600 _
544 8294400 _
545 1048576 /model/extractor/res4/b21/conv3/conv/W
546 1024 /model/extractor/res4/b20/conv2/bn/gamma
547 8294400 _
548 8294400 _
549 1048576 /model/extractor/res4/b7/conv3/conv/W
550 1024 /model/extractor/res4/b20/conv2/bn/beta
551 4194304 /model/extractor/res5/b2/conv1/conv/W
552 524288 /model/extractor/res3/a/residual_conv/conv/W
553 1024 /model/extractor/res2/b2/conv3/bn/gamma
554 256 /model/extractor/conv1_1/bn/gamma
555 4096 /model/extractor/res4/b21/conv3/bn/gamma
556 1024 /model/extractor/res2/b2/conv3/bn/beta
557 8202496 _
558 256 /model/extractor/conv1_1/bn/beta
559 33177600 _
560 4096 /model/extractor/res4/b21/conv3/bn/beta
561 2048 /model/extractor/res5/b2/conv1/bn/gamma
562 1048576 /model/extractor/res4/b20/conv3/conv/W
563 33177600 _
564 8294400 _
565 2048 /model/extractor/res3/a/residual_conv/bn/gamma
566 32809984 _
567 33177600 _
568 8202496 _
569 2048 /model/extractor/res5/b2/conv1/bn/beta
570 2048 /model/extractor/res3/a/residual_conv/bn/beta
571 147456 /model/extractor/conv1_2/conv/W
572 8294400 _
573 33177600 _
574 8294400 _
575 4096 /model/extractor/res4/b20/conv3/bn/gamma
576 16404992 _
577 131072 /model/extractor/res3/a/conv1/conv/W
578 1048576 /model/extractor/res4/b22/conv1/conv/W
579 256 /model/extractor/conv1_2/bn/gamma
580 4096 /model/extractor/res4/b20/conv3/bn/beta
581 9437184 /model/extractor/res5/b2/conv2/conv/W
582 32809984 _
583 32809984 _
584 256 /model/extractor/conv1_2/bn/beta
585 262144 /model/extractor/res3/b1/conv1/conv/W
586 512 /model/extractor/res3/a/conv1/bn/gamma
587 33177600 _
588 32809984 _
589 1024 /model/extractor/res4/b22/conv1/bn/gamma
590 8294400 _
591 33177600 _
592 2048 /model/extractor/res5/b2/conv2/bn/gamma
593 512 /model/extractor/res3/a/conv1/bn/beta
594 33177600 _
595 1024 /model/extractor/res4/b22/conv1/bn/beta
596 294912 /model/extractor/conv1_3/conv/W
597 1048576 /model/extractor/res4/b21/conv1/conv/W
598 2048 /model/extractor/res5/b2/conv2/bn/beta
599 8294400 _
600 8294400 _
601 512 /model/extractor/res3/b1/conv1/bn/gamma
602 8294400 _
603 4096 /model/extractor/res4/b7/conv3/bn/gamma
604 512 /model/extractor/res3/b1/conv1/bn/beta
605 589824 /model/extractor/res3/a/conv2/conv/W
606 512 /model/extractor/conv1_3/bn/gamma
607 2359296 /model/extractor/res4/b22/conv2/conv/W
608 1024 /model/extractor/res4/b21/conv1/bn/gamma
609 16404992 _
610 4194304 /model/extractor/res5/b2/conv3/conv/W
611 512 /model/extractor/conv1_3/bn/beta
612 33177600 _
613 1024 /model/extractor/res4/b21/conv1/bn/beta
614 589824 /model/extractor/res3/b1/conv2/conv/W
615 33177600 _
616 512 /model/extractor/res3/a/conv2/bn/gamma
617 1024 /model/extractor/res4/b22/conv2/bn/gamma
618 8294400 _
619 33177600 _
620 4147200 _
621 16404992 _
622 8294400 _
623 1048576 /model/extractor/res4/b8/conv1/conv/W
624 1024 /model/extractor/res4/b3/conv1/bn/gamma
625 32809984 _
626 16588800 _
627 2048 /model/extractor/res3/b3/conv3/bn/beta
628 1024 /model/extractor/res4/b16/conv2/bn/beta
629 1024 /model/extractor/res4/b3/conv1/bn/beta
630 8294400 _
631 16588800 _
632 8294400 _
633 8294400 _
634 550800 _
635 4096 /model/extractor/res4/b11/conv3/bn/gamma
636 8202496 _
637 1024 /model/extractor/res4/b8/conv1/bn/gamma
638 16588800 _
639 33177600 _
640 4096 /model/extractor/res4/b11/conv3/bn/beta
641 1048576 /model/extractor/res4/b16/conv3/conv/W
642 1024 /model/extractor/res4/b8/conv1/bn/beta
643 2359296 /model/extractor/res4/b3/conv2/conv/W
644 524288 /model/extractor/res4/a/conv1/conv/W
645 32809984 _
646 4 _
647 33177600 _
648 33177600 _
649 32809984 _
650 4096 /model/extractor/res4/b16/conv3/bn/gamma
651 8294400 _
652 32809984 _
653 33177600 _
654 2359296 /model/extractor/res4/b8/conv2/conv/W
655 1024 /model/extractor/res4/b3/conv2/bn/gamma
656 1024 /model/extractor/res4/a/conv1/bn/gamma
657 1048576 /model/extractor/res4/b12/conv1/conv/W
658 4096 /model/extractor/res4/b16/conv3/bn/beta
659 8294400 _
660 33177600 _
661 1024 /model/extractor/res4/b3/conv2/bn/beta
662 8294400 _
663 1024 /model/extractor/res4/a/conv1/bn/beta
664 34569092 _
665 1024 /model/extractor/res4/b8/conv2/bn/gamma
666 1024 /model/extractor/res4/b12/conv1/bn/gamma
667 1024 /model/extractor/res4/b8/conv2/bn/beta
668 1048576 /model/extractor/res4/b3/conv3/conv/W
669 2359296 /model/extractor/res4/a/conv2/conv/W
670 1024 /model/extractor/res4/b12/conv1/bn/beta
671 8202496 _
672 1048576 /model/extractor/res4/b17/conv1/conv/W
673 33177600 _
674 8294400 _
675 33177600 _
676 4 _
677 8202496 _
678 33177600 _
679 1048576 /model/extractor/res4/b8/conv3/conv/W
680 4096 /model/extractor/res4/b3/conv3/bn/gamma
681 1024 /model/extractor/res4/a/conv2/bn/gamma
682 8202496 _
683 1024 /model/extractor/res4/b17/conv1/bn/gamma
684 8294400 _
685 2359296 /model/extractor/res4/b12/conv2/conv/W
686 8294400 _
687 8294400 _
688 4 _
689 4096 /model/extractor/res4/b3/conv3/bn/beta
690 1024 /model/extractor/res4/a/conv2/bn/beta
691 8294400 _
692 1024 /model/extractor/res4/b17/conv1/bn/beta
693 4096 /model/extractor/res4/b8/conv3/bn/gamma
694 1024 /model/extractor/res4/b12/conv2/bn/gamma
695 4096 /model/extractor/res4/b8/conv3/bn/beta
696 1048576 /model/extractor/res4/a/conv3/conv/W
697 8202496 _
698 4 _
699 8294400 _
700 1024 /model/extractor/res4/b12/conv2/bn/beta
701 2359296 /model/extractor/res4/b17/conv2/conv/W
702 1048576 /model/extractor/res4/b4/conv1/conv/W
703 8294400 _
704 8294400 _
705 32809984 _
706 8202496 _
707 4096 /model/extractor/res4/a/conv3/bn/gamma
708 33177600 _
709 8294400 _
710 1024 /model/extractor/res4/b17/conv2/bn/gamma
711 8294400 _
712 1048576 /model/extractor/res4/b12/conv3/conv/W
713 1048576 /model/extractor/res4/b9/conv1/conv/W
714 1024 /model/extractor/res4/b4/conv1/bn/gamma
715 8294400 _
716 4096 /model/extractor/res4/a/conv3/bn/beta
717 1024 /model/extractor/res4/b17/conv2/bn/beta
718 1024 /model/extractor/res4/b4/conv1/bn/beta
719 32809984 _
720 4096 /model/extractor/res4/b12/conv3/bn/gamma
721 1024 /model/extractor/res4/b9/conv1/bn/gamma
722 32809984 _
723 33177600 _
724 2097152 /model/extractor/res4/a/residual_conv/conv/W
725 32809984 _
726 1048576 /model/extractor/res4/b17/conv3/conv/W
forward
1 1
25 _
30
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 152, "lazy_grad_sum": false}
forward
2 1
46 _
597 _
47
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 290, "lazy_grad_sum": false}
forward
2 1
517 _
623 _
41
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 160, "lazy_grad_sum": false}
forward
3 1
21 _
565 _
570 _
33
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 41, "lazy_grad_sum": false}
forward
3 1
17 _
94 _
102 _
25
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 151, "lazy_grad_sum": false}
forward
3 1
9 _
535 _
541 _
22
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 47, "lazy_grad_sum": false}
forward
2 1
133 _
111 _
516
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 88, "lazy_grad_sum": false}
forward
2 1
588 _
552 _
21
Convolution2DFunction
{"sy": 2, "sx": 2, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 40, "lazy_grad_sum": false}
forward
1 1
27 _
31
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 285, "lazy_grad_sum": false}
forward
2 1
16 _
534 _
18
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 283, "lazy_grad_sum": false}
forward
1 1
8 _
14
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 149, "lazy_grad_sum": false}
forward
2 1
31 _
562 _
29
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 286, "lazy_grad_sum": false}
forward
3 1
18 _
546 _
550 _
27
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 284, "lazy_grad_sum": false}
forward
2 1
22 _
33 _
35
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 48, "lazy_grad_sum": false}
forward
1 1
35 _
37
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 49, "lazy_grad_sum": false}
forward
3 1
23 _
554 _
558 _
36
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 1, "lazy_grad_sum": false}
forward
2 1
463 _
578 _
469
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 300, "lazy_grad_sum": false}
forward
1 1
44 _
49
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 155, "lazy_grad_sum": false}
forward
2 1
30 _
113 _
32
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 153, "lazy_grad_sum": false}
forward
3 1
29 _
575 _
580 _
43
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 287, "lazy_grad_sum": false}
forward
2 1
49 _
549 _
48
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 156, "lazy_grad_sum": false}
forward
2 1
43 _
1 _
40
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 288, "lazy_grad_sum": false}
forward
3 1
32 _
125 _
135 _
44
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 154, "lazy_grad_sum": false}
forward
1 1
516 _
165
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 89, "lazy_grad_sum": false}
forward
2 1
352 _
366 _
356
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 60, "lazy_grad_sum": false}
forward
2 1
37 _
585 _
28
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 50, "lazy_grad_sum": false}
forward
1 1
53 _
60
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 5, "lazy_grad_sum": false}
forward
1 1
50 _
54
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 52, "lazy_grad_sum": false}
forward
1 1
61 _
413
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 292, "lazy_grad_sum": false}
forward
3 1
28 _
601 _
604 _
50
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 51, "lazy_grad_sum": false}
forward
3 1
47 _
608 _
613 _
61
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 291, "lazy_grad_sum": false}
forward
2 1
60 _
596 _
57
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 6, "lazy_grad_sum": false}
forward
3 1
42 _
579 _
584 _
53
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 4, "lazy_grad_sum": false}
forward
1 1
40 _
46
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 289, "lazy_grad_sum": false}
forward
3 1
48 _
603 _
166 _
62
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 157, "lazy_grad_sum": false}
forward
2 1
62 _
14 _
58
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 158, "lazy_grad_sum": false}
forward
1 1
327 _
333
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 55, "lazy_grad_sum": false}
forward
2 1
54 _
614 _
55
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 53, "lazy_grad_sum": false}
forward
1 1
267 _
270
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 8, "lazy_grad_sum": false}
forward
1 1
536 _
544
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 162, "lazy_grad_sum": false}
forward
2 1
333 _
342 _
332
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 56, "lazy_grad_sum": false}
forward
3 1
57 _
606 _
611 _
267
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 7, "lazy_grad_sum": false}
forward
3 1
55 _
323 _
329 _
327
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 54, "lazy_grad_sum": false}
forward
3 1
41 _
637 _
642 _
536
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 161, "lazy_grad_sum": false}
forward
1 1
270 _
56
MaxPooling2D
{"kh": 3, "kw": 3, "sy": 2, "sx": 2, "ph": 1, "pw": 1, "cover_all": true, "return_indices": false, "_used_cudnn": true, "_input_indexes_to_retain": [0], "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 9, "lazy_grad_sum": false}
forward
3 1
51 _
236 _
242 _
435
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 107, "lazy_grad_sum": false}
forward
3 1
416 _
529 _
533 _
433
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 294, "lazy_grad_sum": false}
forward
2 1
413 _
520 _
416
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 293, "lazy_grad_sum": false}
forward
1 1
58 _
517
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 159, "lazy_grad_sum": false}
forward
2 1
100 _
478 _
97
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 216, "lazy_grad_sum": false}
forward
3 1
167 _
459 _
468 _
180
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 342, "lazy_grad_sum": false}
forward
1 1
118 _
126
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 272, "lazy_grad_sum": false}
forward
1 1
103 _
107
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 85, "lazy_grad_sum": false}
forward
1 1
89 _
100
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 215, "lazy_grad_sum": false}
forward
2 1
155 _
422 _
691
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 210, "lazy_grad_sum": false}
forward
2 1
76 _
669 _
78
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 83, "lazy_grad_sum": false}
forward
2 1
107 _
696 _
105
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 86, "lazy_grad_sum": false}
forward
1 1
108 _
115
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 335, "lazy_grad_sum": false}
forward
2 1
1 _
171 _
147
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 280, "lazy_grad_sum": false}
forward
3 1
78 _
681 _
690 _
103
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 84, "lazy_grad_sum": false}
forward
2 1
82 _
581 _
86
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 4, "pw": 4, "cover_all": false, "dy": 4, "dx": 4, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 333, "lazy_grad_sum": false}
forward
3 1
96 _
87 _
93 _
118
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 271, "lazy_grad_sum": false}
forward
1 1
141 _
85
AveragePooling2D
{"kh": 14, "kw": 14, "sy": 14, "sx": 14, "ph": 0, "pw": 0, "cover_all": false, "return_indices": false, "_used_cudnn": true, "_input_indexes_to_retain": [0], "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 340, "lazy_grad_sum": false}
forward
2 1
115 _
610 _
114
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 336, "lazy_grad_sum": false}
forward
3 1
86 _
592 _
598 _
108
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 334, "lazy_grad_sum": false}
forward
1 1
83 _
92
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 269, "lazy_grad_sum": false}
forward
1 1
142 _
156
ResizeImages
{"out_H": 90, "out_W": 90, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 344, "lazy_grad_sum": false}
forward
2 1
653 _
388 _
659
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 230, "lazy_grad_sum": false}
forward
3 1
97 _
488 _
496 _
120
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 217, "lazy_grad_sum": false}
forward
2 1
98 _
685 _
101
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 203, "lazy_grad_sum": false}
forward
2 1
131 _
712 _
128
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 206, "lazy_grad_sum": false}
forward
2 1
85 _
425 _
112
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 341, "lazy_grad_sum": false}
forward
2 1
120 _
155 _
119
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 218, "lazy_grad_sum": false}
forward
3 1
101 _
694 _
700 _
121
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 204, "lazy_grad_sum": false}
forward
3 1
123 _
414 _
421 _
111
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 81, "lazy_grad_sum": false}
forward
3 1
105 _
707 _
716 _
133
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 87, "lazy_grad_sum": false}
forward
3 1
112 _
432 _
440 _
134
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 342, "lazy_grad_sum": false}
forward
2 1
251 _
724 _
123
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 80, "lazy_grad_sum": false}
forward
2 1
260 _
274 _
148
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 346, "lazy_grad_sum": false}
forward
1 1
151 _
160
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 222, "lazy_grad_sum": false}
forward
2 1
165 _
437 _
139
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 90, "lazy_grad_sum": false}
forward
3 1
114 _
411 _
415 _
138
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 337, "lazy_grad_sum": false}
forward
3 1
127 _
322 _
328 _
151
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 221, "lazy_grad_sum": false}
forward
1 1
134 _
142
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 343, "lazy_grad_sum": false}
forward
2 1
138 _
400 _
136
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 338, "lazy_grad_sum": false}
forward
1 1
153 _
161
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 275, "lazy_grad_sum": false}
forward
2 1
122 _
510 _
127
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 220, "lazy_grad_sum": false}
forward
2 1
126 _
106 _
130
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 273, "lazy_grad_sum": false}
forward
1 1
119 _
122
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 219, "lazy_grad_sum": false}
forward
3 1
128 _
720 _
20 _
154
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 207, "lazy_grad_sum": false}
forward
1 1
372 _
376
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 62, "lazy_grad_sum": false}
forward
1 1
163 _
169
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 312, "lazy_grad_sum": false}
forward
2 1
161 _
140 _
158
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 276, "lazy_grad_sum": false}
forward
2 1
154 _
65 _
639
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 208, "lazy_grad_sum": false}
forward
3 1
130 _
117 _
124 _
153
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 274, "lazy_grad_sum": false}
forward
3 1
146 _
309 _
312 _
163
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 311, "lazy_grad_sum": false}
forward
1 1
178 _
630
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 92, "lazy_grad_sum": false}
forward
1 1
177 _
68
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 212, "lazy_grad_sum": false}
forward
1 1
141 _
144
AveragePooling2D
{"kh": 29, "kw": 29, "sy": 29, "sx": 29, "ph": 0, "pw": 0, "cover_all": false, "return_indices": false, "_used_cudnn": true, "_input_indexes_to_retain": [0], "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 340, "lazy_grad_sum": false}
forward
1 1
136 _
141
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 339, "lazy_grad_sum": false}
forward
3 1
691 _
429 _
438 _
177
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 211, "lazy_grad_sum": false}
forward
2 1
588 _
577 _
576
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 40, "lazy_grad_sum": false}
forward
2 1
678 _
187 _
686
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 100, "lazy_grad_sum": false}
forward
1 1
622 _
632
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 225, "lazy_grad_sum": false}
forward
2 1
160 _
337 _
164
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 223, "lazy_grad_sum": false}
forward
3 1
158 _
152 _
159 _
175
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 277, "lazy_grad_sum": false}
forward
1 1
639 _
155
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 209, "lazy_grad_sum": false}
forward
1 1
186 _
132
ResizeImages
{"out_H": 90, "out_W": 90, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 344, "lazy_grad_sum": false}
forward
1 1
626 _
631
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 348, "lazy_grad_sum": false}
forward
2 1
632 _
362 _
173
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 226, "lazy_grad_sum": false}
forward
2 1
175 _
92 _
172
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 278, "lazy_grad_sum": false}
forward
3 1
139 _
448 _
453 _
178
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 91, "lazy_grad_sum": false}
forward
3 1
148 _
280 _
281 _
626
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 347, "lazy_grad_sum": false}
forward
1 1
74 _
95
ResizeImages
{"out_H": 713, "out_W": 713, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 315, "lazy_grad_sum": false}
forward
3 1
164 _
349 _
353 _
622
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 224, "lazy_grad_sum": false}
forward
2 1
144 _
451 _
167
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 341, "lazy_grad_sum": false}
forward
1 1
180 _
186
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 343, "lazy_grad_sum": false}
forward
1 1
169 _
66
Dropout
{"dropout_ratio": 0.1, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 313, "lazy_grad_sum": false}
forward
3 1
66 _
314 _
3 _
74
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 314, "lazy_grad_sum": false}
forward
1 1
11 _
16
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 282, "lazy_grad_sum": false}
forward
3 1
147 _
521 _
525 _
11
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 281, "lazy_grad_sum": false}
forward
5 1
141 _
156 _
132 _
229 _
257 _
260
Concat
{"axis": 1, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 345, "lazy_grad_sum": false}
forward
2 1
648 _
122 _
647
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 228, "lazy_grad_sum": false}
forward
1 1
172 _
1
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 279, "lazy_grad_sum": false}
forward
3 1
71 _
458 _
465 _
89
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 214, "lazy_grad_sum": false}
forward
2 1
68 _
450 _
71
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 213, "lazy_grad_sum": false}
forward
1 1
141 _
193
AveragePooling2D
{"kh": 44, "kw": 44, "sy": 44, "sx": 44, "ph": 0, "pw": 0, "cover_all": false, "return_indices": false, "_used_cudnn": true, "_input_indexes_to_retain": [0], "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 340, "lazy_grad_sum": false}
forward
3 1
173 _
371 _
374 _
648
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 227, "lazy_grad_sum": false}
forward
3 1
202 _
490 _
498 _
213
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 342, "lazy_grad_sum": false}
forward
1 1
207 _
211
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 72, "lazy_grad_sum": false}
forward
2 1
206 _
265 _
203
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 136, "lazy_grad_sum": false}
forward
1 1
198 _
206
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 135, "lazy_grad_sum": false}
forward
3 1
237 _
263 _
266 _
250
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 342, "lazy_grad_sum": false}
forward
2 1
193 _
479 _
202
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 341, "lazy_grad_sum": false}
forward
3 1
241 _
656 _
663 _
72
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 81, "lazy_grad_sum": false}
forward
1 1
72 _
76
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 82, "lazy_grad_sum": false}
forward
2 1
14 _
81 _
17
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 150, "lazy_grad_sum": false}
forward
1 1
220 _
229
ResizeImages
{"out_H": 90, "out_W": 90, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 344, "lazy_grad_sum": false}
forward
1 1
213 _
220
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 343, "lazy_grad_sum": false}
forward
3 1
203 _
269 _
271 _
219
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 137, "lazy_grad_sum": false}
forward
2 1
219 _
302 _
216
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 138, "lazy_grad_sum": false}
forward
1 1
228 _
235
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 75, "lazy_grad_sum": false}
forward
2 1
211 _
34 _
212
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 73, "lazy_grad_sum": false}
forward
1 1
239 _
245
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 142, "lazy_grad_sum": false}
forward
2 1
235 _
52 _
234
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 76, "lazy_grad_sum": false}
forward
3 1
212 _
38 _
45 _
228
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 74, "lazy_grad_sum": false}
forward
3 1
226 _
282 _
287 _
239
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 141, "lazy_grad_sum": false}
forward
2 1
95 _
15 _
646
SoftmaxCrossEntropy
{"normalize": true, "cache_score": true, "class_weight": null, "ignore_label": -1, "reduce": "mean", "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 316, "lazy_grad_sum": false}
forward
1 1
141 _
222
AveragePooling2D
{"kh": 89, "kw": 89, "sy": 89, "sx": 89, "ph": 0, "pw": 0, "cover_all": false, "return_indices": false, "_used_cudnn": true, "_input_indexes_to_retain": [0], "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 340, "lazy_grad_sum": false}
forward
1 1
216 _
223
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 139, "lazy_grad_sum": false}
forward
1 1
634 _
664
ResizeImages
{"out_H": 713, "out_W": 713, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 351, "lazy_grad_sum": false}
forward
1 1
255 _
257
ResizeImages
{"out_H": 90, "out_W": 90, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 344, "lazy_grad_sum": false}
forward
3 1
234 _
59 _
627 _
249
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 77, "lazy_grad_sum": false}
forward
3 1
633 _
474 _
480 _
651
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 94, "lazy_grad_sum": false}
forward
2 1
249 _
190 _
246
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 78, "lazy_grad_sum": false}
forward
2 1
222 _
508 _
237
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 341, "lazy_grad_sum": false}
forward
1 1
250 _
255
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 343, "lazy_grad_sum": false}
forward
2 1
630 _
464 _
633
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 93, "lazy_grad_sum": false}
forward
1 1
0 _
4
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 145, "lazy_grad_sum": false}
forward
2 1
245 _
295 _
248
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 143, "lazy_grad_sum": false}
forward
2 1
4 _
311 _
259
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 146, "lazy_grad_sum": false}
forward
1 1
631 _
638
Dropout
{"dropout_ratio": 0.1, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 349, "lazy_grad_sum": false}
forward
3 1
248 _
298 _
304 _
0
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 144, "lazy_grad_sum": false}
forward
1 1
246 _
251
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 79, "lazy_grad_sum": false}
forward
2 1
343 _
283 _
331
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 310, "lazy_grad_sum": false}
forward
3 1
638 _
284 _
289 _
634
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 350, "lazy_grad_sum": false}
forward
2 1
12 _
223 _
8
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 148, "lazy_grad_sum": false}
forward
3 1
259 _
315 _
69 _
12
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 147, "lazy_grad_sum": false}
forward
2 1
302 _
466 _
305
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 130, "lazy_grad_sum": false}
forward
1 1
285 _
291
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 125, "lazy_grad_sum": false}
forward
2 1
276 _
426 _
277
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 123, "lazy_grad_sum": false}
forward
2 1
56 _
191 _
278
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 10, "lazy_grad_sum": false}
forward
2 1
291 _
434 _
288
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 126, "lazy_grad_sum": false}
forward
3 1
278 _
199 _
201 _
286
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 11, "lazy_grad_sum": false}
forward
3 1
277 _
420 _
424 _
285
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 124, "lazy_grad_sum": false}
forward
1 1
286 _
293
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 12, "lazy_grad_sum": false}
forward
2 1
223 _
279 _
226
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 140, "lazy_grad_sum": false}
forward
1 1
303 _
308
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 15, "lazy_grad_sum": false}
forward
3 1
288 _
447 _
452 _
300
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 127, "lazy_grad_sum": false}
forward
2 1
293 _
145 _
292
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 13, "lazy_grad_sum": false}
forward
2 1
300 _
262 _
297
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 128, "lazy_grad_sum": false}
forward
2 1
308 _
210 _
306
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 16, "lazy_grad_sum": false}
forward
3 1
292 _
528 _
393 _
303
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 14, "lazy_grad_sum": false}
forward
1 1
316 _
183
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 132, "lazy_grad_sum": false}
forward
3 1
305 _
476 _
481 _
316
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 131, "lazy_grad_sum": false}
forward
1 1
297 _
302
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 129, "lazy_grad_sum": false}
forward
3 1
313 _
240 _
244 _
645
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 11, "lazy_grad_sum": false}
forward
3 1
306 _
218 _
224 _
625
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 17, "lazy_grad_sum": false}
forward
2 1
10 _
320 _
23
Convolution2DFunction
{"sy": 2, "sx": 2, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 0, "lazy_grad_sum": false}
forward
2 1
56 _
233 _
313
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 10, "lazy_grad_sum": false}
forward
2 1
625 _
645 _
649
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 18, "lazy_grad_sum": false}
forward
3 1
185 _
506 _
513 _
198
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 134, "lazy_grad_sum": false}
forward
2 1
183 _
497 _
185
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 133, "lazy_grad_sum": false}
forward
1 1
649 _
652
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 19, "lazy_grad_sum": false}
forward
2 1
348 _
726 _
345
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 256, "lazy_grad_sum": false}
forward
1 1
363 _
369
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 192, "lazy_grad_sum": false}
forward
1 1
341 _
348
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 255, "lazy_grad_sum": false}
forward
2 1
190 _
19 _
192
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 70, "lazy_grad_sum": false}
forward
3 1
332 _
351 _
354 _
350
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 57, "lazy_grad_sum": false}
forward
2 1
400 _
551 _
405
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 330, "lazy_grad_sum": false}
forward
2 1
335 _
129 _
319
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 320, "lazy_grad_sum": false}
forward
2 1
65 _
657 _
382
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 200, "lazy_grad_sum": false}
forward
2 1
350 _
37 _
347
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 58, "lazy_grad_sum": false}
forward
1 1
355 _
357
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 322, "lazy_grad_sum": false}
forward
3 1
346 _
225 _
230 _
363
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 191, "lazy_grad_sum": false}
forward
3 1
319 _
143 _
149 _
355
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 321, "lazy_grad_sum": false}
forward
2 1
92 _
75 _
96
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 270, "lazy_grad_sum": false}
forward
1 1
336 _
343
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 309, "lazy_grad_sum": false}
forward
1 1
338 _
344
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 189, "lazy_grad_sum": false}
forward
3 1
345 _
418 _
423 _
361
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 257, "lazy_grad_sum": false}
forward
3 1
356 _
373 _
378 _
372
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 61, "lazy_grad_sum": false}
forward
2 1
361 _
491 _
359
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 258, "lazy_grad_sum": false}
forward
1 1
347 _
352
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 59, "lazy_grad_sum": false}
forward
1 1
375 _
380
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 325, "lazy_grad_sum": false}
forward
1 1
383 _
389
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 262, "lazy_grad_sum": false}
forward
2 1
357 _
162 _
360
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 4, "pw": 4, "cover_all": false, "dy": 4, "dx": 4, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 323, "lazy_grad_sum": false}
forward
3 1
368 _
449 _
454 _
383
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 261, "lazy_grad_sum": false}
forward
2 1
380 _
524 _
379
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 326, "lazy_grad_sum": false}
forward
1 1
381 _
387
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 315, "lazy_grad_sum": false}
forward
3 1
360 _
170 _
174 _
375
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 324, "lazy_grad_sum": false}
forward
2 1
365 _
299 _
367
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 4, "pw": 4, "cover_all": false, "dy": 4, "dx": 4, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 313, "lazy_grad_sum": false}
forward
1 1
359 _
364
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 259, "lazy_grad_sum": false}
forward
1 1
384 _
392
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 195, "lazy_grad_sum": false}
forward
2 1
369 _
238 _
370
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 193, "lazy_grad_sum": false}
forward
2 1
387 _
63 _
385
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 316, "lazy_grad_sum": false}
forward
3 1
367 _
307 _
310 _
381
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 314, "lazy_grad_sum": false}
forward
2 1
392 _
261 _
390
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 196, "lazy_grad_sum": false}
forward
3 1
370 _
247 _
253 _
384
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 194, "lazy_grad_sum": false}
forward
1 1
394 _
401
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 65, "lazy_grad_sum": false}
forward
2 1
376 _
386 _
377
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 63, "lazy_grad_sum": false}
forward
2 1
343 _
301 _
146
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 310, "lazy_grad_sum": false}
forward
2 1
401 _
2 _
399
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 66, "lazy_grad_sum": false}
forward
3 1
379 _
532 _
537 _
396
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 327, "lazy_grad_sum": false}
forward
1 1
121 _
131
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 205, "lazy_grad_sum": false}
forward
3 1
377 _
398 _
403 _
394
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 64, "lazy_grad_sum": false}
forward
2 1
396 _
335 _
395
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 328, "lazy_grad_sum": false}
forward
3 1
402 _
104 _
109 _
330
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 311, "lazy_grad_sum": false}
forward
3 1
385 _
73 _
79 _
406
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 317, "lazy_grad_sum": false}
forward
1 1
64 _
70
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 265, "lazy_grad_sum": false}
forward
2 1
389 _
467 _
391
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 263, "lazy_grad_sum": false}
forward
3 1
390 _
635 _
640 _
409
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 197, "lazy_grad_sum": false}
forward
2 1
343 _
91 _
402
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 310, "lazy_grad_sum": false}
forward
1 1
77 _
82
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 332, "lazy_grad_sum": false}
forward
2 1
70 _
500 _
407
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 266, "lazy_grad_sum": false}
forward
2 1
409 _
344 _
408
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 198, "lazy_grad_sum": false}
forward
1 1
36 _
39
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 2, "lazy_grad_sum": false}
forward
3 1
391 _
477 _
482 _
64
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 264, "lazy_grad_sum": false}
forward
3 1
405 _
561 _
569 _
77
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 331, "lazy_grad_sum": false}
forward
1 1
184 _
190
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 69, "lazy_grad_sum": false}
forward
3 1
399 _
5 _
7 _
188
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 67, "lazy_grad_sum": false}
forward
1 1
90 _
98
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 202, "lazy_grad_sum": false}
forward
1 1
395 _
400
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 329, "lazy_grad_sum": false}
forward
2 1
406 _
330 _
334
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 318, "lazy_grad_sum": false}
forward
2 1
188 _
352 _
184
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 68, "lazy_grad_sum": false}
forward
3 1
382 _
666 _
670 _
90
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 201, "lazy_grad_sum": false}
forward
1 1
334 _
335
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 319, "lazy_grad_sum": false}
forward
2 1
88 _
364 _
83
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 268, "lazy_grad_sum": false}
forward
1 1
408 _
65
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 199, "lazy_grad_sum": false}
forward
3 1
192 _
24 _
26 _
207
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 71, "lazy_grad_sum": false}
forward
3 1
407 _
507 _
511 _
88
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 267, "lazy_grad_sum": false}
forward
2 1
39 _
571 _
42
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 3, "lazy_grad_sum": false}
forward
2 1
444 _
545 _
441
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 296, "lazy_grad_sum": false}
forward
1 1
462 _
473
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 112, "lazy_grad_sum": false}
forward
1 1
433 _
444
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 295, "lazy_grad_sum": false}
forward
2 1
491 _
672 _
495
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 250, "lazy_grad_sum": false}
forward
2 1
262 _
702 _
484
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 120, "lazy_grad_sum": false}
forward
3 1
443 _
624 _
629 _
462
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 111, "lazy_grad_sum": false}
forward
3 1
331 _
290 _
294 _
358
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 311, "lazy_grad_sum": false}
forward
1 1
460 _
471
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 245, "lazy_grad_sum": false}
forward
2 1
442 _
168 _
445
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 243, "lazy_grad_sum": false}
forward
1 1
428 _
436
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 109, "lazy_grad_sum": false}
forward
3 1
441 _
555 _
560 _
457
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 297, "lazy_grad_sum": false}
forward
2 1
471 _
641 _
470
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 246, "lazy_grad_sum": false}
forward
2 1
457 _
46 _
456
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 298, "lazy_grad_sum": false}
forward
3 1
445 _
176 _
628 _
460
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 244, "lazy_grad_sum": false}
forward
1 1
485 _
494
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 302, "lazy_grad_sum": false}
forward
3 1
469 _
589 _
595 _
485
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 301, "lazy_grad_sum": false}
forward
2 1
364 _
439 _
368
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 260, "lazy_grad_sum": false}
forward
1 1
489 _
502
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 115, "lazy_grad_sum": false}
forward
1 1
456 _
463
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 299, "lazy_grad_sum": false}
forward
2 1
473 _
643 _
472
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 113, "lazy_grad_sum": false}
forward
3 1
470 _
650 _
658 _
486
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 247, "lazy_grad_sum": false}
forward
2 1
502 _
668 _
501
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 116, "lazy_grad_sum": false}
forward
2 1
486 _
412 _
483
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 248, "lazy_grad_sum": false}
forward
3 1
472 _
655 _
661 _
489
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 114, "lazy_grad_sum": false}
forward
1 1
358 _
365
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 312, "lazy_grad_sum": false}
forward
1 1
514 _
321
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 252, "lazy_grad_sum": false}
forward
3 1
495 _
683 _
692 _
514
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 251, "lazy_grad_sum": false}
forward
1 1
317 _
324
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 305, "lazy_grad_sum": false}
forward
2 1
494 _
607 _
499
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 303, "lazy_grad_sum": false}
forward
1 1
483 _
491
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 249, "lazy_grad_sum": false}
forward
3 1
501 _
680 _
689 _
515
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 117, "lazy_grad_sum": false}
forward
2 1
324 _
268 _
512
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 306, "lazy_grad_sum": false}
forward
2 1
515 _
436 _
619
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 118, "lazy_grad_sum": false}
forward
3 1
499 _
617 _
264 _
317
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 304, "lazy_grad_sum": false}
forward
1 1
272 _
276
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 122, "lazy_grad_sum": false}
forward
3 1
484 _
714 _
718 _
272
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 121, "lazy_grad_sum": false}
forward
2 1
339 _
463 _
336
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 308, "lazy_grad_sum": false}
forward
3 1
325 _
710 _
717 _
341
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 254, "lazy_grad_sum": false}
forward
2 1
321 _
701 _
325
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 253, "lazy_grad_sum": false}
forward
3 1
512 _
273 _
275 _
339
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 307, "lazy_grad_sum": false}
forward
1 1
619 _
262
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 119, "lazy_grad_sum": false}
forward
2 1
547 _
446 _
543
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 176, "lazy_grad_sum": false}
forward
1 1
538 _
547
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 175, "lazy_grad_sum": false}
forward
2 1
594 _
713 _
600
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 170, "lazy_grad_sum": false}
forward
1 1
609 _
621
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 42, "lazy_grad_sum": false}
forward
1 1
557 _
568
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 35, "lazy_grad_sum": false}
forward
2 1
539 _
519 _
540
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 33, "lazy_grad_sum": false}
forward
2 1
344 _
215 _
346
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 190, "lazy_grad_sum": false}
forward
1 1
564 _
574
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 165, "lazy_grad_sum": false}
forward
2 1
544 _
654 _
548
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 163, "lazy_grad_sum": false}
forward
2 1
568 _
542 _
566
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 36, "lazy_grad_sum": false}
forward
3 1
543 _
455 _
461 _
563
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 177, "lazy_grad_sum": false}
forward
3 1
540 _
527 _
530 _
557
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 34, "lazy_grad_sum": false}
forward
2 1
574 _
679 _
573
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 166, "lazy_grad_sum": false}
forward
2 1
563 _
594 _
559
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 178, "lazy_grad_sum": false}
forward
3 1
548 _
665 _
667 _
564
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 164, "lazy_grad_sum": false}
forward
1 1
590 _
599
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 182, "lazy_grad_sum": false}
forward
3 1
572 _
487 _
492 _
590
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 181, "lazy_grad_sum": false}
forward
3 1
566 _
553 _
556 _
583
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 37, "lazy_grad_sum": false}
forward
2 1
567 _
475 _
572
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 180, "lazy_grad_sum": false}
forward
1 1
559 _
567
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 179, "lazy_grad_sum": false}
forward
2 1
583 _
725 _
582
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 38, "lazy_grad_sum": false}
forward
3 1
573 _
693 _
695 _
591
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 167, "lazy_grad_sum": false}
forward
2 1
591 _
517 _
587
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 168, "lazy_grad_sum": false}
forward
1 1
618 _
522
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 172, "lazy_grad_sum": false}
forward
3 1
600 _
721 _
503 _
618
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 171, "lazy_grad_sum": false}
forward
1 1
582 _
588
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 39, "lazy_grad_sum": false}
forward
1 1
318 _
326
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 185, "lazy_grad_sum": false}
forward
2 1
599 _
505 _
602
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 183, "lazy_grad_sum": false}
forward
1 1
587 _
594
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 169, "lazy_grad_sum": false}
forward
2 1
326 _
194 _
615
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 186, "lazy_grad_sum": false}
forward
3 1
602 _
179 _
182 _
318
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 184, "lazy_grad_sum": false}
forward
2 1
251 _
644 _
241
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 80, "lazy_grad_sum": false}
forward
1 1
6 _
13
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 45, "lazy_grad_sum": false}
forward
2 1
621 _
605 _
620
Convolution2DFunction
{"sy": 2, "sx": 2, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 43, "lazy_grad_sum": false}
forward
2 1
13 _
526 _
9
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 46, "lazy_grad_sum": false}
forward
2 1
340 _
567 _
338
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 188, "lazy_grad_sum": false}
forward
3 1
523 _
427 _
431 _
538
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 174, "lazy_grad_sum": false}
forward
2 1
522 _
419 _
523
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 173, "lazy_grad_sum": false}
forward
3 1
620 _
616 _
518 _
6
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 44, "lazy_grad_sum": false}
forward
3 1
615 _
200 _
205 _
340
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 187, "lazy_grad_sum": false}
forward
2 1
662 _
493 _
660
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 96, "lazy_grad_sum": false}
forward
1 1
674 _
684
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 232, "lazy_grad_sum": false}
forward
1 1
651 _
662
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 95, "lazy_grad_sum": false}
forward
2 1
412 _
137 _
699
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 240, "lazy_grad_sum": false}
forward
2 1
725 _
243 _
296
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 30, "lazy_grad_sum": false}
forward
3 1
659 _
397 _
404 _
674
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 231, "lazy_grad_sum": false}
forward
2 1
652 _
258 _
636
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 20, "lazy_grad_sum": false}
forward
1 1
671 _
677
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 22, "lazy_grad_sum": false}
forward
2 1
436 _
254 _
443
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 110, "lazy_grad_sum": false}
forward
1 1
647 _
653
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 229, "lazy_grad_sum": false}
forward
3 1
636 _
181 _
189 _
671
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 21, "lazy_grad_sum": false}
forward
3 1
660 _
504 _
509 _
675
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 97, "lazy_grad_sum": false}
forward
2 1
675 _
165 _
673
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 98, "lazy_grad_sum": false}
forward
1 1
703 _
709
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 102, "lazy_grad_sum": false}
forward
2 1
664 _
15 _
676
SoftmaxCrossEntropy
{"normalize": true, "cache_score": true, "class_weight": null, "ignore_label": -1, "reduce": "mean", "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 352, "lazy_grad_sum": false}
forward
3 1
686 _
195 _
197 _
703
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 101, "lazy_grad_sum": false}
forward
1 1
697 _
706
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 25, "lazy_grad_sum": false}
forward
2 1
677 _
196 _
682
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 23, "lazy_grad_sum": false}
forward
1 1
646 _
688
MulConstant
{"value": 0.4, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 317, "lazy_grad_sum": false}
forward
1 1
704 _
711
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 235, "lazy_grad_sum": false}
forward
2 1
684 _
67 _
687
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 233, "lazy_grad_sum": false}
forward
1 1
673 _
678
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 99, "lazy_grad_sum": false}
forward
2 1
706 _
217 _
705
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 26, "lazy_grad_sum": false}
forward
3 1
682 _
204 _
209 _
697
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 24, "lazy_grad_sum": false}
forward
2 1
688 _
676 _
698
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 353, "lazy_grad_sum": false}
forward
2 1
711 _
99 _
708
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 236, "lazy_grad_sum": false}
forward
3 1
687 _
80 _
84 _
704
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 234, "lazy_grad_sum": false}
forward
3 1
576 _
586 _
593 _
609
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 41, "lazy_grad_sum": false}
forward
3 1
705 _
227 _
232 _
722
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 27, "lazy_grad_sum": false}
forward
1 1
410 _
417
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 105, "lazy_grad_sum": false}
forward
2 1
709 _
208 _
715
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 103, "lazy_grad_sum": false}
forward
3 1
708 _
110 _
116 _
612
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 237, "lazy_grad_sum": false}
forward
2 1
722 _
652 _
719
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 28, "lazy_grad_sum": false}
forward
2 1
417 _
231 _
51
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 106, "lazy_grad_sum": false}
forward
2 1
612 _
653 _
723
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 238, "lazy_grad_sum": false}
forward
3 1
715 _
214 _
221 _
410
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 104, "lazy_grad_sum": false}
forward
1 1
531 _
539
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 32, "lazy_grad_sum": false}
forward
3 1
296 _
252 _
256 _
531
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 31, "lazy_grad_sum": false}
forward
1 1
430 _
442
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 242, "lazy_grad_sum": false}
forward
3 1
699 _
150 _
157 _
430
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 241, "lazy_grad_sum": false}
forward
1 1
719 _
725
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 29, "lazy_grad_sum": false}
forward
2 1
435 _
678 _
428
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 108, "lazy_grad_sum": false}
forward
1 1
723 _
412
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 239, "lazy_grad_sum": false}
backward
2 1
30 gradient
30 output
25
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 152, "lazy_grad_sum": false}
backward
3 2
47 gradient
46 input
597 input
46
597
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 290, "lazy_grad_sum": false}
backward
3 2
41 gradient
517 input
623 input
517
623
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 160, "lazy_grad_sum": false}
backward
4 3
33 gradient
21 input
565 input
570 input
21
565
570
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 41, "lazy_grad_sum": false}
backward
4 3
25 gradient
17 input
94 input
102 input
17
94
102
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 151, "lazy_grad_sum": false}
backward
4 3
22 gradient
9 input
535 input
541 input
9
535
541
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 47, "lazy_grad_sum": false}
backward
3 2
516 gradient
133 input
111 input
133
111
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 88, "lazy_grad_sum": false}
backward
3 2
21 gradient
588 input
552 input
588
552
Convolution2DFunction
{"sy": 2, "sx": 2, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 40, "lazy_grad_sum": false}
backward
2 1
31 gradient
31 output
27
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 285, "lazy_grad_sum": false}
backward
3 2
18 gradient
16 input
534 input
16
534
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 283, "lazy_grad_sum": false}
backward
2 1
14 gradient
14 output
8
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 149, "lazy_grad_sum": false}
backward
3 2
29 gradient
31 input
562 input
31
562
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 286, "lazy_grad_sum": false}
backward
4 3
27 gradient
18 input
546 input
550 input
18
546
550
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 284, "lazy_grad_sum": false}
backward
3 2
35 gradient
22 input
33 input
22
33
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 48, "lazy_grad_sum": false}
backward
2 1
37 gradient
37 output
35
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 49, "lazy_grad_sum": false}
backward
4 3
36 gradient
23 input
554 input
558 input
23
554
558
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 1, "lazy_grad_sum": false}
backward
3 2
469 gradient
463 input
578 input
463
578
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 300, "lazy_grad_sum": false}
backward
2 1
49 gradient
49 output
44
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 155, "lazy_grad_sum": false}
backward
3 2
32 gradient
30 input
113 input
30
113
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 153, "lazy_grad_sum": false}
backward
4 3
43 gradient
29 input
575 input
580 input
29
575
580
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 287, "lazy_grad_sum": false}
backward
3 2
48 gradient
49 input
549 input
49
549
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 156, "lazy_grad_sum": false}
backward
3 2
40 gradient
43 input
1 input
43
1
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 288, "lazy_grad_sum": false}
backward
4 3
44 gradient
32 input
125 input
135 input
32
125
135
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 154, "lazy_grad_sum": false}
backward
2 1
165 gradient
165 output
516
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 89, "lazy_grad_sum": false}
backward
3 2
356 gradient
352 input
366 input
352
366
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 60, "lazy_grad_sum": false}
backward
3 2
28 gradient
37 input
585 input
37
585
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 50, "lazy_grad_sum": false}
backward
2 1
60 gradient
60 output
53
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 5, "lazy_grad_sum": false}
backward
2 1
54 gradient
54 output
50
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 52, "lazy_grad_sum": false}
backward
2 1
413 gradient
413 output
61
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 292, "lazy_grad_sum": false}
backward
4 3
50 gradient
28 input
601 input
604 input
28
601
604
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 51, "lazy_grad_sum": false}
backward
4 3
61 gradient
47 input
608 input
613 input
47
608
613
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 291, "lazy_grad_sum": false}
backward
3 2
57 gradient
60 input
596 input
60
596
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 6, "lazy_grad_sum": false}
backward
4 3
53 gradient
42 input
579 input
584 input
42
579
584
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 4, "lazy_grad_sum": false}
backward
2 1
46 gradient
46 output
40
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 289, "lazy_grad_sum": false}
backward
4 3
62 gradient
48 input
603 input
166 input
48
603
166
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 157, "lazy_grad_sum": false}
backward
3 2
58 gradient
62 input
14 input
62
14
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 158, "lazy_grad_sum": false}
backward
2 1
333 gradient
333 output
327
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 55, "lazy_grad_sum": false}
backward
3 2
55 gradient
54 input
614 input
54
614
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 53, "lazy_grad_sum": false}
backward
2 1
270 gradient
270 output
267
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 8, "lazy_grad_sum": false}
backward
2 1
544 gradient
544 output
536
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 162, "lazy_grad_sum": false}
backward
3 2
332 gradient
333 input
342 input
333
342
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 56, "lazy_grad_sum": false}
backward
4 3
267 gradient
57 input
606 input
611 input
57
606
611
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 7, "lazy_grad_sum": false}
backward
4 3
327 gradient
55 input
323 input
329 input
55
323
329
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 54, "lazy_grad_sum": false}
backward
4 3
536 gradient
41 input
637 input
642 input
41
637
642
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 161, "lazy_grad_sum": false}
backward
3 1
56 gradient
270 input
56 output
270
MaxPooling2D
{"kh": 3, "kw": 3, "sy": 2, "sx": 2, "ph": 1, "pw": 1, "cover_all": true, "return_indices": false, "_used_cudnn": true, "_input_indexes_to_retain": [0], "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 9, "lazy_grad_sum": false}
backward
4 3
435 gradient
51 input
236 input
242 input
51
236
242
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 107, "lazy_grad_sum": false}
backward
4 3
433 gradient
416 input
529 input
533 input
416
529
533
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 294, "lazy_grad_sum": false}
backward
3 2
416 gradient
413 input
520 input
413
520
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 293, "lazy_grad_sum": false}
backward
2 1
517 gradient
517 output
58
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 159, "lazy_grad_sum": false}
backward
3 2
97 gradient
100 input
478 input
100
478
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 216, "lazy_grad_sum": false}
backward
4 3
180 gradient
167 input
459 input
468 input
167
459
468
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 342, "lazy_grad_sum": false}
backward
2 1
126 gradient
126 output
118
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 272, "lazy_grad_sum": false}
backward
2 1
107 gradient
107 output
103
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 85, "lazy_grad_sum": false}
backward
2 1
100 gradient
100 output
89
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 215, "lazy_grad_sum": false}
backward
3 2
691 gradient
155 input
422 input
155
422
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 210, "lazy_grad_sum": false}
backward
3 2
78 gradient
76 input
669 input
76
669
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 83, "lazy_grad_sum": false}
backward
3 2
105 gradient
107 input
696 input
107
696
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 86, "lazy_grad_sum": false}
backward
2 1
115 gradient
115 output
108
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 335, "lazy_grad_sum": false}
backward
3 2
147 gradient
1 input
171 input
1
171
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 280, "lazy_grad_sum": false}
backward
4 3
103 gradient
78 input
681 input
690 input
78
681
690
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 84, "lazy_grad_sum": false}
backward
3 2
86 gradient
82 input
581 input
82
581
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 4, "pw": 4, "cover_all": false, "dy": 4, "dx": 4, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 333, "lazy_grad_sum": false}
backward
4 3
118 gradient
96 input
87 input
93 input
96
87
93
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 271, "lazy_grad_sum": false}
backward
3 1
85 gradient
141 input
85 output
141
AveragePooling2D
{"kh": 14, "kw": 14, "sy": 14, "sx": 14, "ph": 0, "pw": 0, "cover_all": false, "return_indices": false, "_used_cudnn": true, "_input_indexes_to_retain": [0], "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 340, "lazy_grad_sum": false}
backward
3 2
114 gradient
115 input
610 input
115
610
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 336, "lazy_grad_sum": false}
backward
4 3
108 gradient
86 input
592 input
598 input
86
592
598
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 334, "lazy_grad_sum": false}
backward
2 1
92 gradient
92 output
83
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 269, "lazy_grad_sum": false}
backward
2 1
156 gradient
142 input
142
ResizeImages
{"out_H": 90, "out_W": 90, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 344, "lazy_grad_sum": false}
backward
3 2
659 gradient
653 input
388 input
653
388
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 230, "lazy_grad_sum": false}
backward
4 3
120 gradient
97 input
488 input
496 input
97
488
496
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 217, "lazy_grad_sum": false}
backward
3 2
101 gradient
98 input
685 input
98
685
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 203, "lazy_grad_sum": false}
backward
3 2
128 gradient
131 input
712 input
131
712
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 206, "lazy_grad_sum": false}
backward
3 2
112 gradient
85 input
425 input
85
425
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 341, "lazy_grad_sum": false}
backward
3 2
119 gradient
120 input
155 input
120
155
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 218, "lazy_grad_sum": false}
backward
4 3
121 gradient
101 input
694 input
700 input
101
694
700
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 204, "lazy_grad_sum": false}
backward
4 3
111 gradient
123 input
414 input
421 input
123
414
421
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 81, "lazy_grad_sum": false}
backward
4 3
133 gradient
105 input
707 input
716 input
105
707
716
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 87, "lazy_grad_sum": false}
backward
4 3
134 gradient
112 input
432 input
440 input
112
432
440
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 342, "lazy_grad_sum": false}
backward
3 2
123 gradient
251 input
724 input
251
724
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 80, "lazy_grad_sum": false}
backward
3 2
148 gradient
260 input
274 input
260
274
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 346, "lazy_grad_sum": false}
backward
2 1
160 gradient
160 output
151
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 222, "lazy_grad_sum": false}
backward
3 2
139 gradient
165 input
437 input
165
437
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 90, "lazy_grad_sum": false}
backward
4 3
138 gradient
114 input
411 input
415 input
114
411
415
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 337, "lazy_grad_sum": false}
backward
4 3
151 gradient
127 input
322 input
328 input
127
322
328
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 221, "lazy_grad_sum": false}
backward
2 1
142 gradient
142 output
134
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 343, "lazy_grad_sum": false}
backward
3 2
136 gradient
138 input
400 input
138
400
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 338, "lazy_grad_sum": false}
backward
2 1
161 gradient
161 output
153
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 275, "lazy_grad_sum": false}
backward
3 2
127 gradient
122 input
510 input
122
510
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 220, "lazy_grad_sum": false}
backward
3 2
130 gradient
126 input
106 input
126
106
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 273, "lazy_grad_sum": false}
backward
2 1
122 gradient
122 output
119
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 219, "lazy_grad_sum": false}
backward
4 3
154 gradient
128 input
720 input
20 input
128
720
20
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 207, "lazy_grad_sum": false}
backward
2 1
376 gradient
376 output
372
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 62, "lazy_grad_sum": false}
backward
2 1
169 gradient
169 output
163
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 312, "lazy_grad_sum": false}
backward
3 2
158 gradient
161 input
140 input
161
140
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 276, "lazy_grad_sum": false}
backward
3 2
639 gradient
154 input
65 input
154
65
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 208, "lazy_grad_sum": false}
backward
4 3
153 gradient
130 input
117 input
124 input
130
117
124
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 274, "lazy_grad_sum": false}
backward
4 3
163 gradient
146 input
309 input
312 input
146
309
312
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 311, "lazy_grad_sum": false}
backward
2 1
630 gradient
630 output
178
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 92, "lazy_grad_sum": false}
backward
2 1
68 gradient
68 output
177
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 212, "lazy_grad_sum": false}
backward
3 1
144 gradient
141 input
144 output
141
AveragePooling2D
{"kh": 29, "kw": 29, "sy": 29, "sx": 29, "ph": 0, "pw": 0, "cover_all": false, "return_indices": false, "_used_cudnn": true, "_input_indexes_to_retain": [0], "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 340, "lazy_grad_sum": false}
backward
2 1
141 gradient
141 output
136
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 339, "lazy_grad_sum": false}
backward
4 3
177 gradient
691 input
429 input
438 input
691
429
438
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 211, "lazy_grad_sum": false}
backward
3 2
576 gradient
588 input
577 input
588
577
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 40, "lazy_grad_sum": false}
backward
3 2
686 gradient
678 input
187 input
678
187
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 100, "lazy_grad_sum": false}
backward
2 1
632 gradient
632 output
622
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 225, "lazy_grad_sum": false}
backward
3 2
164 gradient
160 input
337 input
160
337
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 223, "lazy_grad_sum": false}
backward
4 3
175 gradient
158 input
152 input
159 input
158
152
159
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 277, "lazy_grad_sum": false}
backward
2 1
155 gradient
155 output
639
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 209, "lazy_grad_sum": false}
backward
2 1
132 gradient
186 input
186
ResizeImages
{"out_H": 90, "out_W": 90, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 344, "lazy_grad_sum": false}
backward
2 1
631 gradient
631 output
626
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 348, "lazy_grad_sum": false}
backward
3 2
173 gradient
632 input
362 input
632
362
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 226, "lazy_grad_sum": false}
backward
3 2
172 gradient
175 input
92 input
175
92
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 278, "lazy_grad_sum": false}
backward
4 3
178 gradient
139 input
448 input
453 input
139
448
453
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 91, "lazy_grad_sum": false}
backward
4 3
626 gradient
148 input
280 input
281 input
148
280
281
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 347, "lazy_grad_sum": false}
backward
2 1
95 gradient
74 input
74
ResizeImages
{"out_H": 713, "out_W": 713, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 315, "lazy_grad_sum": false}
backward
4 3
622 gradient
164 input
349 input
353 input
164
349
353
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 224, "lazy_grad_sum": false}
backward
3 2
167 gradient
144 input
451 input
144
451
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 341, "lazy_grad_sum": false}
backward
2 1
186 gradient
186 output
180
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 343, "lazy_grad_sum": false}
backward
2 1
66 gradient
169 input
169
Dropout
{"dropout_ratio": 0.1, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 313, "lazy_grad_sum": false}
backward
4 3
74 gradient
66 input
314 input
3 input
66
314
3
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 314, "lazy_grad_sum": false}
backward
2 1
16 gradient
16 output
11
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 282, "lazy_grad_sum": false}
backward
4 3
11 gradient
147 input
521 input
525 input
147
521
525
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 281, "lazy_grad_sum": false}
backward
6 5
260 gradient
141 input
156 input
132 input
229 input
257 input
141
156
132
229
257
Concat
{"axis": 1, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 345, "lazy_grad_sum": false}
backward
3 2
647 gradient
648 input
122 input
648
122
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 228, "lazy_grad_sum": false}
backward
2 1
1 gradient
1 output
172
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 279, "lazy_grad_sum": false}
backward
4 3
89 gradient
71 input
458 input
465 input
71
458
465
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 214, "lazy_grad_sum": false}
backward
3 2
71 gradient
68 input
450 input
68
450
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 213, "lazy_grad_sum": false}
backward
3 1
193 gradient
141 input
193 output
141
AveragePooling2D
{"kh": 44, "kw": 44, "sy": 44, "sx": 44, "ph": 0, "pw": 0, "cover_all": false, "return_indices": false, "_used_cudnn": true, "_input_indexes_to_retain": [0], "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 340, "lazy_grad_sum": false}
backward
4 3
648 gradient
173 input
371 input
374 input
173
371
374
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 227, "lazy_grad_sum": false}
backward
4 3
213 gradient
202 input
490 input
498 input
202
490
498
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 342, "lazy_grad_sum": false}
backward
2 1
211 gradient
211 output
207
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 72, "lazy_grad_sum": false}
backward
3 2
203 gradient
206 input
265 input
206
265
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 136, "lazy_grad_sum": false}
backward
2 1
206 gradient
206 output
198
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 135, "lazy_grad_sum": false}
backward
4 3
250 gradient
237 input
263 input
266 input
237
263
266
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 342, "lazy_grad_sum": false}
backward
3 2
202 gradient
193 input
479 input
193
479
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 341, "lazy_grad_sum": false}
backward
4 3
72 gradient
241 input
656 input
663 input
241
656
663
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 81, "lazy_grad_sum": false}
backward
2 1
76 gradient
76 output
72
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 82, "lazy_grad_sum": false}
backward
3 2
17 gradient
14 input
81 input
14
81
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 150, "lazy_grad_sum": false}
backward
2 1
229 gradient
220 input
220
ResizeImages
{"out_H": 90, "out_W": 90, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 344, "lazy_grad_sum": false}
backward
2 1
220 gradient
220 output
213
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 343, "lazy_grad_sum": false}
backward
4 3
219 gradient
203 input
269 input
271 input
203
269
271
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 137, "lazy_grad_sum": false}
backward
3 2
216 gradient
219 input
302 input
219
302
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 138, "lazy_grad_sum": false}
backward
2 1
235 gradient
235 output
228
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 75, "lazy_grad_sum": false}
backward
3 2
212 gradient
211 input
34 input
211
34
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 73, "lazy_grad_sum": false}
backward
2 1
245 gradient
245 output
239
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 142, "lazy_grad_sum": false}
backward
3 2
234 gradient
235 input
52 input
235
52
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 76, "lazy_grad_sum": false}
backward
4 3
228 gradient
212 input
38 input
45 input
212
38
45
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 74, "lazy_grad_sum": false}
backward
4 3
239 gradient
226 input
282 input
287 input
226
282
287
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 141, "lazy_grad_sum": false}
backward
3 2
646 gradient
95 input
15 input
95
15
SoftmaxCrossEntropy
{"normalize": true, "cache_score": true, "class_weight": null, "ignore_label": -1, "reduce": "mean", "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 316, "lazy_grad_sum": false}
backward
3 1
222 gradient
141 input
222 output
141
AveragePooling2D
{"kh": 89, "kw": 89, "sy": 89, "sx": 89, "ph": 0, "pw": 0, "cover_all": false, "return_indices": false, "_used_cudnn": true, "_input_indexes_to_retain": [0], "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 340, "lazy_grad_sum": false}
backward
2 1
223 gradient
223 output
216
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 139, "lazy_grad_sum": false}
backward
2 1
664 gradient
634 input
634
ResizeImages
{"out_H": 713, "out_W": 713, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 351, "lazy_grad_sum": false}
backward
2 1
257 gradient
255 input
255
ResizeImages
{"out_H": 90, "out_W": 90, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 344, "lazy_grad_sum": false}
backward
4 3
249 gradient
234 input
59 input
627 input
234
59
627
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 77, "lazy_grad_sum": false}
backward
4 3
651 gradient
633 input
474 input
480 input
633
474
480
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 94, "lazy_grad_sum": false}
backward
3 2
246 gradient
249 input
190 input
249
190
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 78, "lazy_grad_sum": false}
backward
3 2
237 gradient
222 input
508 input
222
508
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 341, "lazy_grad_sum": false}
backward
2 1
255 gradient
255 output
250
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 343, "lazy_grad_sum": false}
backward
3 2
633 gradient
630 input
464 input
630
464
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 93, "lazy_grad_sum": false}
backward
2 1
4 gradient
4 output
0
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 145, "lazy_grad_sum": false}
backward
3 2
248 gradient
245 input
295 input
245
295
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 143, "lazy_grad_sum": false}
backward
3 2
259 gradient
4 input
311 input
4
311
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 146, "lazy_grad_sum": false}
backward
2 1
638 gradient
631 input
631
Dropout
{"dropout_ratio": 0.1, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 349, "lazy_grad_sum": false}
backward
4 3
0 gradient
248 input
298 input
304 input
248
298
304
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 144, "lazy_grad_sum": false}
backward
2 1
251 gradient
251 output
246
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 79, "lazy_grad_sum": false}
backward
3 2
331 gradient
343 input
283 input
343
283
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 310, "lazy_grad_sum": false}
backward
4 3
634 gradient
638 input
284 input
289 input
638
284
289
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 350, "lazy_grad_sum": false}
backward
3 2
8 gradient
12 input
223 input
12
223
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 148, "lazy_grad_sum": false}
backward
4 3
12 gradient
259 input
315 input
69 input
259
315
69
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 147, "lazy_grad_sum": false}
backward
3 2
305 gradient
302 input
466 input
302
466
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 130, "lazy_grad_sum": false}
backward
2 1
291 gradient
291 output
285
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 125, "lazy_grad_sum": false}
backward
3 2
277 gradient
276 input
426 input
276
426
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 123, "lazy_grad_sum": false}
backward
3 2
278 gradient
56 input
191 input
56
191
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 10, "lazy_grad_sum": false}
backward
3 2
288 gradient
291 input
434 input
291
434
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 126, "lazy_grad_sum": false}
backward
4 3
286 gradient
278 input
199 input
201 input
278
199
201
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 11, "lazy_grad_sum": false}
backward
4 3
285 gradient
277 input
420 input
424 input
277
420
424
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 124, "lazy_grad_sum": false}
backward
2 1
293 gradient
293 output
286
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 12, "lazy_grad_sum": false}
backward
3 2
226 gradient
223 input
279 input
223
279
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 140, "lazy_grad_sum": false}
backward
2 1
308 gradient
308 output
303
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 15, "lazy_grad_sum": false}
backward
4 3
300 gradient
288 input
447 input
452 input
288
447
452
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 127, "lazy_grad_sum": false}
backward
3 2
292 gradient
293 input
145 input
293
145
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 13, "lazy_grad_sum": false}
backward
3 2
297 gradient
300 input
262 input
300
262
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 128, "lazy_grad_sum": false}
backward
3 2
306 gradient
308 input
210 input
308
210
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 16, "lazy_grad_sum": false}
backward
4 3
303 gradient
292 input
528 input
393 input
292
528
393
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 14, "lazy_grad_sum": false}
backward
2 1
183 gradient
183 output
316
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 132, "lazy_grad_sum": false}
backward
4 3
316 gradient
305 input
476 input
481 input
305
476
481
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 131, "lazy_grad_sum": false}
backward
2 1
302 gradient
302 output
297
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 129, "lazy_grad_sum": false}
backward
4 3
645 gradient
313 input
240 input
244 input
313
240
244
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 11, "lazy_grad_sum": false}
backward
4 3
625 gradient
306 input
218 input
224 input
306
218
224
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 17, "lazy_grad_sum": false}
backward
3 2
23 gradient
10 input
320 input
10
320
Convolution2DFunction
{"sy": 2, "sx": 2, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 0, "lazy_grad_sum": false}
backward
3 2
313 gradient
56 input
233 input
56
233
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 10, "lazy_grad_sum": false}
backward
3 2
649 gradient
625 input
645 input
625
645
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 18, "lazy_grad_sum": false}
backward
4 3
198 gradient
185 input
506 input
513 input
185
506
513
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 134, "lazy_grad_sum": false}
backward
3 2
185 gradient
183 input
497 input
183
497
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 133, "lazy_grad_sum": false}
backward
2 1
652 gradient
652 output
649
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 19, "lazy_grad_sum": false}
backward
3 2
345 gradient
348 input
726 input
348
726
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 256, "lazy_grad_sum": false}
backward
2 1
369 gradient
369 output
363
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 192, "lazy_grad_sum": false}
backward
2 1
348 gradient
348 output
341
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 255, "lazy_grad_sum": false}
backward
3 2
192 gradient
190 input
19 input
190
19
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 70, "lazy_grad_sum": false}
backward
4 3
350 gradient
332 input
351 input
354 input
332
351
354
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 57, "lazy_grad_sum": false}
backward
3 2
405 gradient
400 input
551 input
400
551
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 330, "lazy_grad_sum": false}
backward
3 2
319 gradient
335 input
129 input
335
129
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 320, "lazy_grad_sum": false}
backward
3 2
382 gradient
65 input
657 input
65
657
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 200, "lazy_grad_sum": false}
backward
3 2
347 gradient
350 input
37 input
350
37
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 58, "lazy_grad_sum": false}
backward
2 1
357 gradient
357 output
355
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 322, "lazy_grad_sum": false}
backward
4 3
363 gradient
346 input
225 input
230 input
346
225
230
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 191, "lazy_grad_sum": false}
backward
4 3
355 gradient
319 input
143 input
149 input
319
143
149
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 321, "lazy_grad_sum": false}
backward
3 2
96 gradient
92 input
75 input
92
75
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 270, "lazy_grad_sum": false}
backward
2 1
343 gradient
343 output
336
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 309, "lazy_grad_sum": false}
backward
2 1
344 gradient
344 output
338
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 189, "lazy_grad_sum": false}
backward
4 3
361 gradient
345 input
418 input
423 input
345
418
423
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 257, "lazy_grad_sum": false}
backward
4 3
372 gradient
356 input
373 input
378 input
356
373
378
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 61, "lazy_grad_sum": false}
backward
3 2
359 gradient
361 input
491 input
361
491
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 258, "lazy_grad_sum": false}
backward
2 1
352 gradient
352 output
347
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 59, "lazy_grad_sum": false}
backward
2 1
380 gradient
380 output
375
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 325, "lazy_grad_sum": false}
backward
2 1
389 gradient
389 output
383
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 262, "lazy_grad_sum": false}
backward
3 2
360 gradient
357 input
162 input
357
162
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 4, "pw": 4, "cover_all": false, "dy": 4, "dx": 4, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 323, "lazy_grad_sum": false}
backward
4 3
383 gradient
368 input
449 input
454 input
368
449
454
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 261, "lazy_grad_sum": false}
backward
3 2
379 gradient
380 input
524 input
380
524
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 326, "lazy_grad_sum": false}
backward
2 1
387 gradient
387 output
381
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 315, "lazy_grad_sum": false}
backward
4 3
375 gradient
360 input
170 input
174 input
360
170
174
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 324, "lazy_grad_sum": false}
backward
3 2
367 gradient
365 input
299 input
365
299
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 4, "pw": 4, "cover_all": false, "dy": 4, "dx": 4, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 313, "lazy_grad_sum": false}
backward
2 1
364 gradient
364 output
359
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 259, "lazy_grad_sum": false}
backward
2 1
392 gradient
392 output
384
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 195, "lazy_grad_sum": false}
backward
3 2
370 gradient
369 input
238 input
369
238
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 193, "lazy_grad_sum": false}
backward
3 2
385 gradient
387 input
63 input
387
63
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 316, "lazy_grad_sum": false}
backward
4 3
381 gradient
367 input
307 input
310 input
367
307
310
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 314, "lazy_grad_sum": false}
backward
3 2
390 gradient
392 input
261 input
392
261
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 196, "lazy_grad_sum": false}
backward
4 3
384 gradient
370 input
247 input
253 input
370
247
253
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 194, "lazy_grad_sum": false}
backward
2 1
401 gradient
401 output
394
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 65, "lazy_grad_sum": false}
backward
3 2
377 gradient
376 input
386 input
376
386
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 63, "lazy_grad_sum": false}
backward
3 2
146 gradient
343 input
301 input
343
301
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 310, "lazy_grad_sum": false}
backward
3 2
399 gradient
401 input
2 input
401
2
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 66, "lazy_grad_sum": false}
backward
4 3
396 gradient
379 input
532 input
537 input
379
532
537
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 327, "lazy_grad_sum": false}
backward
2 1
131 gradient
131 output
121
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 205, "lazy_grad_sum": false}
backward
4 3
394 gradient
377 input
398 input
403 input
377
398
403
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 64, "lazy_grad_sum": false}
backward
3 2
395 gradient
396 input
335 input
396
335
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 328, "lazy_grad_sum": false}
backward
4 3
330 gradient
402 input
104 input
109 input
402
104
109
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 311, "lazy_grad_sum": false}
backward
4 3
406 gradient
385 input
73 input
79 input
385
73
79
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 317, "lazy_grad_sum": false}
backward
2 1
70 gradient
70 output
64
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 265, "lazy_grad_sum": false}
backward
3 2
391 gradient
389 input
467 input
389
467
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 263, "lazy_grad_sum": false}
backward
4 3
409 gradient
390 input
635 input
640 input
390
635
640
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 197, "lazy_grad_sum": false}
backward
3 2
402 gradient
343 input
91 input
343
91
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 310, "lazy_grad_sum": false}
backward
2 1
82 gradient
82 output
77
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 332, "lazy_grad_sum": false}
backward
3 2
407 gradient
70 input
500 input
70
500
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 266, "lazy_grad_sum": false}
backward
3 2
408 gradient
409 input
344 input
409
344
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 198, "lazy_grad_sum": false}
backward
2 1
39 gradient
39 output
36
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 2, "lazy_grad_sum": false}
backward
4 3
64 gradient
391 input
477 input
482 input
391
477
482
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 264, "lazy_grad_sum": false}
backward
4 3
77 gradient
405 input
561 input
569 input
405
561
569
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 331, "lazy_grad_sum": false}
backward
2 1
190 gradient
190 output
184
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 69, "lazy_grad_sum": false}
backward
4 3
188 gradient
399 input
5 input
7 input
399
5
7
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 67, "lazy_grad_sum": false}
backward
2 1
98 gradient
98 output
90
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 202, "lazy_grad_sum": false}
backward
2 1
400 gradient
400 output
395
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 329, "lazy_grad_sum": false}
backward
3 2
334 gradient
406 input
330 input
406
330
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 318, "lazy_grad_sum": false}
backward
3 2
184 gradient
188 input
352 input
188
352
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 68, "lazy_grad_sum": false}
backward
4 3
90 gradient
382 input
666 input
670 input
382
666
670
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 201, "lazy_grad_sum": false}
backward
2 1
335 gradient
335 output
334
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 319, "lazy_grad_sum": false}
backward
3 2
83 gradient
88 input
364 input
88
364
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 268, "lazy_grad_sum": false}
backward
2 1
65 gradient
65 output
408
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 199, "lazy_grad_sum": false}
backward
4 3
207 gradient
192 input
24 input
26 input
192
24
26
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 71, "lazy_grad_sum": false}
backward
4 3
88 gradient
407 input
507 input
511 input
407
507
511
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 267, "lazy_grad_sum": false}
backward
3 2
42 gradient
39 input
571 input
39
571
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 3, "lazy_grad_sum": false}
backward
3 2
441 gradient
444 input
545 input
444
545
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 296, "lazy_grad_sum": false}
backward
2 1
473 gradient
473 output
462
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 112, "lazy_grad_sum": false}
backward
2 1
444 gradient
444 output
433
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 295, "lazy_grad_sum": false}
backward
3 2
495 gradient
491 input
672 input
491
672
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 250, "lazy_grad_sum": false}
backward
3 2
484 gradient
262 input
702 input
262
702
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 120, "lazy_grad_sum": false}
backward
4 3
462 gradient
443 input
624 input
629 input
443
624
629
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 111, "lazy_grad_sum": false}
backward
4 3
358 gradient
331 input
290 input
294 input
331
290
294
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 311, "lazy_grad_sum": false}
backward
2 1
471 gradient
471 output
460
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 245, "lazy_grad_sum": false}
backward
3 2
445 gradient
442 input
168 input
442
168
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 243, "lazy_grad_sum": false}
backward
2 1
436 gradient
436 output
428
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 109, "lazy_grad_sum": false}
backward
4 3
457 gradient
441 input
555 input
560 input
441
555
560
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 297, "lazy_grad_sum": false}
backward
3 2
470 gradient
471 input
641 input
471
641
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 246, "lazy_grad_sum": false}
backward
3 2
456 gradient
457 input
46 input
457
46
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 298, "lazy_grad_sum": false}
backward
4 3
460 gradient
445 input
176 input
628 input
445
176
628
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 244, "lazy_grad_sum": false}
backward
2 1
494 gradient
494 output
485
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 302, "lazy_grad_sum": false}
backward
4 3
485 gradient
469 input
589 input
595 input
469
589
595
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 301, "lazy_grad_sum": false}
backward
3 2
368 gradient
364 input
439 input
364
439
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 260, "lazy_grad_sum": false}
backward
2 1
502 gradient
502 output
489
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 115, "lazy_grad_sum": false}
backward
2 1
463 gradient
463 output
456
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 299, "lazy_grad_sum": false}
backward
3 2
472 gradient
473 input
643 input
473
643
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 113, "lazy_grad_sum": false}
backward
4 3
486 gradient
470 input
650 input
658 input
470
650
658
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 247, "lazy_grad_sum": false}
backward
3 2
501 gradient
502 input
668 input
502
668
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 116, "lazy_grad_sum": false}
backward
3 2
483 gradient
486 input
412 input
486
412
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 248, "lazy_grad_sum": false}
backward
4 3
489 gradient
472 input
655 input
661 input
472
655
661
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 114, "lazy_grad_sum": false}
backward
2 1
365 gradient
365 output
358
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 312, "lazy_grad_sum": false}
backward
2 1
321 gradient
321 output
514
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 252, "lazy_grad_sum": false}
backward
4 3
514 gradient
495 input
683 input
692 input
495
683
692
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 251, "lazy_grad_sum": false}
backward
2 1
324 gradient
324 output
317
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 305, "lazy_grad_sum": false}
backward
3 2
499 gradient
494 input
607 input
494
607
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 303, "lazy_grad_sum": false}
backward
2 1
491 gradient
491 output
483
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 249, "lazy_grad_sum": false}
backward
4 3
515 gradient
501 input
680 input
689 input
501
680
689
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 117, "lazy_grad_sum": false}
backward
3 2
512 gradient
324 input
268 input
324
268
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 306, "lazy_grad_sum": false}
backward
3 2
619 gradient
515 input
436 input
515
436
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 118, "lazy_grad_sum": false}
backward
4 3
317 gradient
499 input
617 input
264 input
499
617
264
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 304, "lazy_grad_sum": false}
backward
2 1
276 gradient
276 output
272
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 122, "lazy_grad_sum": false}
backward
4 3
272 gradient
484 input
714 input
718 input
484
714
718
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 121, "lazy_grad_sum": false}
backward
3 2
336 gradient
339 input
463 input
339
463
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 308, "lazy_grad_sum": false}
backward
4 3
341 gradient
325 input
710 input
717 input
325
710
717
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 254, "lazy_grad_sum": false}
backward
3 2
325 gradient
321 input
701 input
321
701
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 253, "lazy_grad_sum": false}
backward
4 3
339 gradient
512 input
273 input
275 input
512
273
275
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 307, "lazy_grad_sum": false}
backward
2 1
262 gradient
262 output
619
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 119, "lazy_grad_sum": false}
backward
3 2
543 gradient
547 input
446 input
547
446
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 176, "lazy_grad_sum": false}
backward
2 1
547 gradient
547 output
538
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 175, "lazy_grad_sum": false}
backward
3 2
600 gradient
594 input
713 input
594
713
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 170, "lazy_grad_sum": false}
backward
2 1
621 gradient
621 output
609
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 42, "lazy_grad_sum": false}
backward
2 1
568 gradient
568 output
557
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 35, "lazy_grad_sum": false}
backward
3 2
540 gradient
539 input
519 input
539
519
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 33, "lazy_grad_sum": false}
backward
3 2
346 gradient
344 input
215 input
344
215
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 190, "lazy_grad_sum": false}
backward
2 1
574 gradient
574 output
564
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 165, "lazy_grad_sum": false}
backward
3 2
548 gradient
544 input
654 input
544
654
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 163, "lazy_grad_sum": false}
backward
3 2
566 gradient
568 input
542 input
568
542
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 36, "lazy_grad_sum": false}
backward
4 3
563 gradient
543 input
455 input
461 input
543
455
461
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 177, "lazy_grad_sum": false}
backward
4 3
557 gradient
540 input
527 input
530 input
540
527
530
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 34, "lazy_grad_sum": false}
backward
3 2
573 gradient
574 input
679 input
574
679
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 166, "lazy_grad_sum": false}
backward
3 2
559 gradient
563 input
594 input
563
594
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 178, "lazy_grad_sum": false}
backward
4 3
564 gradient
548 input
665 input
667 input
548
665
667
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 164, "lazy_grad_sum": false}
backward
2 1
599 gradient
599 output
590
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 182, "lazy_grad_sum": false}
backward
4 3
590 gradient
572 input
487 input
492 input
572
487
492
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 181, "lazy_grad_sum": false}
backward
4 3
583 gradient
566 input
553 input
556 input
566
553
556
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 37, "lazy_grad_sum": false}
backward
3 2
572 gradient
567 input
475 input
567
475
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 180, "lazy_grad_sum": false}
backward
2 1
567 gradient
567 output
559
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 179, "lazy_grad_sum": false}
backward
3 2
582 gradient
583 input
725 input
583
725
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 38, "lazy_grad_sum": false}
backward
4 3
591 gradient
573 input
693 input
695 input
573
693
695
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 167, "lazy_grad_sum": false}
backward
3 2
587 gradient
591 input
517 input
591
517
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 168, "lazy_grad_sum": false}
backward
2 1
522 gradient
522 output
618
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 172, "lazy_grad_sum": false}
backward
4 3
618 gradient
600 input
721 input
503 input
600
721
503
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 171, "lazy_grad_sum": false}
backward
2 1
588 gradient
588 output
582
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 39, "lazy_grad_sum": false}
backward
2 1
326 gradient
326 output
318
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 185, "lazy_grad_sum": false}
backward
3 2
602 gradient
599 input
505 input
599
505
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 183, "lazy_grad_sum": false}
backward
2 1
594 gradient
594 output
587
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 169, "lazy_grad_sum": false}
backward
3 2
615 gradient
326 input
194 input
326
194
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 186, "lazy_grad_sum": false}
backward
4 3
318 gradient
602 input
179 input
182 input
602
179
182
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 184, "lazy_grad_sum": false}
backward
3 2
241 gradient
251 input
644 input
251
644
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 80, "lazy_grad_sum": false}
backward
2 1
13 gradient
13 output
6
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 45, "lazy_grad_sum": false}
backward
3 2
620 gradient
621 input
605 input
621
605
Convolution2DFunction
{"sy": 2, "sx": 2, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 43, "lazy_grad_sum": false}
backward
3 2
9 gradient
13 input
526 input
13
526
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 46, "lazy_grad_sum": false}
backward
3 2
338 gradient
340 input
567 input
340
567
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 188, "lazy_grad_sum": false}
backward
4 3
538 gradient
523 input
427 input
431 input
523
427
431
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 174, "lazy_grad_sum": false}
backward
3 2
523 gradient
522 input
419 input
522
419
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 173, "lazy_grad_sum": false}
backward
4 3
6 gradient
620 input
616 input
518 input
620
616
518
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 44, "lazy_grad_sum": false}
backward
4 3
340 gradient
615 input
200 input
205 input
615
200
205
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 187, "lazy_grad_sum": false}
backward
3 2
660 gradient
662 input
493 input
662
493
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 96, "lazy_grad_sum": false}
backward
2 1
684 gradient
684 output
674
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 232, "lazy_grad_sum": false}
backward
2 1
662 gradient
662 output
651
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 95, "lazy_grad_sum": false}
backward
3 2
699 gradient
412 input
137 input
412
137
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 240, "lazy_grad_sum": false}
backward
3 2
296 gradient
725 input
243 input
725
243
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 30, "lazy_grad_sum": false}
backward
4 3
674 gradient
659 input
397 input
404 input
659
397
404
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 231, "lazy_grad_sum": false}
backward
3 2
636 gradient
652 input
258 input
652
258
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 20, "lazy_grad_sum": false}
backward
2 1
677 gradient
677 output
671
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 22, "lazy_grad_sum": false}
backward
3 2
443 gradient
436 input
254 input
436
254
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 110, "lazy_grad_sum": false}
backward
2 1
653 gradient
653 output
647
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 229, "lazy_grad_sum": false}
backward
4 3
671 gradient
636 input
181 input
189 input
636
181
189
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 21, "lazy_grad_sum": false}
backward
4 3
675 gradient
660 input
504 input
509 input
660
504
509
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 97, "lazy_grad_sum": false}
backward
3 2
673 gradient
675 input
165 input
675
165
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 98, "lazy_grad_sum": false}
backward
2 1
709 gradient
709 output
703
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 102, "lazy_grad_sum": false}
backward
3 2
676 gradient
664 input
15 input
664
15
SoftmaxCrossEntropy
{"normalize": true, "cache_score": true, "class_weight": null, "ignore_label": -1, "reduce": "mean", "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 352, "lazy_grad_sum": false}
backward
4 3
703 gradient
686 input
195 input
197 input
686
195
197
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 101, "lazy_grad_sum": false}
backward
2 1
706 gradient
706 output
697
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 25, "lazy_grad_sum": false}
backward
3 2
682 gradient
677 input
196 input
677
196
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 23, "lazy_grad_sum": false}
backward
2 1
688 gradient
646 input
646
MulConstant
{"value": 0.4, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 317, "lazy_grad_sum": false}
backward
2 1
711 gradient
711 output
704
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 235, "lazy_grad_sum": false}
backward
3 2
687 gradient
684 input
67 input
684
67
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 233, "lazy_grad_sum": false}
backward
2 1
678 gradient
678 output
673
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 99, "lazy_grad_sum": false}
backward
3 2
705 gradient
706 input
217 input
706
217
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 26, "lazy_grad_sum": false}
backward
4 3
697 gradient
682 input
204 input
209 input
682
204
209
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 24, "lazy_grad_sum": false}
backward
3 2
698 gradient
688 input
676 input
688
676
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 353, "lazy_grad_sum": false}
backward
3 2
708 gradient
711 input
99 input
711
99
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 236, "lazy_grad_sum": false}
backward
4 3
704 gradient
687 input
80 input
84 input
687
80
84
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 234, "lazy_grad_sum": false}
backward
4 3
609 gradient
576 input
586 input
593 input
576
586
593
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 41, "lazy_grad_sum": false}
backward
4 3
722 gradient
705 input
227 input
232 input
705
227
232
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 27, "lazy_grad_sum": false}
backward
2 1
417 gradient
417 output
410
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 105, "lazy_grad_sum": false}
backward
3 2
715 gradient
709 input
208 input
709
208
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 2, "pw": 2, "cover_all": false, "dy": 2, "dx": 2, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 103, "lazy_grad_sum": false}
backward
4 3
612 gradient
708 input
110 input
116 input
708
110
116
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 237, "lazy_grad_sum": false}
backward
3 2
719 gradient
722 input
652 input
722
652
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 28, "lazy_grad_sum": false}
backward
3 2
51 gradient
417 input
231 input
417
231
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 106, "lazy_grad_sum": false}
backward
3 2
723 gradient
612 input
653 input
612
653
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 238, "lazy_grad_sum": false}
backward
4 3
410 gradient
715 input
214 input
221 input
715
214
221
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 104, "lazy_grad_sum": false}
backward
2 1
539 gradient
539 output
531
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 32, "lazy_grad_sum": false}
backward
4 3
531 gradient
296 input
252 input
256 input
296
252
256
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 31, "lazy_grad_sum": false}
backward
2 1
442 gradient
442 output
430
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 242, "lazy_grad_sum": false}
backward
4 3
430 gradient
699 input
150 input
157 input
699
150
157
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 241, "lazy_grad_sum": false}
backward
2 1
725 gradient
725 output
719
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 29, "lazy_grad_sum": false}
backward
3 2
428 gradient
435 input
678 input
435
678
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 108, "lazy_grad_sum": false}
backward
2 1
412 gradient
412 output
723
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 239, "lazy_grad_sum": false}
