986 1032
0 1048576 /predictor/res4/b19/conv3/W
1 4096 /predictor/res4/b19/bn3/gamma
2 4096 /predictor/res4/b19/bn3/beta
3 1048576 /predictor/res4/b20/conv1/W
4 1024 /predictor/res4/b20/bn1/gamma
5 1024 /predictor/res4/b20/bn1/beta
6 2359296 /predictor/res4/b20/conv2/W
7 1024 /predictor/res4/b20/bn2/gamma
8 1024 /predictor/res4/b20/bn2/beta
9 1048576 /predictor/res4/b20/conv3/W
10 4096 /predictor/res4/b20/bn3/gamma
11 4096 /predictor/res4/b20/bn3/beta
12 1048576 /predictor/res4/b27/conv3/W
13 12845056 _
14 6422528 _
15 12845056 _
16 4096 /predictor/res4/b27/bn3/gamma
17 6422528 _
18 6422528 _
19 4096 /predictor/res4/b27/bn3/beta
20 3211264 _
21 1048576 /predictor/res4/b28/conv1/W
22 3211264 _
23 3211264 _
24 6422528 _
25 1024 /predictor/res4/b28/bn1/gamma
26 25690112 _
27 6422528 _
28 1024 /predictor/res4/b28/bn1/beta
29 3211264 _
30 2359296 /predictor/res4/b28/conv2/W
31 12845056 _
32 25690112 _
33 3211264 _
34 25690112 _
35 1024 /predictor/res4/b28/bn2/gamma
36 6422528 _
37 1024 /predictor/res4/b28/bn2/beta
38 25690112 _
39 12845056 _
40 12845056 _
41 1048576 /predictor/res4/b28/conv3/W
42 3211264 _
43 6422528 _
44 12845056 _
45 4096 /predictor/res4/b28/bn3/gamma
46 262144 _
47 6422528 _
48 6422528 _
49 4096 /predictor/res4/b28/bn3/beta
50 102760448 _
51 25690112 _
52 1048576 /predictor/res4/b11/conv3/W
53 1048576 /predictor/res4/b3/conv3/W
54 102760448 _
55 6422528 _
56 4096 /predictor/res4/b11/bn3/gamma
57 4096 /predictor/res4/b3/bn3/gamma
58 102760448 _
59 25690112 _
60 6422528 _
61 128 1
62 4096 /predictor/res4/b11/bn3/beta
63 4096 /predictor/res4/b3/bn3/beta
64 25690112 _
65 1048576 /predictor/res4/b12/conv1/W
66 25690112 _
67 1048576 /predictor/res4/b4/conv1/W
68 25690112 _
69 25690112 _
70 25690112 _
71 6422528 _
72 1024 /predictor/res4/b12/bn1/gamma
73 1024 /predictor/res4/b4/bn1/gamma
74 25690112 _
75 1024 /predictor/res4/b12/bn1/beta
76 1024 /predictor/res4/b4/bn1/beta
77 2359296 /predictor/res4/b12/conv2/W
78 2359296 /predictor/res4/b4/conv2/W
79 25690112 _
80 6422528 _
81 102760448 _
82 25690112 _
83 1024 /predictor/res4/b12/bn2/gamma
84 1024 /predictor/res4/b4/bn2/gamma
85 6422528 _
86 6422528 _
87 1024 /predictor/res4/b12/bn2/beta
88 1024 /predictor/res4/b4/bn2/beta
89 19267584 0
90 102760448 _
91 12845056 _
92 1048576 /predictor/res4/b12/conv3/W
93 1048576 /predictor/res4/b4/conv3/W
94 102760448 _
95 6422528 _
96 4096 /predictor/res4/b12/bn3/gamma
97 4096 /predictor/res4/b4/bn3/gamma
98 102760448 _
99 25690112 _
100 6422528 _
101 4096 /predictor/res4/b12/bn3/beta
102 4096 /predictor/res4/b4/bn3/beta
103 6422528 _
104 51380224 _
105 25690112 _
106 262144 /predictor/res3/b4/conv1/W
107 25690112 _
108 6422528 _
109 6422528 _
110 6422528 _
111 512 /predictor/res3/b4/bn1/gamma
112 6422528 _
113 25690112 _
114 512 /predictor/res3/b4/bn1/beta
115 6422528 _
116 6422528 _
117 589824 /predictor/res3/b4/conv2/W
118 6422528 _
119 6422528 _
120 512 /predictor/res3/b4/bn2/gamma
121 6422528 _
122 25690112 _
123 6422528 _
124 6422528 _
125 6422528 _
126 512 /predictor/res3/b4/bn2/beta
127 25690112 _
128 6422528 _
129 262144 /predictor/res3/b4/conv3/W
130 25690112 _
131 25690112 _
132 6422528 _
133 6422528 _
134 25690112 _
135 2048 /predictor/res3/b4/bn3/gamma
136 6422528 _
137 25690112 _
138 25690112 _
139 6422528 _
140 2048 /predictor/res3/b4/bn3/beta
141 25690112 _
142 25690112 _
143 25690112 _
144 262144 /predictor/res3/b5/conv1/W
145 25690112 _
146 6422528 _
147 6422528 _
148 25690112 _
149 6422528 _
150 512 /predictor/res3/b5/bn1/gamma
151 6422528 _
152 25690112 _
153 25690112 _
154 512 /predictor/res3/b5/bn1/beta
155 6422528 _
156 6422528 _
157 6422528 _
158 6422528 _
159 25690112 _
160 6422528 _
161 25690112 _
162 25690112 _
163 6422528 _
164 25690112 _
165 6422528 _
166 6422528 _
167 6422528 _
168 12845056 _
169 12845056 _
170 8388608 /predictor/res5/a/conv4/W
171 8192 /predictor/res5/a/bn4/gamma
172 8192 /predictor/res5/a/bn4/beta
173 12845056 _
174 51380224 _
175 12845056 _
176 4194304 /predictor/res5/b1/conv1/W
177 51380224 _
178 2048 /predictor/res5/b1/bn1/gamma
179 51380224 _
180 2048 /predictor/res5/b1/bn1/beta
181 12845056 _
182 9437184 /predictor/res5/b1/conv2/W
183 51380224 _
184 2048 /predictor/res5/b1/bn2/gamma
185 12845056 _
186 2048 /predictor/res5/b1/bn2/beta
187 12845056 _
188 12845056 _
189 4194304 /predictor/res5/b1/conv3/W
190 8192 /predictor/res5/b1/bn3/gamma
191 51380224 _
192 8192 /predictor/res5/b1/bn3/beta
193 12845056 _
194 3211264 _
195 3211264 _
196 1048576 /predictor/res4/b29/conv1/W
197 1048576 /predictor/res4/b21/conv1/W
198 3211264 _
199 1024 /predictor/res4/b29/bn1/gamma
200 1024 /predictor/res4/b21/bn1/gamma
201 1024 /predictor/res4/b29/bn1/beta
202 1024 /predictor/res4/b21/bn1/beta
203 3211264 _
204 2359296 /predictor/res4/b29/conv2/W
205 2359296 /predictor/res4/b21/conv2/W
206 12845056 _
207 3211264 _
208 1024 /predictor/res4/b29/bn2/gamma
209 1024 /predictor/res4/b21/bn2/gamma
210 262144 _
211 1024 /predictor/res4/b29/bn2/beta
212 1024 /predictor/res4/b21/bn2/beta
213 12845056 _
214 128000 _
215 12845056 _
216 1048576 /predictor/res4/b29/conv3/W
217 1048576 /predictor/res4/b21/conv3/W
218 12845056 _
219 4096 /predictor/res4/b29/bn3/gamma
220 4096 /predictor/res4/b21/bn3/gamma
221 4096 /predictor/res4/b29/bn3/beta
222 4096 /predictor/res4/b21/bn3/beta
223 4 _
224 1048576 /predictor/res4/b30/conv1/W
225 1048576 /predictor/res4/b22/conv1/W
226 1024 /predictor/res4/b30/bn1/gamma
227 1024 /predictor/res4/b22/bn1/gamma
228 1024 /predictor/res4/b30/bn1/beta
229 1024 /predictor/res4/b22/bn1/beta
230 6422528 _
231 25690112 _
232 1048576 /predictor/res4/b13/conv1/W
233 6422528 _
234 25690112 _
235 1024 /predictor/res4/b13/bn1/gamma
236 6422528 _
237 6422528 _
238 25690112 _
239 1024 /predictor/res4/b13/bn1/beta
240 1024 /predictor/res2/a/bn4/gamma
241 2359296 /predictor/res4/b13/conv2/W
242 6422528 _
243 6422528 _
244 1024 /predictor/res4/b13/bn2/gamma
245 6422528 _
246 25690112 _
247 6422528 _
248 6422528 _
249 1024 /predictor/res4/b13/bn2/beta
250 1048576 /predictor/res4/b13/conv3/W
251 25690112 _
252 25690112 _
253 6422528 _
254 4096 /predictor/res4/b13/bn3/gamma
255 6422528 _
256 25690112 _
257 6422528 _
258 4096 /predictor/res4/b13/bn3/beta
259 25690112 _
260 1048576 /predictor/res4/b14/conv1/W
261 25690112 _
262 6422528 _
263 25690112 _
264 6422528 _
265 6422528 _
266 1024 /predictor/res4/b14/bn1/gamma
267 6422528 _
268 25690112 _
269 1024 /predictor/res4/b14/bn1/beta
270 1048576 /predictor/res4/b5/conv1/W
271 6422528 _
272 25690112 _
273 1024 /predictor/res4/b5/bn1/gamma
274 6422528 _
275 102760448 _
276 1024 /predictor/res4/b5/bn1/beta
277 102760448 _
278 2359296 /predictor/res4/b5/conv2/W
279 25690112 _
280 25690112 _
281 6422528 _
282 1024 /predictor/res4/b5/bn2/gamma
283 25690112 _
284 25690112 _
285 1024 /predictor/res4/b5/bn2/beta
286 1048576 /predictor/res4/b5/conv3/W
287 6422528 _
288 25690112 _
289 4096 /predictor/res4/b5/bn3/gamma
290 6422528 _
291 6422528 _
292 25690112 _
293 4096 /predictor/res4/b5/bn3/beta
294 25690112 _
295 1048576 /predictor/res4/b6/conv1/W
296 6422528 _
297 25690112 _
298 25690112 _
299 1024 /predictor/res4/b6/bn1/gamma
300 6422528 _
301 102760448 _
302 25690112 _
303 1024 /predictor/res4/b6/bn1/beta
304 256 /predictor/res2/a/bn2/beta
305 589824 /predictor/res3/b5/conv2/W
306 65536 /predictor/res2/a/conv3/W
307 512 /predictor/res3/b5/bn2/gamma
308 1024 /predictor/res2/a/bn3/gamma
309 512 /predictor/res3/b5/bn2/beta
310 1024 /predictor/res2/a/bn3/beta
311 262144 /predictor/res3/b5/conv3/W
312 65536 /predictor/res2/a/conv4/W
313 256 /predictor/res2/b1/bn1/gamma
314 2048 /predictor/res3/b5/bn3/gamma
315 2048 /predictor/res3/b5/bn3/beta
316 256 /predictor/res2/b1/bn1/beta
317 147456 /predictor/res2/b1/conv2/W
318 262144 /predictor/res3/b6/conv1/W
319 256 /predictor/res2/b1/bn2/gamma
320 512 /predictor/res3/b6/bn1/gamma
321 256 /predictor/res2/b1/bn2/beta
322 512 /predictor/res3/b6/bn1/beta
323 65536 /predictor/res2/b1/conv3/W
324 589824 /predictor/res3/b6/conv2/W
325 1024 /predictor/res2/b1/bn3/gamma
326 512 /predictor/res3/b6/bn2/gamma
327 1024 /predictor/res2/a/bn4/beta
328 1024 /predictor/res2/b1/bn3/beta
329 512 /predictor/res3/b6/bn2/beta
330 12845056 _
331 2359296 /predictor/res4/b30/conv2/W
332 2359296 /predictor/res4/b22/conv2/W
333 6422528 _
334 25690112 _
335 25690112 _
336 6422528 _
337 1024 /predictor/res4/b30/bn2/gamma
338 1024 /predictor/res4/b22/bn2/gamma
339 12845056 _
340 25690112 _
341 51380224 _
342 6422528 _
343 51380224 _
344 1024 /predictor/res4/b30/bn2/beta
345 1024 /predictor/res4/b22/bn2/beta
346 25690112 _
347 1048576 /predictor/res4/b30/conv3/W
348 1048576 /predictor/res4/b22/conv3/W
349 51380224 _
350 25690112 _
351 25690112 _
352 6422528 _
353 4096 /predictor/res4/b30/bn3/gamma
354 4096 /predictor/res4/b22/bn3/gamma
355 6422528 _
356 6422528 _
357 6422528 _
358 4096 /predictor/res4/b30/bn3/beta
359 4096 /predictor/res4/b22/bn3/beta
360 12845056 _
361 25690112 _
362 12845056 _
363 12845056 _
364 1048576 /predictor/res4/b31/conv1/W
365 1048576 /predictor/res4/b23/conv1/W
366 6422528 _
367 6422528 _
368 1024 /predictor/res4/b31/bn1/gamma
369 6422528 _
370 1024 /predictor/res4/b23/bn1/gamma
371 6422528 _
372 25690112 _
373 6422528 _
374 12845056 _
375 1024 /predictor/res4/b31/bn1/beta
376 1024 /predictor/res4/b23/bn1/beta
377 51380224 _
378 12845056 _
379 2359296 /predictor/res4/b31/conv2/W
380 2359296 /predictor/res4/b23/conv2/W
381 25690112 _
382 25690112 _
383 6422528 _
384 12845056 _
385 1024 /predictor/res4/b31/bn2/gamma
386 1024 /predictor/res4/b23/bn2/gamma
387 51380224 _
388 25690112 _
389 6422528 _
390 6422528 _
391 51380224 _
392 1024 /predictor/res4/b31/bn2/beta
393 1024 /predictor/res4/b23/bn2/beta
394 25690112 _
395 2359296 /predictor/res4/b14/conv2/W
396 2359296 /predictor/res4/b6/conv2/W
397 4194304 /predictor/res5/b2/conv1/W
398 1024 /predictor/res4/b14/bn2/gamma
399 1024 /predictor/res4/b6/bn2/gamma
400 2048 /predictor/res5/b2/bn1/gamma
401 1024 /predictor/res4/b14/bn2/beta
402 1024 /predictor/res4/b6/bn2/beta
403 2048 /predictor/res5/b2/bn1/beta
404 1048576 /predictor/res4/b14/conv3/W
405 1048576 /predictor/res4/b6/conv3/W
406 9437184 /predictor/res5/b2/conv2/W
407 4096 /predictor/res4/b14/bn3/gamma
408 4096 /predictor/res4/b6/bn3/gamma
409 2048 /predictor/res5/b2/bn2/gamma
410 4096 /predictor/res4/b14/bn3/beta
411 4096 /predictor/res4/b6/bn3/beta
412 2048 /predictor/res5/b2/bn2/beta
413 4194304 /predictor/res5/b2/conv3/W
414 1048576 /predictor/res4/b15/conv1/W
415 1048576 /predictor/res4/b7/conv1/W
416 8192 /predictor/res5/b2/bn3/gamma
417 1024 /predictor/res4/b15/bn1/gamma
418 1024 /predictor/res4/b7/bn1/gamma
419 8192 /predictor/res5/b2/bn3/beta
420 1024 /predictor/res4/b15/bn1/beta
421 1024 /predictor/res4/b7/bn1/beta
422 8192000 /predictor/fc6/W
423 2359296 /predictor/res4/b15/conv2/W
424 2359296 /predictor/res4/b7/conv2/W
425 4000 /predictor/fc6/b
426 1024 /predictor/res4/b15/bn2/gamma
427 1024 /predictor/res4/b7/bn2/gamma
428 1024 /predictor/res4/b15/bn2/beta
429 1024 /predictor/res4/b7/bn2/beta
430 37632 /predictor/conv1/W
431 6422528 _
432 6422528 _
433 6422528 _
434 6422528 _
435 25690112 _
436 6422528 _
437 25690112 _
438 25690112 _
439 6422528 _
440 25690112 _
441 6422528 _
442 6422528 _
443 6422528 _
444 6422528 _
445 25690112 _
446 25690112 _
447 25690112 _
448 6422528 _
449 6422528 _
450 6422528 _
451 6422528 _
452 25690112 _
453 6422528 _
454 25690112 _
455 25690112 _
456 6422528 _
457 25690112 _
458 1048576 /predictor/res4/b23/conv3/W
459 262144 /predictor/res3/b6/conv3/W
460 65536 /predictor/res2/b2/conv1/W
461 4096 /predictor/res4/b23/bn3/gamma
462 2048 /predictor/res3/b6/bn3/gamma
463 256 /predictor/res2/b2/bn1/gamma
464 2048 /predictor/res3/b6/bn3/beta
465 4096 /predictor/res4/b23/bn3/beta
466 256 /predictor/res2/b2/bn1/beta
467 147456 /predictor/res2/b2/conv2/W
468 262144 /predictor/res3/b7/conv1/W
469 1048576 /predictor/res4/b24/conv1/W
470 256 /predictor/res2/b2/bn2/gamma
471 512 /predictor/res3/b7/bn1/gamma
472 1024 /predictor/res4/b24/bn1/gamma
473 256 /predictor/res2/b2/bn2/beta
474 1024 /predictor/res4/b24/bn1/beta
475 512 /predictor/res3/b7/bn1/beta
476 65536 /predictor/res2/b2/conv3/W
477 589824 /predictor/res3/b7/conv2/W
478 2359296 /predictor/res4/b24/conv2/W
479 1024 /predictor/res2/b2/bn3/gamma
480 512 /predictor/res3/b7/bn2/gamma
481 1024 /predictor/res4/b24/bn2/gamma
482 1024 /predictor/res2/b2/bn3/beta
483 1024 /predictor/res4/b24/bn2/beta
484 512 /predictor/res3/b7/bn2/beta
485 1048576 /predictor/res4/b24/conv3/W
486 262144 /predictor/res3/b7/conv3/W
487 131072 /predictor/res3/a/conv1/W
488 4096 /predictor/res4/b24/bn3/gamma
489 2048 /predictor/res3/b7/bn3/gamma
490 512 /predictor/res3/a/bn1/gamma
491 4096 /predictor/res4/b24/bn3/beta
492 2048 /predictor/res3/b7/bn3/beta
493 512 /predictor/res3/a/bn1/beta
494 1048576 /predictor/res4/b15/conv3/W
495 6422528 _
496 6422528 _
497 6422528 _
498 4096 /predictor/res4/b15/bn3/gamma
499 25690112 _
500 6422528 _
501 25690112 _
502 6422528 _
503 6422528 _
504 6422528 _
505 4096 /predictor/res4/b15/bn3/beta
506 25690112 _
507 1048576 /predictor/res4/b16/conv1/W
508 25690112 _
509 25690112 _
510 25690112 _
511 6422528 _
512 6422528 _
513 6422528 _
514 25690112 _
515 1024 /predictor/res4/b16/bn1/gamma
516 6422528 _
517 25690112 _
518 25690112 _
519 1024 /predictor/res4/b16/bn1/beta
520 2359296 /predictor/res4/b16/conv2/W
521 25690112 _
522 6422528 _
523 25690112 _
524 6422528 _
525 6422528 _
526 1024 /predictor/res4/b16/bn2/gamma
527 6422528 _
528 6422528 _
529 6422528 _
530 6422528 _
531 25690112 _
532 1024 /predictor/res4/b16/bn2/beta
533 1048576 /predictor/res4/b16/conv3/W
534 6422528 _
535 6422528 _
536 6422528 _
537 4096 /predictor/res4/b16/bn3/gamma
538 25690112 _
539 6422528 _
540 25690112 _
541 6422528 _
542 6422528 _
543 6422528 _
544 4096 /predictor/res4/b16/bn3/beta
545 3211264 _
546 1048576 /predictor/res4/b31/conv3/W
547 6422528 _
548 51380224 _
549 25690112 _
550 25690112 _
551 6422528 _
552 4096 /predictor/res4/b31/bn3/gamma
553 6422528 _
554 6422528 _
555 4096 /predictor/res4/b31/bn3/beta
556 12845056 _
557 25690112 _
558 12845056 _
559 12845056 _
560 1048576 /predictor/res4/b32/conv1/W
561 6422528 _
562 6422528 _
563 6422528 _
564 1024 /predictor/res4/b32/bn1/gamma
565 25690112 _
566 6422528 _
567 6422528 _
568 12845056 _
569 1024 /predictor/res4/b32/bn1/beta
570 51380224 _
571 12845056 _
572 2359296 /predictor/res4/b32/conv2/W
573 25690112 _
574 25690112 _
575 6422528 _
576 1024 /predictor/res4/b32/bn2/gamma
577 6422528 _
578 25690112 _
579 51380224 _
580 6422528 _
581 51380224 _
582 1024 /predictor/res4/b32/bn2/beta
583 25690112 _
584 12845056 _
585 1048576 /predictor/res4/b32/conv3/W
586 51380224 _
587 25690112 _
588 25690112 _
589 6422528 _
590 4096 /predictor/res4/b32/bn3/gamma
591 6422528 _
592 6422528 _
593 6422528 _
594 4096 /predictor/res4/b32/bn3/beta
595 12845056 _
596 25690112 _
597 1048576 /predictor/res4/b7/conv3/W
598 4096 /predictor/res4/b7/bn3/gamma
599 4096 /predictor/res4/b7/bn3/beta
600 1048576 /predictor/res4/b8/conv1/W
601 1024 /predictor/res4/b8/bn1/gamma
602 1024 /predictor/res4/b8/bn1/beta
603 2359296 /predictor/res4/b8/conv2/W
604 1024 /predictor/res4/b8/bn2/gamma
605 25690112 _
606 1024 /predictor/res4/b8/bn2/beta
607 1048576 /predictor/res4/b8/conv3/W
608 4096 /predictor/res4/b8/bn3/gamma
609 4096 /predictor/res4/b8/bn3/beta
610 524288 /predictor/res4/a/conv1/W
611 1024 /predictor/res4/a/bn1/gamma
612 1024 /predictor/res4/a/bn1/beta
613 2359296 /predictor/res4/a/conv2/W
614 1024 /predictor/res4/a/bn2/gamma
615 1024 /predictor/res4/a/bn2/beta
616 1048576 /predictor/res4/a/conv3/W
617 4096 /predictor/res4/a/bn3/gamma
618 4096 /predictor/res4/a/bn3/beta
619 2097152 /predictor/res4/a/conv4/W
620 4096 /predictor/res4/a/bn4/gamma
621 4096 /predictor/res4/a/bn4/beta
622 6422528 _
623 25690112 _
624 589824 /predictor/res3/a/conv2/W
625 25690112 _
626 512 /predictor/res3/a/bn2/gamma
627 25690112 _
628 512 /predictor/res3/a/bn2/beta
629 262144 /predictor/res3/a/conv3/W
630 6422528 _
631 2048 /predictor/res3/a/bn3/gamma
632 6422528 _
633 6422528 _
634 2048 /predictor/res3/a/bn3/beta
635 524288 /predictor/res3/a/conv4/W
636 6422528 _
637 2048 /predictor/res3/a/bn4/gamma
638 25690112 _
639 6422528 _
640 2048 /predictor/res3/a/bn4/beta
641 262144 /predictor/res3/b1/conv1/W
642 25690112 _
643 25690112 _
644 6422528 _
645 512 /predictor/res3/b1/bn1/gamma
646 25690112 _
647 512 /predictor/res3/b1/bn1/beta
648 1048576 /predictor/res4/b33/conv1/W
649 1048576 /predictor/res4/b25/conv1/W
650 1024 /predictor/res4/b33/bn1/gamma
651 1024 /predictor/res4/b25/bn1/gamma
652 1024 /predictor/res4/b33/bn1/beta
653 1024 /predictor/res4/b25/bn1/beta
654 2359296 /predictor/res4/b33/conv2/W
655 2359296 /predictor/res4/b25/conv2/W
656 1024 /predictor/res4/b33/bn2/gamma
657 1024 /predictor/res4/b25/bn2/gamma
658 1024 /predictor/res4/b33/bn2/beta
659 1024 /predictor/res4/b25/bn2/beta
660 1048576 /predictor/res4/b33/conv3/W
661 1048576 /predictor/res4/b25/conv3/W
662 4096 /predictor/res4/b33/bn3/gamma
663 4096 /predictor/res4/b25/bn3/gamma
664 4096 /predictor/res4/b33/bn3/beta
665 4096 /predictor/res4/b25/bn3/beta
666 1048576 /predictor/res4/b34/conv1/W
667 1048576 /predictor/res4/b26/conv1/W
668 1024 /predictor/res4/b34/bn1/gamma
669 1024 /predictor/res4/b26/bn1/gamma
670 1024 /predictor/res4/b34/bn1/beta
671 1024 /predictor/res4/b26/bn1/beta
672 12845056 _
673 12845056 _
674 102760448 _
675 1048576 /predictor/res4/b9/conv1/W
676 25690112 _
677 1048576 /predictor/res4/b17/conv1/W
678 25690112 _
679 6422528 _
680 6422528 _
681 6422528 _
682 25690112 _
683 1024 /predictor/res4/b9/bn1/gamma
684 6422528 _
685 25690112 _
686 1024 /predictor/res4/b17/bn1/gamma
687 6422528 _
688 6422528 _
689 6422528 _
690 25690112 _
691 12845056 _
692 1024 /predictor/res4/b17/bn1/beta
693 1024 /predictor/res4/b9/bn1/beta
694 51380224 _
695 12845056 _
696 2359296 /predictor/res4/b9/conv2/W
697 25690112 _
698 2359296 /predictor/res4/b17/conv2/W
699 3211264 _
700 25690112 _
701 25690112 _
702 6422528 _
703 25690112 _
704 3211264 _
705 6422528 _
706 1024 /predictor/res4/b9/bn2/gamma
707 51380224 _
708 3211264 _
709 6422528 _
710 1024 /predictor/res4/b17/bn2/gamma
711 25690112 _
712 6422528 _
713 51380224 _
714 25690112 _
715 1024 /predictor/res4/b17/bn2/beta
716 25690112 _
717 1024 /predictor/res4/b9/bn2/beta
718 12845056 _
719 1048576 /predictor/res4/b17/conv3/W
720 51380224 _
721 1048576 /predictor/res4/b9/conv3/W
722 25690112 _
723 3211264 _
724 25690112 _
725 6422528 _
726 6422528 _
727 4096 /predictor/res4/b9/bn3/gamma
728 12845056 _
729 4096 /predictor/res4/b17/bn3/gamma
730 3211264 _
731 6422528 _
732 6422528 _
733 6422528 _
734 6422528 _
735 6422528 _
736 12845056 _
737 4096 /predictor/res4/b17/bn3/beta
738 4096 /predictor/res4/b9/bn3/beta
739 25690112 _
740 12845056 _
741 12845056 _
742 12845056 _
743 1048576 /predictor/res4/b10/conv1/W
744 12845056 _
745 1048576 /predictor/res4/b18/conv1/W
746 6422528 _
747 6422528 _
748 6422528 _
749 3211264 _
750 1024 /predictor/res4/b10/bn1/gamma
751 6422528 _
752 25690112 _
753 51380224 _
754 1024 /predictor/res4/b18/bn1/gamma
755 6422528 _
756 6422528 _
757 25690112 _
758 6422528 _
759 12845056 _
760 1024 /predictor/res4/b10/bn1/beta
761 1024 /predictor/res4/b18/bn1/beta
762 12845056 _
763 25690112 _
764 102760448 _
765 6422528 _
766 102760448 _
767 25690112 _
768 6422528 _
769 102760448 _
770 25690112 _
771 25690112 _
772 102760448 _
773 6422528 _
774 102760448 _
775 25690112 _
776 25690112 _
777 6422528 _
778 25690112 _
779 25690112 _
780 6422528 _
781 6422528 _
782 25690112 _
783 6422528 _
784 102760448 _
785 25690112 _
786 25690112 _
787 6422528 _
788 589824 /predictor/res3/b1/conv2/W
789 1048576 /predictor/res4/b1/conv1/W
790 512 /predictor/res3/b1/bn2/gamma
791 1024 /predictor/res4/b1/bn1/gamma
792 512 /predictor/res3/b1/bn2/beta
793 1024 /predictor/res4/b1/bn1/beta
794 262144 /predictor/res3/b1/conv3/W
795 2359296 /predictor/res4/b1/conv2/W
796 2048 /predictor/res3/b1/bn3/gamma
797 1024 /predictor/res4/b1/bn2/gamma
798 2048 /predictor/res3/b1/bn3/beta
799 1024 /predictor/res4/b1/bn2/beta
800 1048576 /predictor/res4/b1/conv3/W
801 262144 /predictor/res3/b2/conv1/W
802 4096 /predictor/res4/b1/bn3/gamma
803 512 /predictor/res3/b2/bn1/gamma
804 4096 /predictor/res4/b1/bn3/beta
805 512 /predictor/res3/b2/bn1/beta
806 589824 /predictor/res3/b2/conv2/W
807 1048576 /predictor/res4/b2/conv1/W
808 512 /predictor/res3/b2/bn2/gamma
809 1024 /predictor/res4/b2/bn1/gamma
810 512 /predictor/res3/b2/bn2/beta
811 1024 /predictor/res4/b2/bn1/beta
812 2359296 /predictor/res4/b34/conv2/W
813 6422528 _
814 25690112 _
815 25690112 _
816 6422528 _
817 1024 /predictor/res4/b34/bn2/gamma
818 6422528 _
819 6422528 _
820 1024 /predictor/res4/b34/bn2/beta
821 25690112 _
822 1048576 /predictor/res4/b34/conv3/W
823 6422528 _
824 6422528 _
825 4096 /predictor/res4/b34/bn3/gamma
826 6422528 _
827 25690112 _
828 6422528 _
829 6422528 _
830 4096 /predictor/res4/b34/bn3/beta
831 1048576 /predictor/res4/b35/conv1/W
832 25690112 _
833 25690112 _
834 6422528 _
835 6422528 _
836 1024 /predictor/res4/b35/bn1/gamma
837 25690112 _
838 6422528 _
839 25690112 _
840 1024 /predictor/res4/b35/bn1/beta
841 2359296 /predictor/res4/b35/conv2/W
842 25690112 _
843 25690112 _
844 6422528 _
845 1024 /predictor/res4/b35/bn2/gamma
846 6422528 _
847 6422528 _
848 6422528 _
849 1024 /predictor/res4/b35/bn2/beta
850 25690112 _
851 2359296 /predictor/res4/b18/conv2/W
852 1024 /predictor/res4/b18/bn2/gamma
853 1024 /predictor/res4/b18/bn2/beta
854 1048576 /predictor/res4/b18/conv3/W
855 4096 /predictor/res4/b18/bn3/gamma
856 4096 /predictor/res4/b18/bn3/beta
857 1048576 /predictor/res4/b19/conv1/W
858 1024 /predictor/res4/b19/bn1/gamma
859 1024 /predictor/res4/b19/bn1/beta
860 2359296 /predictor/res4/b19/conv2/W
861 1024 /predictor/res4/b19/bn2/gamma
862 1024 /predictor/res4/b19/bn2/beta
863 12845056 _
864 2359296 /predictor/res4/b2/conv2/W
865 2359296 /predictor/res4/b26/conv2/W
866 6422528 _
867 2359296 /predictor/res4/b10/conv2/W
868 25690112 _
869 25690112 _
870 1024 /predictor/res4/b26/bn2/gamma
871 1024 /predictor/res4/b10/bn2/gamma
872 1024 /predictor/res4/b2/bn2/gamma
873 12845056 _
874 51380224 _
875 51380224 _
876 1024 /predictor/res4/b26/bn2/beta
877 25690112 _
878 1024 /predictor/res4/b10/bn2/beta
879 1024 /predictor/res4/b2/bn2/beta
880 1048576 /predictor/res4/b26/conv3/W
881 1048576 /predictor/res4/b10/conv3/W
882 1048576 /predictor/res4/b2/conv3/W
883 51380224 _
884 6422528 _
885 4096 /predictor/res4/b26/bn3/gamma
886 4096 /predictor/res4/b10/bn3/gamma
887 4096 /predictor/res4/b2/bn3/gamma
888 6422528 _
889 6422528 _
890 4096 /predictor/res4/b26/bn3/beta
891 4096 /predictor/res4/b10/bn3/beta
892 4096 /predictor/res4/b2/bn3/beta
893 12845056 _
894 12845056 _
895 12845056 _
896 1048576 /predictor/res4/b27/conv1/W
897 1048576 /predictor/res4/b11/conv1/W
898 1048576 /predictor/res4/b3/conv1/W
899 6422528 _
900 1024 /predictor/res4/b27/bn1/gamma
901 25690112 _
902 1024 /predictor/res4/b11/bn1/gamma
903 1024 /predictor/res4/b3/bn1/gamma
904 6422528 _
905 12845056 _
906 1024 /predictor/res4/b27/bn1/beta
907 1024 /predictor/res4/b11/bn1/beta
908 1024 /predictor/res4/b3/bn1/beta
909 51380224 _
910 12845056 _
911 2359296 /predictor/res4/b27/conv2/W
912 2359296 /predictor/res4/b11/conv2/W
913 2359296 /predictor/res4/b3/conv2/W
914 25690112 _
915 25690112 _
916 1024 /predictor/res4/b27/bn2/gamma
917 6422528 _
918 1024 /predictor/res4/b11/bn2/gamma
919 1024 /predictor/res4/b3/bn2/gamma
920 51380224 _
921 6422528 _
922 51380224 _
923 1024 /predictor/res4/b27/bn2/beta
924 25690112 _
925 1024 /predictor/res4/b11/bn2/beta
926 1024 /predictor/res4/b3/bn2/beta
927 262144 /predictor/res3/b2/conv3/W
928 6422528 _
929 2048 /predictor/res3/b2/bn3/gamma
930 25690112 _
931 6422528 _
932 2048 /predictor/res3/b2/bn3/beta
933 262144 /predictor/res3/b3/conv1/W
934 25690112 _
935 25690112 _
936 6422528 _
937 512 /predictor/res3/b3/bn1/gamma
938 25690112 _
939 512 /predictor/res3/b3/bn1/beta
940 589824 /predictor/res3/b3/conv2/W
941 6422528 _
942 512 /predictor/res3/b3/bn2/gamma
943 6422528 _
944 6422528 _
945 512 /predictor/res3/b3/bn2/beta
946 262144 /predictor/res3/b3/conv3/W
947 6422528 _
948 2048 /predictor/res3/b3/bn3/gamma
949 25690112 _
950 6422528 _
951 2048 /predictor/res3/b3/bn3/beta
952 12845056 _
953 1048576 /predictor/res4/b35/conv3/W
954 12845056 _
955 12845056 _
956 4096 /predictor/res4/b35/bn3/gamma
957 4096 /predictor/res4/b35/bn3/beta
958 12845056 _
959 2097152 /predictor/res5/a/conv1/W
960 51380224 _
961 256 /predictor/conv1/b
962 12845056 _
963 2048 /predictor/res5/a/bn1/gamma
964 256 /predictor/bn1/gamma
965 12845056 _
966 2048 /predictor/res5/a/bn1/beta
967 51380224 _
968 256 /predictor/bn1/beta
969 51380224 _
970 9437184 /predictor/res5/a/conv2/W
971 16384 /predictor/res2/a/conv1/W
972 2048 /predictor/res5/a/bn2/gamma
973 51380224 _
974 2048 /predictor/res5/a/bn2/beta
975 256 /predictor/res2/a/bn1/gamma
976 65536 /predictor/res2/b1/conv1/W
977 51380224 _
978 256 /predictor/res2/a/bn1/beta
979 4194304 /predictor/res5/a/conv3/W
980 51380224 _
981 147456 /predictor/res2/a/conv2/W
982 8192 /predictor/res5/a/bn3/gamma
983 12845056 _
984 8192 /predictor/res5/a/bn3/beta
985 256 /predictor/res2/a/bn2/gamma
forward
1 1
24 _
27
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 249, "lazy_grad_sum": false}
forward
2 1
17 _
241 _
18
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 247, "lazy_grad_sum": false}
forward
2 1
44 _
397 _
42
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 494, "lazy_grad_sum": false}
forward
2 1
27 _
250 _
26
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 250, "lazy_grad_sum": false}
forward
3 1
18 _
244 _
249 _
24
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 248, "lazy_grad_sum": false}
forward
1 1
29 _
33
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 489, "lazy_grad_sum": false}
forward
2 1
22 _
182 _
23
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 487, "lazy_grad_sum": false}
forward
2 1
33 _
189 _
31
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 490, "lazy_grad_sum": false}
forward
3 1
23 _
184 _
186 _
29
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 488, "lazy_grad_sum": false}
forward
1 1
32 _
38
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 253, "lazy_grad_sum": false}
forward
3 1
26 _
254 _
258 _
34
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 251, "lazy_grad_sum": false}
forward
2 1
34 _
850 _
32
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 252, "lazy_grad_sum": false}
forward
1 1
39 _
44
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 493, "lazy_grad_sum": false}
forward
3 1
31 _
190 _
192 _
40
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 491, "lazy_grad_sum": false}
forward
2 1
40 _
15 _
39
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 492, "lazy_grad_sum": false}
forward
1 1
43 _
47
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 256, "lazy_grad_sum": false}
forward
3 1
36 _
266 _
269 _
43
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 255, "lazy_grad_sum": false}
forward
2 1
284 _
414 _
281
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 264, "lazy_grad_sum": false}
forward
1 1
194 _
195
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 496, "lazy_grad_sum": false}
forward
3 1
42 _
400 _
403 _
194
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 495, "lazy_grad_sum": false}
forward
1 1
271 _
274
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 259, "lazy_grad_sum": false}
forward
2 1
47 _
395 _
48
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 257, "lazy_grad_sum": false}
forward
3 1
210 _
422 _
425 _
214
LinearFunction
{"_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_config_use_ideep": "never", "_output_count": 1, "rank": 506, "lazy_grad_sum": false}
forward
2 1
274 _
404 _
272
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 260, "lazy_grad_sum": false}
forward
3 1
48 _
398 _
401 _
271
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 258, "lazy_grad_sum": false}
forward
3 1
198 _
409 _
412 _
203
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 498, "lazy_grad_sum": false}
forward
2 1
195 _
406 _
198
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 497, "lazy_grad_sum": false}
forward
1 1
66 _
74
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 183, "lazy_grad_sum": false}
forward
3 1
59 _
408 _
411 _
68
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 181, "lazy_grad_sum": false}
forward
2 1
68 _
839 _
66
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 182, "lazy_grad_sum": false}
forward
3 1
91 _
490 _
493 _
952
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 35, "lazy_grad_sum": false}
forward
1 1
952 _
954
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 36, "lazy_grad_sum": false}
forward
1 1
79 _
82
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 29, "lazy_grad_sum": false}
forward
2 1
69 _
467 _
70
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 27, "lazy_grad_sum": false}
forward
1 1
80 _
85
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 186, "lazy_grad_sum": false}
forward
3 1
71 _
418 _
421 _
80
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 185, "lazy_grad_sum": false}
forward
2 1
82 _
476 _
81
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 30, "lazy_grad_sum": false}
forward
3 1
70 _
470 _
473 _
79
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 28, "lazy_grad_sum": false}
forward
2 1
238 _
600 _
230
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 194, "lazy_grad_sum": false}
forward
1 1
90 _
98
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 33, "lazy_grad_sum": false}
forward
3 1
81 _
479 _
482 _
94
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 31, "lazy_grad_sum": false}
forward
1 1
95 _
100
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 189, "lazy_grad_sum": false}
forward
2 1
85 _
424 _
86
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 187, "lazy_grad_sum": false}
forward
2 1
94 _
58 _
90
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 32, "lazy_grad_sum": false}
forward
2 1
100 _
597 _
99
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 190, "lazy_grad_sum": false}
forward
3 1
86 _
427 _
429 _
95
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 188, "lazy_grad_sum": false}
forward
1 1
231 _
238
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 193, "lazy_grad_sum": false}
forward
3 1
99 _
598 _
599 _
234
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 191, "lazy_grad_sum": false}
forward
2 1
234 _
74 _
231
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 192, "lazy_grad_sum": false}
forward
2 1
104 _
610 _
921
Convolution2DFunction
{"sy": 2, "sx": 2, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 114, "lazy_grad_sum": false}
forward
3 1
230 _
601 _
602 _
242
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 195, "lazy_grad_sum": false}
forward
2 1
954 _
624 _
955
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 37, "lazy_grad_sum": false}
forward
1 1
46 _
210
Reshape
{"shape": [32, 2048], "_cnt": 0, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 505, "lazy_grad_sum": false}
forward
1 1
119 _
124
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 369, "lazy_grad_sum": false}
forward
1 1
118 _
121
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 436, "lazy_grad_sum": false}
forward
2 1
109 _
655 _
112
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 367, "lazy_grad_sum": false}
forward
2 1
690 _
959 _
545
Convolution2DFunction
{"sy": 2, "sx": 2, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 474, "lazy_grad_sum": false}
forward
2 1
124 _
661 _
122
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 370, "lazy_grad_sum": false}
forward
1 1
125 _
128
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 119, "lazy_grad_sum": false}
forward
3 1
112 _
657 _
659 _
119
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 368, "lazy_grad_sum": false}
forward
2 1
115 _
613 _
116
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 117, "lazy_grad_sum": false}
forward
2 1
152 _
648 _
147
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 444, "lazy_grad_sum": false}
forward
2 1
128 _
616 _
127
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 120, "lazy_grad_sum": false}
forward
3 1
116 _
614 _
615 _
125
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 118, "lazy_grad_sum": false}
forward
1 1
132 _
139
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 439, "lazy_grad_sum": false}
forward
1 1
130 _
141
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 373, "lazy_grad_sum": false}
forward
2 1
121 _
572 _
123
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 437, "lazy_grad_sum": false}
forward
3 1
122 _
663 _
665 _
131
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 371, "lazy_grad_sum": false}
forward
2 1
139 _
585 _
137
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 440, "lazy_grad_sum": false}
forward
2 1
131 _
924 _
130
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 372, "lazy_grad_sum": false}
forward
3 1
134 _
620 _
621 _
143
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 115, "lazy_grad_sum": false}
forward
3 1
123 _
576 _
582 _
132
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 438, "lazy_grad_sum": false}
forward
3 1
127 _
617 _
618 _
138
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 121, "lazy_grad_sum": false}
forward
2 1
104 _
619 _
134
Convolution2DFunction
{"sy": 2, "sx": 2, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 114, "lazy_grad_sum": false}
forward
1 1
146 _
149
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 376, "lazy_grad_sum": false}
forward
1 1
142 _
152
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 443, "lazy_grad_sum": false}
forward
2 1
138 _
143 _
148
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 122, "lazy_grad_sum": false}
forward
3 1
136 _
669 _
671 _
146
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 375, "lazy_grad_sum": false}
forward
3 1
137 _
590 _
594 _
145
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 441, "lazy_grad_sum": false}
forward
2 1
145 _
113 _
142
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 442, "lazy_grad_sum": false}
forward
1 1
155 _
156
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 126, "lazy_grad_sum": false}
forward
2 1
361 _
896 _
355
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 384, "lazy_grad_sum": false}
forward
1 1
148 _
153
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 123, "lazy_grad_sum": false}
forward
1 1
233 _
236
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 446, "lazy_grad_sum": false}
forward
2 1
153 _
789 _
133
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 124, "lazy_grad_sum": false}
forward
1 1
336 _
342
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 379, "lazy_grad_sum": false}
forward
3 1
147 _
650 _
652 _
233
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 445, "lazy_grad_sum": false}
forward
2 1
149 _
865 _
151
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 377, "lazy_grad_sum": false}
forward
2 1
342 _
880 _
340
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 380, "lazy_grad_sum": false}
forward
3 1
133 _
791 _
793 _
155
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 125, "lazy_grad_sum": false}
forward
3 1
151 _
870 _
876 _
336
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 378, "lazy_grad_sum": false}
forward
2 1
259 _
666 _
255
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 454, "lazy_grad_sum": false}
forward
2 1
164 _
807 _
163
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 134, "lazy_grad_sum": false}
forward
1 1
158 _
160
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 129, "lazy_grad_sum": false}
forward
2 1
156 _
795 _
157
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 127, "lazy_grad_sum": false}
forward
2 1
160 _
800 _
159
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 130, "lazy_grad_sum": false}
forward
3 1
157 _
797 _
799 _
158
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 128, "lazy_grad_sum": false}
forward
1 1
161 _
164
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 133, "lazy_grad_sum": false}
forward
3 1
159 _
802 _
804 _
162
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 131, "lazy_grad_sum": false}
forward
2 1
162 _
153 _
161
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 132, "lazy_grad_sum": false}
forward
1 1
165 _
166
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 136, "lazy_grad_sum": false}
forward
3 1
163 _
809 _
811 _
165
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 135, "lazy_grad_sum": false}
forward
2 1
518 _
898 _
513
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 144, "lazy_grad_sum": false}
forward
1 1
497 _
504
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 139, "lazy_grad_sum": false}
forward
2 1
166 _
864 _
167
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 137, "lazy_grad_sum": false}
forward
2 1
504 _
882 _
501
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 140, "lazy_grad_sum": false}
forward
3 1
167 _
872 _
879 _
497
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 138, "lazy_grad_sum": false}
forward
1 1
173 _
175
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 49, "lazy_grad_sum": false}
forward
1 1
177 _
183
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 53, "lazy_grad_sum": false}
forward
3 1
174 _
796 _
798 _
179
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 51, "lazy_grad_sum": false}
forward
2 1
179 _
980 _
177
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 52, "lazy_grad_sum": false}
forward
1 1
185 _
187
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 56, "lazy_grad_sum": false}
forward
3 1
181 _
803 _
805 _
185
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 55, "lazy_grad_sum": false}
forward
2 1
349 _
933 _
339
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 64, "lazy_grad_sum": false}
forward
1 1
193 _
330
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 59, "lazy_grad_sum": false}
forward
2 1
187 _
806 _
188
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 57, "lazy_grad_sum": false}
forward
2 1
330 _
927 _
191
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 60, "lazy_grad_sum": false}
forward
3 1
188 _
808 _
810 _
193
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 58, "lazy_grad_sum": false}
forward
3 1
339 _
937 _
939 _
360
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 65, "lazy_grad_sum": false}
forward
3 1
191 _
929 _
932 _
343
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 61, "lazy_grad_sum": false}
forward
2 1
343 _
183 _
341
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 62, "lazy_grad_sum": false}
forward
2 1
207 _
413 _
206
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 500, "lazy_grad_sum": false}
forward
1 1
203 _
207
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 499, "lazy_grad_sum": false}
forward
1 1
213 _
218
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 503, "lazy_grad_sum": false}
forward
3 1
206 _
416 _
419 _
215
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 501, "lazy_grad_sum": false}
forward
2 1
215 _
44 _
213
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 502, "lazy_grad_sum": false}
forward
1 1
243 _
247
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 449, "lazy_grad_sum": false}
forward
2 1
236 _
654 _
237
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 447, "lazy_grad_sum": false}
forward
1 1
242 _
245
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 196, "lazy_grad_sum": false}
forward
2 1
247 _
660 _
246
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 450, "lazy_grad_sum": false}
forward
3 1
237 _
656 _
658 _
243
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 448, "lazy_grad_sum": false}
forward
2 1
268 _
675 _
264
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 204, "lazy_grad_sum": false}
forward
1 1
253 _
257
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 199, "lazy_grad_sum": false}
forward
1 1
251 _
259
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 453, "lazy_grad_sum": false}
forward
2 1
245 _
603 _
248
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 197, "lazy_grad_sum": false}
forward
3 1
246 _
662 _
664 _
252
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 451, "lazy_grad_sum": false}
forward
2 1
257 _
607 _
256
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 200, "lazy_grad_sum": false}
forward
2 1
252 _
152 _
251
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 452, "lazy_grad_sum": false}
forward
3 1
248 _
604 _
606 _
253
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 198, "lazy_grad_sum": false}
forward
1 1
262 _
265
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 456, "lazy_grad_sum": false}
forward
1 1
261 _
268
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 203, "lazy_grad_sum": false}
forward
3 1
255 _
668 _
670 _
262
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 455, "lazy_grad_sum": false}
forward
3 1
256 _
608 _
609 _
263
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 201, "lazy_grad_sum": false}
forward
2 1
263 _
238 _
261
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 202, "lazy_grad_sum": false}
forward
2 1
517 _
831 _
512
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 464, "lazy_grad_sum": false}
forward
1 1
431 _
432
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 206, "lazy_grad_sum": false}
forward
1 1
496 _
502
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 459, "lazy_grad_sum": false}
forward
3 1
264 _
683 _
693 _
431
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 205, "lazy_grad_sum": false}
forward
2 1
265 _
812 _
267
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 457, "lazy_grad_sum": false}
forward
2 1
502 _
822 _
499
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 460, "lazy_grad_sum": false}
forward
3 1
267 _
817 _
820 _
496
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 458, "lazy_grad_sum": false}
forward
2 1
440 _
743 _
439
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 214, "lazy_grad_sum": false}
forward
1 1
279 _
284
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 263, "lazy_grad_sum": false}
forward
2 1
605 _
971 _
283
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 4, "lazy_grad_sum": false}
forward
3 1
272 _
407 _
410 _
280
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 261, "lazy_grad_sum": false}
forward
2 1
280 _
38 _
279
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 262, "lazy_grad_sum": false}
forward
1 1
287 _
290
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 266, "lazy_grad_sum": false}
forward
3 1
281 _
417 _
420 _
287
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 265, "lazy_grad_sum": false}
forward
2 1
98 _
487 _
91
Convolution2DFunction
{"sy": 2, "sx": 2, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 34, "lazy_grad_sum": false}
forward
3 1
283 _
975 _
978 _
288
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 5, "lazy_grad_sum": false}
forward
1 1
288 _
292
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 6, "lazy_grad_sum": false}
forward
2 1
447 _
507 _
444
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 274, "lazy_grad_sum": false}
forward
1 1
296 _
300
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 269, "lazy_grad_sum": false}
forward
2 1
290 _
423 _
291
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 267, "lazy_grad_sum": false}
forward
1 1
297 _
302
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 9, "lazy_grad_sum": false}
forward
2 1
292 _
981 _
294
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 7, "lazy_grad_sum": false}
forward
2 1
300 _
494 _
298
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 270, "lazy_grad_sum": false}
forward
2 1
302 _
306 _
301
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 10, "lazy_grad_sum": false}
forward
3 1
291 _
426 _
428 _
296
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 268, "lazy_grad_sum": false}
forward
3 1
294 _
985 _
304 _
297
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 8, "lazy_grad_sum": false}
forward
1 1
445 _
447
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 273, "lazy_grad_sum": false}
forward
3 1
764 _
240 _
327 _
769
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 5, "lazy_grad_sum": false}
forward
3 1
298 _
498 _
505 _
446
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 271, "lazy_grad_sum": false}
forward
3 1
301 _
308 _
310 _
766
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 11, "lazy_grad_sum": false}
forward
2 1
446 _
284 _
445
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 272, "lazy_grad_sum": false}
forward
2 1
605 _
312 _
764
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 4, "lazy_grad_sum": false}
forward
3 1
444 _
515 _
519 _
448
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 275, "lazy_grad_sum": false}
forward
1 1
350 _
361
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 383, "lazy_grad_sum": false}
forward
1 1
341 _
349
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 63, "lazy_grad_sum": false}
forward
1 1
352 _
356
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 316, "lazy_grad_sum": false}
forward
3 1
340 _
885 _
890 _
351
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 381, "lazy_grad_sum": false}
forward
2 1
351 _
141 _
350
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 382, "lazy_grad_sum": false}
forward
1 1
360 _
362
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 66, "lazy_grad_sum": false}
forward
2 1
394 _
197 _
389
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 324, "lazy_grad_sum": false}
forward
2 1
548 _
106 _
384
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 74, "lazy_grad_sum": false}
forward
1 1
366 _
369
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 386, "lazy_grad_sum": false}
forward
1 1
367 _
373
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 319, "lazy_grad_sum": false}
forward
3 1
355 _
900 _
906 _
366
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 385, "lazy_grad_sum": false}
forward
2 1
356 _
6 _
357
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 317, "lazy_grad_sum": false}
forward
2 1
373 _
9 _
372
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 320, "lazy_grad_sum": false}
forward
3 1
357 _
7 _
8 _
367
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 318, "lazy_grad_sum": false}
forward
1 1
374 _
378
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 69, "lazy_grad_sum": false}
forward
2 1
362 _
940 _
363
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 67, "lazy_grad_sum": false}
forward
2 1
557 _
21 _
547
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 394, "lazy_grad_sum": false}
forward
2 1
378 _
946 _
377
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 70, "lazy_grad_sum": false}
forward
3 1
363 _
942 _
945 _
374
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 68, "lazy_grad_sum": false}
forward
1 1
381 _
394
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 323, "lazy_grad_sum": false}
forward
1 1
383 _
390
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 389, "lazy_grad_sum": false}
forward
2 1
369 _
911 _
371
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 387, "lazy_grad_sum": false}
forward
3 1
372 _
10 _
11 _
382
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 321, "lazy_grad_sum": false}
forward
2 1
390 _
12 _
388
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 390, "lazy_grad_sum": false}
forward
2 1
382 _
346 _
381
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 322, "lazy_grad_sum": false}
forward
3 1
371 _
916 _
923 _
383
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 388, "lazy_grad_sum": false}
forward
1 1
387 _
548
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 73, "lazy_grad_sum": false}
forward
3 1
377 _
948 _
951 _
391
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 71, "lazy_grad_sum": false}
forward
2 1
391 _
349 _
387
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 72, "lazy_grad_sum": false}
forward
1 1
495 _
500
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 326, "lazy_grad_sum": false}
forward
1 1
549 _
557
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 393, "lazy_grad_sum": false}
forward
3 1
389 _
200 _
202 _
495
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 325, "lazy_grad_sum": false}
forward
3 1
388 _
16 _
19 _
550
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 391, "lazy_grad_sum": false}
forward
2 1
550 _
361 _
549
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 392, "lazy_grad_sum": false}
forward
1 1
556 _
558
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 76, "lazy_grad_sum": false}
forward
3 1
384 _
111 _
114 _
556
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 75, "lazy_grad_sum": false}
forward
2 1
531 _
225 _
525
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 334, "lazy_grad_sum": false}
forward
3 1
547 _
25 _
28 _
561
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 395, "lazy_grad_sum": false}
forward
2 1
214 _
61 _
223
SoftmaxCrossEntropy
{"normalize": true, "cache_score": true, "class_weight": null, "ignore_label": -1, "reduce": "mean", "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 507, "lazy_grad_sum": false}
forward
3 1
89 _
430 _
961 _
674
Convolution2DFunction
{"sy": 2, "sx": 2, "ph": 3, "pw": 3, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 0, "lazy_grad_sum": false}
forward
3 1
674 _
964 _
968 _
275
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 1, "lazy_grad_sum": false}
forward
1 1
275 _
277
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 2, "lazy_grad_sum": false}
forward
1 1
434 _
436
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 209, "lazy_grad_sum": false}
forward
2 1
432 _
696 _
433
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 207, "lazy_grad_sum": false}
forward
2 1
436 _
721 _
435
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 210, "lazy_grad_sum": false}
forward
3 1
433 _
706 _
717 _
434
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 208, "lazy_grad_sum": false}
forward
1 1
437 _
440
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 213, "lazy_grad_sum": false}
forward
3 1
435 _
727 _
738 _
438
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 211, "lazy_grad_sum": false}
forward
2 1
438 _
268 _
437
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 212, "lazy_grad_sum": false}
forward
1 1
441 _
442
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 216, "lazy_grad_sum": false}
forward
3 1
439 _
750 _
760 _
441
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 215, "lazy_grad_sum": false}
forward
2 1
716 _
897 _
705
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 224, "lazy_grad_sum": false}
forward
1 1
681 _
689
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 219, "lazy_grad_sum": false}
forward
2 1
442 _
867 _
443
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 217, "lazy_grad_sum": false}
forward
2 1
689 _
881 _
682
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 220, "lazy_grad_sum": false}
forward
3 1
443 _
871 _
878 _
681
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 218, "lazy_grad_sum": false}
forward
1 1
448 _
449
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 276, "lazy_grad_sum": false}
forward
2 1
457 _
677 _
456
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 284, "lazy_grad_sum": false}
forward
1 1
451 _
453
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 279, "lazy_grad_sum": false}
forward
2 1
449 _
520 _
450
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 277, "lazy_grad_sum": false}
forward
2 1
453 _
533 _
452
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 280, "lazy_grad_sum": false}
forward
3 1
450 _
526 _
532 _
451
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 278, "lazy_grad_sum": false}
forward
1 1
454 _
457
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 283, "lazy_grad_sum": false}
forward
3 1
452 _
537 _
544 _
455
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 281, "lazy_grad_sum": false}
forward
2 1
455 _
447 _
454
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 282, "lazy_grad_sum": false}
forward
1 1
551 _
553
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 286, "lazy_grad_sum": false}
forward
3 1
456 _
686 _
692 _
551
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 285, "lazy_grad_sum": false}
forward
2 1
583 _
745 _
577
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 294, "lazy_grad_sum": false}
forward
1 1
506 _
517
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 463, "lazy_grad_sum": false}
forward
1 1
511 _
516
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 329, "lazy_grad_sum": false}
forward
1 1
508 _
518
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 143, "lazy_grad_sum": false}
forward
2 1
500 _
205 _
503
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 327, "lazy_grad_sum": false}
forward
3 1
499 _
825 _
830 _
509
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 461, "lazy_grad_sum": false}
forward
3 1
501 _
887 _
892 _
510
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 141, "lazy_grad_sum": false}
forward
2 1
516 _
217 _
514
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 330, "lazy_grad_sum": false}
forward
2 1
509 _
259 _
506
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 462, "lazy_grad_sum": false}
forward
2 1
510 _
164 _
508
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 142, "lazy_grad_sum": false}
forward
3 1
503 _
209 _
212 _
511
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 328, "lazy_grad_sum": false}
forward
1 1
522 _
527
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 466, "lazy_grad_sum": false}
forward
1 1
524 _
528
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 146, "lazy_grad_sum": false}
forward
1 1
521 _
531
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 333, "lazy_grad_sum": false}
forward
3 1
512 _
836 _
840 _
522
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 465, "lazy_grad_sum": false}
forward
3 1
513 _
903 _
908 _
524
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 145, "lazy_grad_sum": false}
forward
3 1
514 _
220 _
222 _
523
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 331, "lazy_grad_sum": false}
forward
2 1
523 _
394 _
521
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 332, "lazy_grad_sum": false}
forward
3 1
545 _
963 _
966 _
699
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 475, "lazy_grad_sum": false}
forward
2 1
627 _
67 _
622
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 154, "lazy_grad_sum": false}
forward
1 1
699 _
704
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 476, "lazy_grad_sum": false}
forward
1 1
534 _
539
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 336, "lazy_grad_sum": false}
forward
1 1
535 _
541
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 469, "lazy_grad_sum": false}
forward
1 1
536 _
543
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 149, "lazy_grad_sum": false}
forward
2 1
527 _
841 _
529
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 467, "lazy_grad_sum": false}
forward
3 1
525 _
227 _
229 _
534
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 335, "lazy_grad_sum": false}
forward
2 1
528 _
913 _
530
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 147, "lazy_grad_sum": false}
forward
2 1
541 _
953 _
538
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 470, "lazy_grad_sum": false}
forward
2 1
543 _
53 _
540
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 150, "lazy_grad_sum": false}
forward
3 1
529 _
845 _
849 _
535
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 468, "lazy_grad_sum": false}
forward
3 1
530 _
919 _
926 _
536
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 148, "lazy_grad_sum": false}
forward
2 1
714 _
365 _
709
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 344, "lazy_grad_sum": false}
forward
1 1
676 _
690
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 473, "lazy_grad_sum": false}
forward
1 1
680 _
688
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 339, "lazy_grad_sum": false}
forward
1 1
623 _
627
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 153, "lazy_grad_sum": false}
forward
2 1
539 _
332 _
542
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 337, "lazy_grad_sum": false}
forward
3 1
538 _
956 _
957 _
678
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 471, "lazy_grad_sum": false}
forward
3 1
540 _
57 _
63 _
625
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 151, "lazy_grad_sum": false}
forward
2 1
688 _
348 _
685
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 340, "lazy_grad_sum": false}
forward
2 1
678 _
517 _
676
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 472, "lazy_grad_sum": false}
forward
2 1
625 _
518 _
623
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 152, "lazy_grad_sum": false}
forward
3 1
542 _
338 _
345 _
680
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 338, "lazy_grad_sum": false}
forward
3 1
622 _
73 _
76 _
630
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 155, "lazy_grad_sum": false}
forward
2 1
586 _
144 _
584
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 84, "lazy_grad_sum": false}
forward
1 1
562 _
567
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 289, "lazy_grad_sum": false}
forward
1 1
561 _
563
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 396, "lazy_grad_sum": false}
forward
2 1
553 _
698 _
554
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 287, "lazy_grad_sum": false}
forward
2 1
567 _
719 _
565
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 290, "lazy_grad_sum": false}
forward
3 1
554 _
710 _
715 _
562
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 288, "lazy_grad_sum": false}
forward
1 1
568 _
571
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 79, "lazy_grad_sum": false}
forward
2 1
558 _
117 _
559
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 77, "lazy_grad_sum": false}
forward
2 1
596 _
196 _
591
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 404, "lazy_grad_sum": false}
forward
2 1
571 _
129 _
570
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 80, "lazy_grad_sum": false}
forward
3 1
559 _
120 _
126 _
568
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 78, "lazy_grad_sum": false}
forward
1 1
575 _
580
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 399, "lazy_grad_sum": false}
forward
1 1
573 _
583
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 293, "lazy_grad_sum": false}
forward
2 1
563 _
30 _
566
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 397, "lazy_grad_sum": false}
forward
3 1
565 _
729 _
737 _
574
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 291, "lazy_grad_sum": false}
forward
2 1
580 _
41 _
578
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 400, "lazy_grad_sum": false}
forward
2 1
574 _
457 _
573
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 292, "lazy_grad_sum": false}
forward
3 1
566 _
35 _
37 _
575
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 398, "lazy_grad_sum": false}
forward
1 1
579 _
586
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 83, "lazy_grad_sum": false}
forward
3 1
570 _
135 _
140 _
581
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 81, "lazy_grad_sum": false}
forward
2 1
581 _
548 _
579
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 82, "lazy_grad_sum": false}
forward
1 1
589 _
592
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 296, "lazy_grad_sum": false}
forward
1 1
587 _
596
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 403, "lazy_grad_sum": false}
forward
3 1
577 _
754 _
761 _
589
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 295, "lazy_grad_sum": false}
forward
3 1
578 _
45 _
49 _
588
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 401, "lazy_grad_sum": false}
forward
2 1
588 _
557 _
587
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 402, "lazy_grad_sum": false}
forward
1 1
595 _
672
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 86, "lazy_grad_sum": false}
forward
3 1
584 _
150 _
154 _
595
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 85, "lazy_grad_sum": false}
forward
2 1
775 _
857 _
773
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 304, "lazy_grad_sum": false}
forward
2 1
720 _
318 _
718
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 94, "lazy_grad_sum": false}
forward
1 1
679 _
684
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 406, "lazy_grad_sum": false}
forward
1 1
765 _
768
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 299, "lazy_grad_sum": false}
forward
3 1
591 _
199 _
201 _
679
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 405, "lazy_grad_sum": false}
forward
2 1
592 _
851 _
593
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 297, "lazy_grad_sum": false}
forward
2 1
768 _
854 _
767
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 300, "lazy_grad_sum": false}
forward
3 1
593 _
852 _
853 _
765
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 298, "lazy_grad_sum": false}
forward
3 1
673 _
307 _
309 _
691
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 88, "lazy_grad_sum": false}
forward
2 1
672 _
305 _
673
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 87, "lazy_grad_sum": false}
forward
2 1
739 _
224 _
731
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 414, "lazy_grad_sum": false}
forward
2 1
695 _
311 _
694
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 90, "lazy_grad_sum": false}
forward
1 1
630 _
632
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 156, "lazy_grad_sum": false}
forward
2 1
646 _
270 _
644
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 164, "lazy_grad_sum": false}
forward
1 1
636 _
639
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 159, "lazy_grad_sum": false}
forward
2 1
632 _
78 _
633
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 157, "lazy_grad_sum": false}
forward
2 1
639 _
93 _
638
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 160, "lazy_grad_sum": false}
forward
3 1
633 _
84 _
88 _
636
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 158, "lazy_grad_sum": false}
forward
1 1
642 _
646
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 163, "lazy_grad_sum": false}
forward
3 1
638 _
97 _
102 _
643
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 161, "lazy_grad_sum": false}
forward
2 1
643 _
627 _
642
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 162, "lazy_grad_sum": false}
forward
1 1
816 _
818
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 166, "lazy_grad_sum": false}
forward
3 1
644 _
273 _
276 _
816
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 165, "lazy_grad_sum": false}
forward
2 1
839 _
295 _
835
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 174, "lazy_grad_sum": false}
forward
1 1
277 _
605
MaxPooling2D
{"kh": 3, "kw": 3, "sy": 2, "sx": 2, "ph": 0, "pw": 0, "cover_all": true, "return_indices": false, "_used_cudnn": true, "_input_indexes_to_retain": [0], "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 3, "lazy_grad_sum": false}
forward
1 1
691 _
695
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 89, "lazy_grad_sum": false}
forward
1 1
697 _
716
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 223, "lazy_grad_sum": false}
forward
1 1
702 _
712
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 409, "lazy_grad_sum": false}
forward
2 1
684 _
204 _
687
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 407, "lazy_grad_sum": false}
forward
1 1
700 _
714
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 343, "lazy_grad_sum": false}
forward
3 1
685 _
354 _
359 _
701
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 341, "lazy_grad_sum": false}
forward
3 1
682 _
886 _
891 _
703
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 221, "lazy_grad_sum": false}
forward
2 1
712 _
216 _
711
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 410, "lazy_grad_sum": false}
forward
2 1
701 _
531 _
700
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 342, "lazy_grad_sum": false}
forward
2 1
703 _
440 _
697
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 222, "lazy_grad_sum": false}
forward
3 1
687 _
208 _
211 _
702
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 408, "lazy_grad_sum": false}
forward
1 1
707 _
720
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 93, "lazy_grad_sum": false}
forward
3 1
694 _
314 _
315 _
713
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 91, "lazy_grad_sum": false}
forward
1 1
218 _
46
AveragePooling2D
{"kh": 7, "kw": 7, "sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "return_indices": false, "_used_cudnn": true, "_input_indexes_to_retain": [0], "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 504, "lazy_grad_sum": false}
forward
2 1
713 _
586 _
707
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 92, "lazy_grad_sum": false}
forward
1 1
723 _
730
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 479, "lazy_grad_sum": false}
forward
1 1
726 _
732
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 226, "lazy_grad_sum": false}
forward
2 1
704 _
970 _
708
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 477, "lazy_grad_sum": false}
forward
1 1
725 _
733
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 346, "lazy_grad_sum": false}
forward
3 1
705 _
902 _
907 _
726
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 225, "lazy_grad_sum": false}
forward
1 1
722 _
739
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 413, "lazy_grad_sum": false}
forward
3 1
709 _
370 _
376 _
725
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 345, "lazy_grad_sum": false}
forward
2 1
730 _
979 _
728
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 480, "lazy_grad_sum": false}
forward
3 1
711 _
219 _
221 _
724
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 411, "lazy_grad_sum": false}
forward
3 1
708 _
972 _
974 _
723
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 478, "lazy_grad_sum": false}
forward
2 1
724 _
596 _
722
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 412, "lazy_grad_sum": false}
forward
1 1
736 _
740
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 96, "lazy_grad_sum": false}
forward
3 1
718 _
320 _
322 _
736
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 95, "lazy_grad_sum": false}
forward
2 1
877 _
469 _
866
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 354, "lazy_grad_sum": false}
forward
2 1
821 _
65 _
813
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 234, "lazy_grad_sum": false}
forward
2 1
883 _
468 _
873
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 104, "lazy_grad_sum": false}
forward
3 1
742 _
171 _
172 _
762
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 475, "lazy_grad_sum": false}
forward
1 1
746 _
751
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 416, "lazy_grad_sum": false}
forward
1 1
748 _
758
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 229, "lazy_grad_sum": false}
forward
1 1
747 _
756
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 349, "lazy_grad_sum": false}
forward
2 1
732 _
912 _
735
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 227, "lazy_grad_sum": false}
forward
3 1
728 _
982 _
984 _
744
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 481, "lazy_grad_sum": false}
forward
3 1
731 _
226 _
228 _
746
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 415, "lazy_grad_sum": false}
forward
2 1
733 _
380 _
734
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 347, "lazy_grad_sum": false}
forward
2 1
690 _
170 _
742
Convolution2DFunction
{"sy": 2, "sx": 2, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 474, "lazy_grad_sum": false}
forward
2 1
756 _
458 _
752
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 350, "lazy_grad_sum": false}
forward
2 1
758 _
52 _
757
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 230, "lazy_grad_sum": false}
forward
3 1
734 _
386 _
393 _
747
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 348, "lazy_grad_sum": false}
forward
1 1
759 _
863
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 99, "lazy_grad_sum": false}
forward
3 1
735 _
918 _
925 _
748
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 228, "lazy_grad_sum": false}
forward
2 1
740 _
324 _
741
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 97, "lazy_grad_sum": false}
forward
2 1
938 _
364 _
936
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 424, "lazy_grad_sum": false}
forward
2 1
863 _
459 _
753
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 100, "lazy_grad_sum": false}
forward
2 1
744 _
762 _
13
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 482, "lazy_grad_sum": false}
forward
3 1
741 _
326 _
329 _
759
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 98, "lazy_grad_sum": false}
forward
1 1
20 _
22
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 486, "lazy_grad_sum": false}
forward
3 1
749 _
178 _
180 _
20
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 485, "lazy_grad_sum": false}
forward
1 1
814 _
821
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 233, "lazy_grad_sum": false}
forward
1 1
928 _
931
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 419, "lazy_grad_sum": false}
forward
2 1
751 _
331 _
755
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 417, "lazy_grad_sum": false}
forward
1 1
868 _
877
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 353, "lazy_grad_sum": false}
forward
3 1
752 _
461 _
465 _
869
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 351, "lazy_grad_sum": false}
forward
3 1
757 _
56 _
62 _
815
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 231, "lazy_grad_sum": false}
forward
2 1
931 _
347 _
930
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 420, "lazy_grad_sum": false}
forward
2 1
869 _
714 _
868
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 352, "lazy_grad_sum": false}
forward
2 1
815 _
716 _
814
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 232, "lazy_grad_sum": false}
forward
3 1
755 _
337 _
344 _
928
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 418, "lazy_grad_sum": false}
forward
3 1
873 _
471 _
475 _
893
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 105, "lazy_grad_sum": false}
forward
3 1
753 _
462 _
464 _
875
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 101, "lazy_grad_sum": false}
forward
1 1
13 _
15
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 483, "lazy_grad_sum": false}
forward
3 1
813 _
72 _
75 _
823
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 235, "lazy_grad_sum": false}
forward
3 1
866 _
472 _
474 _
884
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 355, "lazy_grad_sum": false}
forward
2 1
875 _
720 _
874
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 102, "lazy_grad_sum": false}
forward
2 1
15 _
176 _
749
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 484, "lazy_grad_sum": false}
forward
2 1
766 _
769 _
772
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 12, "lazy_grad_sum": false}
forward
1 1
770 _
775
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 303, "lazy_grad_sum": false}
forward
3 1
767 _
855 _
856 _
771
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 301, "lazy_grad_sum": false}
forward
1 1
776 _
778
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 16, "lazy_grad_sum": false}
forward
2 1
771 _
583 _
770
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 302, "lazy_grad_sum": false}
forward
1 1
772 _
774
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 13, "lazy_grad_sum": false}
forward
2 1
774 _
976 _
763
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 14, "lazy_grad_sum": false}
forward
1 1
777 _
780
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 306, "lazy_grad_sum": false}
forward
3 1
773 _
858 _
859 _
777
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 305, "lazy_grad_sum": false}
forward
3 1
763 _
313 _
316 _
776
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 15, "lazy_grad_sum": false}
forward
2 1
58 _
460 _
51
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 24, "lazy_grad_sum": false}
forward
2 1
346 _
3 _
333
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 314, "lazy_grad_sum": false}
forward
1 1
782 _
785
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 19, "lazy_grad_sum": false}
forward
2 1
778 _
317 _
779
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 17, "lazy_grad_sum": false}
forward
1 1
783 _
787
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 309, "lazy_grad_sum": false}
forward
2 1
785 _
323 _
784
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 20, "lazy_grad_sum": false}
forward
2 1
780 _
860 _
781
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 307, "lazy_grad_sum": false}
forward
3 1
779 _
319 _
321 _
782
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 18, "lazy_grad_sum": false}
forward
2 1
787 _
0 _
786
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 310, "lazy_grad_sum": false}
forward
3 1
781 _
861 _
862 _
783
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 308, "lazy_grad_sum": false}
forward
1 1
50 _
58
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 23, "lazy_grad_sum": false}
forward
3 1
784 _
325 _
328 _
54
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 21, "lazy_grad_sum": false}
forward
1 1
334 _
346
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 313, "lazy_grad_sum": false}
forward
2 1
54 _
774 _
50
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 22, "lazy_grad_sum": false}
forward
3 1
786 _
1 _
2 _
335
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 311, "lazy_grad_sum": false}
forward
2 1
335 _
775 _
334
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 312, "lazy_grad_sum": false}
forward
1 1
64 _
69
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 26, "lazy_grad_sum": false}
forward
3 1
51 _
463 _
466 _
64
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 25, "lazy_grad_sum": false}
forward
3 1
333 _
4 _
5 _
352
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 315, "lazy_grad_sum": false}
forward
1 1
824 _
829
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 169, "lazy_grad_sum": false}
forward
1 1
823 _
826
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 236, "lazy_grad_sum": false}
forward
2 1
818 _
278 _
819
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 167, "lazy_grad_sum": false}
forward
2 1
829 _
286 _
827
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 170, "lazy_grad_sum": false}
forward
3 1
819 _
282 _
285 _
824
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 168, "lazy_grad_sum": false}
forward
2 1
850 _
232 _
846
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 244, "lazy_grad_sum": false}
forward
1 1
834 _
838
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 239, "lazy_grad_sum": false}
forward
1 1
832 _
839
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 173, "lazy_grad_sum": false}
forward
2 1
826 _
77 _
828
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 237, "lazy_grad_sum": false}
forward
3 1
827 _
289 _
293 _
833
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 171, "lazy_grad_sum": false}
forward
2 1
838 _
92 _
837
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 240, "lazy_grad_sum": false}
forward
2 1
833 _
646 _
832
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 172, "lazy_grad_sum": false}
forward
3 1
828 _
83 _
87 _
834
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 238, "lazy_grad_sum": false}
forward
1 1
844 _
847
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 176, "lazy_grad_sum": false}
forward
1 1
842 _
850
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 243, "lazy_grad_sum": false}
forward
3 1
835 _
299 _
303 _
844
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 175, "lazy_grad_sum": false}
forward
3 1
837 _
96 _
101 _
843
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 241, "lazy_grad_sum": false}
forward
2 1
843 _
821 _
842
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 242, "lazy_grad_sum": false}
forward
2 1
74 _
415 _
71
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 184, "lazy_grad_sum": false}
forward
1 1
14 _
17
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 246, "lazy_grad_sum": false}
forward
1 1
55 _
60
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 179, "lazy_grad_sum": false}
forward
3 1
846 _
235 _
239 _
14
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 245, "lazy_grad_sum": false}
forward
2 1
847 _
396 _
848
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 177, "lazy_grad_sum": false}
forward
2 1
60 _
405 _
59
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 180, "lazy_grad_sum": false}
forward
3 1
848 _
399 _
402 _
55
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 178, "lazy_grad_sum": false}
forward
2 1
38 _
260 _
36
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 254, "lazy_grad_sum": false}
forward
1 1
874 _
883
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 103, "lazy_grad_sum": false}
forward
1 1
884 _
888
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 356, "lazy_grad_sum": false}
forward
1 1
893 _
894
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 106, "lazy_grad_sum": false}
forward
2 1
924 _
649 _
917
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 364, "lazy_grad_sum": false}
forward
3 1
921 _
611 _
612 _
110
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 115, "lazy_grad_sum": false}
forward
1 1
899 _
904
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 359, "lazy_grad_sum": false}
forward
2 1
888 _
478 _
889
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 357, "lazy_grad_sum": false}
forward
1 1
110 _
115
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 116, "lazy_grad_sum": false}
forward
2 1
904 _
485 _
901
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 360, "lazy_grad_sum": false}
forward
3 1
889 _
481 _
483 _
899
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 358, "lazy_grad_sum": false}
forward
1 1
905 _
910
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 109, "lazy_grad_sum": false}
forward
2 1
894 _
477 _
895
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 107, "lazy_grad_sum": false}
forward
2 1
910 _
486 _
909
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 110, "lazy_grad_sum": false}
forward
3 1
895 _
480 _
484 _
905
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 108, "lazy_grad_sum": false}
forward
1 1
914 _
924
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 363, "lazy_grad_sum": false}
forward
3 1
901 _
488 _
491 _
915
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 361, "lazy_grad_sum": false}
forward
2 1
915 _
877 _
914
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 362, "lazy_grad_sum": false}
forward
1 1
920 _
104
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 113, "lazy_grad_sum": false}
forward
3 1
909 _
489 _
492 _
922
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 111, "lazy_grad_sum": false}
forward
2 1
922 _
883 _
920
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 112, "lazy_grad_sum": false}
forward
1 1
108 _
109
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 366, "lazy_grad_sum": false}
forward
3 1
917 _
651 _
653 _
108
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 365, "lazy_grad_sum": false}
forward
2 1
141 _
667 _
136
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 374, "lazy_grad_sum": false}
forward
1 1
934 _
938
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 423, "lazy_grad_sum": false}
forward
3 1
930 _
353 _
358 _
935
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 421, "lazy_grad_sum": false}
forward
2 1
935 _
739 _
934
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 422, "lazy_grad_sum": false}
forward
1 1
941 _
943
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 426, "lazy_grad_sum": false}
forward
3 1
936 _
368 _
375 _
941
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 425, "lazy_grad_sum": false}
forward
2 1
113 _
560 _
103
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 434, "lazy_grad_sum": false}
forward
1 1
947 _
950
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 429, "lazy_grad_sum": false}
forward
2 1
943 _
379 _
944
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 427, "lazy_grad_sum": false}
forward
2 1
950 _
546 _
949
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 430, "lazy_grad_sum": false}
forward
3 1
944 _
385 _
392 _
947
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 428, "lazy_grad_sum": false}
forward
1 1
105 _
113
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 433, "lazy_grad_sum": false}
forward
3 1
949 _
552 _
555 _
107
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 431, "lazy_grad_sum": false}
forward
2 1
107 _
938 _
105
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 432, "lazy_grad_sum": false}
forward
3 1
103 _
564 _
569 _
118
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 435, "lazy_grad_sum": false}
forward
3 1
955 _
626 _
628 _
958
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 38, "lazy_grad_sum": false}
forward
2 1
962 _
629 _
960
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 40, "lazy_grad_sum": false}
forward
1 1
958 _
962
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 39, "lazy_grad_sum": false}
forward
3 1
967 _
637 _
640 _
973
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 35, "lazy_grad_sum": false}
forward
3 1
960 _
631 _
634 _
969
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 41, "lazy_grad_sum": false}
forward
2 1
98 _
635 _
967
Convolution2DFunction
{"sy": 2, "sx": 2, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 34, "lazy_grad_sum": false}
forward
2 1
969 _
973 _
977
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 42, "lazy_grad_sum": false}
forward
1 1
983 _
168
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 46, "lazy_grad_sum": false}
forward
1 1
977 _
980
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 43, "lazy_grad_sum": false}
forward
2 1
980 _
641 _
965
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 44, "lazy_grad_sum": false}
forward
3 1
965 _
645 _
647 _
983
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 45, "lazy_grad_sum": false}
forward
2 1
183 _
801 _
181
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 54, "lazy_grad_sum": false}
forward
3 1
169 _
790 _
792 _
173
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 48, "lazy_grad_sum": false}
forward
2 1
168 _
788 _
169
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 47, "lazy_grad_sum": false}
forward
2 1
175 _
794 _
174
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 50, "lazy_grad_sum": false}
backward
2 1
27 gradient
27 output
24
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 249, "lazy_grad_sum": false}
backward
3 2
18 gradient
17 input
241 input
17
241
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 247, "lazy_grad_sum": false}
backward
3 2
42 gradient
44 input
397 input
44
397
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 494, "lazy_grad_sum": false}
backward
3 2
26 gradient
27 input
250 input
27
250
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 250, "lazy_grad_sum": false}
backward
4 3
24 gradient
18 input
244 input
249 input
18
244
249
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 248, "lazy_grad_sum": false}
backward
2 1
33 gradient
33 output
29
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 489, "lazy_grad_sum": false}
backward
3 2
23 gradient
22 input
182 input
22
182
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 487, "lazy_grad_sum": false}
backward
3 2
31 gradient
33 input
189 input
33
189
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 490, "lazy_grad_sum": false}
backward
4 3
29 gradient
23 input
184 input
186 input
23
184
186
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 488, "lazy_grad_sum": false}
backward
2 1
38 gradient
38 output
32
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 253, "lazy_grad_sum": false}
backward
4 3
34 gradient
26 input
254 input
258 input
26
254
258
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 251, "lazy_grad_sum": false}
backward
3 2
32 gradient
34 input
850 input
34
850
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 252, "lazy_grad_sum": false}
backward
2 1
44 gradient
44 output
39
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 493, "lazy_grad_sum": false}
backward
4 3
40 gradient
31 input
190 input
192 input
31
190
192
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 491, "lazy_grad_sum": false}
backward
3 2
39 gradient
40 input
15 input
40
15
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 492, "lazy_grad_sum": false}
backward
2 1
47 gradient
47 output
43
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 256, "lazy_grad_sum": false}
backward
4 3
43 gradient
36 input
266 input
269 input
36
266
269
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 255, "lazy_grad_sum": false}
backward
3 2
281 gradient
284 input
414 input
284
414
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 264, "lazy_grad_sum": false}
backward
2 1
195 gradient
195 output
194
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 496, "lazy_grad_sum": false}
backward
4 3
194 gradient
42 input
400 input
403 input
42
400
403
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 495, "lazy_grad_sum": false}
backward
2 1
274 gradient
274 output
271
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 259, "lazy_grad_sum": false}
backward
3 2
48 gradient
47 input
395 input
47
395
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 257, "lazy_grad_sum": false}
backward
4 3
214 gradient
210 input
422 input
425 input
210
422
425
LinearFunction
{"_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_config_use_ideep": "never", "_output_count": 1, "rank": 506, "lazy_grad_sum": false}
backward
3 2
272 gradient
274 input
404 input
274
404
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 260, "lazy_grad_sum": false}
backward
4 3
271 gradient
48 input
398 input
401 input
48
398
401
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 258, "lazy_grad_sum": false}
backward
4 3
203 gradient
198 input
409 input
412 input
198
409
412
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 498, "lazy_grad_sum": false}
backward
3 2
198 gradient
195 input
406 input
195
406
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 497, "lazy_grad_sum": false}
backward
2 1
74 gradient
74 output
66
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 183, "lazy_grad_sum": false}
backward
4 3
68 gradient
59 input
408 input
411 input
59
408
411
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 181, "lazy_grad_sum": false}
backward
3 2
66 gradient
68 input
839 input
68
839
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 182, "lazy_grad_sum": false}
backward
4 3
952 gradient
91 input
490 input
493 input
91
490
493
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 35, "lazy_grad_sum": false}
backward
2 1
954 gradient
954 output
952
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 36, "lazy_grad_sum": false}
backward
2 1
82 gradient
82 output
79
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 29, "lazy_grad_sum": false}
backward
3 2
70 gradient
69 input
467 input
69
467
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 27, "lazy_grad_sum": false}
backward
2 1
85 gradient
85 output
80
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 186, "lazy_grad_sum": false}
backward
4 3
80 gradient
71 input
418 input
421 input
71
418
421
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 185, "lazy_grad_sum": false}
backward
3 2
81 gradient
82 input
476 input
82
476
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 30, "lazy_grad_sum": false}
backward
4 3
79 gradient
70 input
470 input
473 input
70
470
473
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 28, "lazy_grad_sum": false}
backward
3 2
230 gradient
238 input
600 input
238
600
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 194, "lazy_grad_sum": false}
backward
2 1
98 gradient
98 output
90
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 33, "lazy_grad_sum": false}
backward
4 3
94 gradient
81 input
479 input
482 input
81
479
482
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 31, "lazy_grad_sum": false}
backward
2 1
100 gradient
100 output
95
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 189, "lazy_grad_sum": false}
backward
3 2
86 gradient
85 input
424 input
85
424
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 187, "lazy_grad_sum": false}
backward
3 2
90 gradient
94 input
58 input
94
58
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 32, "lazy_grad_sum": false}
backward
3 2
99 gradient
100 input
597 input
100
597
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 190, "lazy_grad_sum": false}
backward
4 3
95 gradient
86 input
427 input
429 input
86
427
429
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 188, "lazy_grad_sum": false}
backward
2 1
238 gradient
238 output
231
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 193, "lazy_grad_sum": false}
backward
4 3
234 gradient
99 input
598 input
599 input
99
598
599
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 191, "lazy_grad_sum": false}
backward
3 2
231 gradient
234 input
74 input
234
74
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 192, "lazy_grad_sum": false}
backward
3 2
921 gradient
104 input
610 input
104
610
Convolution2DFunction
{"sy": 2, "sx": 2, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 114, "lazy_grad_sum": false}
backward
4 3
242 gradient
230 input
601 input
602 input
230
601
602
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 195, "lazy_grad_sum": false}
backward
3 2
955 gradient
954 input
624 input
954
624
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 37, "lazy_grad_sum": false}
backward
2 1
210 gradient
46 input
46
Reshape
{"shape": [32, 2048], "_cnt": 0, "_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 505, "lazy_grad_sum": false}
backward
2 1
124 gradient
124 output
119
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 369, "lazy_grad_sum": false}
backward
2 1
121 gradient
121 output
118
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 436, "lazy_grad_sum": false}
backward
3 2
112 gradient
109 input
655 input
109
655
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 367, "lazy_grad_sum": false}
backward
3 2
545 gradient
690 input
959 input
690
959
Convolution2DFunction
{"sy": 2, "sx": 2, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 474, "lazy_grad_sum": false}
backward
3 2
122 gradient
124 input
661 input
124
661
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 370, "lazy_grad_sum": false}
backward
2 1
128 gradient
128 output
125
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 119, "lazy_grad_sum": false}
backward
4 3
119 gradient
112 input
657 input
659 input
112
657
659
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 368, "lazy_grad_sum": false}
backward
3 2
116 gradient
115 input
613 input
115
613
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 117, "lazy_grad_sum": false}
backward
3 2
147 gradient
152 input
648 input
152
648
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 444, "lazy_grad_sum": false}
backward
3 2
127 gradient
128 input
616 input
128
616
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 120, "lazy_grad_sum": false}
backward
4 3
125 gradient
116 input
614 input
615 input
116
614
615
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 118, "lazy_grad_sum": false}
backward
2 1
139 gradient
139 output
132
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 439, "lazy_grad_sum": false}
backward
2 1
141 gradient
141 output
130
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 373, "lazy_grad_sum": false}
backward
3 2
123 gradient
121 input
572 input
121
572
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 437, "lazy_grad_sum": false}
backward
4 3
131 gradient
122 input
663 input
665 input
122
663
665
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 371, "lazy_grad_sum": false}
backward
3 2
137 gradient
139 input
585 input
139
585
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 440, "lazy_grad_sum": false}
backward
3 2
130 gradient
131 input
924 input
131
924
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 372, "lazy_grad_sum": false}
backward
4 3
143 gradient
134 input
620 input
621 input
134
620
621
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 115, "lazy_grad_sum": false}
backward
4 3
132 gradient
123 input
576 input
582 input
123
576
582
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 438, "lazy_grad_sum": false}
backward
4 3
138 gradient
127 input
617 input
618 input
127
617
618
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 121, "lazy_grad_sum": false}
backward
3 2
134 gradient
104 input
619 input
104
619
Convolution2DFunction
{"sy": 2, "sx": 2, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 114, "lazy_grad_sum": false}
backward
2 1
149 gradient
149 output
146
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 376, "lazy_grad_sum": false}
backward
2 1
152 gradient
152 output
142
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 443, "lazy_grad_sum": false}
backward
3 2
148 gradient
138 input
143 input
138
143
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 122, "lazy_grad_sum": false}
backward
4 3
146 gradient
136 input
669 input
671 input
136
669
671
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 375, "lazy_grad_sum": false}
backward
4 3
145 gradient
137 input
590 input
594 input
137
590
594
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 441, "lazy_grad_sum": false}
backward
3 2
142 gradient
145 input
113 input
145
113
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 442, "lazy_grad_sum": false}
backward
2 1
156 gradient
156 output
155
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 126, "lazy_grad_sum": false}
backward
3 2
355 gradient
361 input
896 input
361
896
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 384, "lazy_grad_sum": false}
backward
2 1
153 gradient
153 output
148
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 123, "lazy_grad_sum": false}
backward
2 1
236 gradient
236 output
233
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 446, "lazy_grad_sum": false}
backward
3 2
133 gradient
153 input
789 input
153
789
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 124, "lazy_grad_sum": false}
backward
2 1
342 gradient
342 output
336
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 379, "lazy_grad_sum": false}
backward
4 3
233 gradient
147 input
650 input
652 input
147
650
652
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 445, "lazy_grad_sum": false}
backward
3 2
151 gradient
149 input
865 input
149
865
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 377, "lazy_grad_sum": false}
backward
3 2
340 gradient
342 input
880 input
342
880
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 380, "lazy_grad_sum": false}
backward
4 3
155 gradient
133 input
791 input
793 input
133
791
793
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 125, "lazy_grad_sum": false}
backward
4 3
336 gradient
151 input
870 input
876 input
151
870
876
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 378, "lazy_grad_sum": false}
backward
3 2
255 gradient
259 input
666 input
259
666
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 454, "lazy_grad_sum": false}
backward
3 2
163 gradient
164 input
807 input
164
807
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 134, "lazy_grad_sum": false}
backward
2 1
160 gradient
160 output
158
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 129, "lazy_grad_sum": false}
backward
3 2
157 gradient
156 input
795 input
156
795
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 127, "lazy_grad_sum": false}
backward
3 2
159 gradient
160 input
800 input
160
800
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 130, "lazy_grad_sum": false}
backward
4 3
158 gradient
157 input
797 input
799 input
157
797
799
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 128, "lazy_grad_sum": false}
backward
2 1
164 gradient
164 output
161
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 133, "lazy_grad_sum": false}
backward
4 3
162 gradient
159 input
802 input
804 input
159
802
804
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 131, "lazy_grad_sum": false}
backward
3 2
161 gradient
162 input
153 input
162
153
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 132, "lazy_grad_sum": false}
backward
2 1
166 gradient
166 output
165
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 136, "lazy_grad_sum": false}
backward
4 3
165 gradient
163 input
809 input
811 input
163
809
811
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 135, "lazy_grad_sum": false}
backward
3 2
513 gradient
518 input
898 input
518
898
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 144, "lazy_grad_sum": false}
backward
2 1
504 gradient
504 output
497
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 139, "lazy_grad_sum": false}
backward
3 2
167 gradient
166 input
864 input
166
864
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 137, "lazy_grad_sum": false}
backward
3 2
501 gradient
504 input
882 input
504
882
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 140, "lazy_grad_sum": false}
backward
4 3
497 gradient
167 input
872 input
879 input
167
872
879
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 138, "lazy_grad_sum": false}
backward
2 1
175 gradient
175 output
173
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 49, "lazy_grad_sum": false}
backward
2 1
183 gradient
183 output
177
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 53, "lazy_grad_sum": false}
backward
4 3
179 gradient
174 input
796 input
798 input
174
796
798
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 51, "lazy_grad_sum": false}
backward
3 2
177 gradient
179 input
980 input
179
980
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 52, "lazy_grad_sum": false}
backward
2 1
187 gradient
187 output
185
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 56, "lazy_grad_sum": false}
backward
4 3
185 gradient
181 input
803 input
805 input
181
803
805
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 55, "lazy_grad_sum": false}
backward
3 2
339 gradient
349 input
933 input
349
933
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 64, "lazy_grad_sum": false}
backward
2 1
330 gradient
330 output
193
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 59, "lazy_grad_sum": false}
backward
3 2
188 gradient
187 input
806 input
187
806
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 57, "lazy_grad_sum": false}
backward
3 2
191 gradient
330 input
927 input
330
927
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 60, "lazy_grad_sum": false}
backward
4 3
193 gradient
188 input
808 input
810 input
188
808
810
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 58, "lazy_grad_sum": false}
backward
4 3
360 gradient
339 input
937 input
939 input
339
937
939
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 65, "lazy_grad_sum": false}
backward
4 3
343 gradient
191 input
929 input
932 input
191
929
932
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 61, "lazy_grad_sum": false}
backward
3 2
341 gradient
343 input
183 input
343
183
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 62, "lazy_grad_sum": false}
backward
3 2
206 gradient
207 input
413 input
207
413
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 500, "lazy_grad_sum": false}
backward
2 1
207 gradient
207 output
203
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 499, "lazy_grad_sum": false}
backward
2 1
218 gradient
218 output
213
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 503, "lazy_grad_sum": false}
backward
4 3
215 gradient
206 input
416 input
419 input
206
416
419
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 501, "lazy_grad_sum": false}
backward
3 2
213 gradient
215 input
44 input
215
44
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 502, "lazy_grad_sum": false}
backward
2 1
247 gradient
247 output
243
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 449, "lazy_grad_sum": false}
backward
3 2
237 gradient
236 input
654 input
236
654
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 447, "lazy_grad_sum": false}
backward
2 1
245 gradient
245 output
242
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 196, "lazy_grad_sum": false}
backward
3 2
246 gradient
247 input
660 input
247
660
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 450, "lazy_grad_sum": false}
backward
4 3
243 gradient
237 input
656 input
658 input
237
656
658
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 448, "lazy_grad_sum": false}
backward
3 2
264 gradient
268 input
675 input
268
675
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 204, "lazy_grad_sum": false}
backward
2 1
257 gradient
257 output
253
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 199, "lazy_grad_sum": false}
backward
2 1
259 gradient
259 output
251
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 453, "lazy_grad_sum": false}
backward
3 2
248 gradient
245 input
603 input
245
603
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 197, "lazy_grad_sum": false}
backward
4 3
252 gradient
246 input
662 input
664 input
246
662
664
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 451, "lazy_grad_sum": false}
backward
3 2
256 gradient
257 input
607 input
257
607
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 200, "lazy_grad_sum": false}
backward
3 2
251 gradient
252 input
152 input
252
152
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 452, "lazy_grad_sum": false}
backward
4 3
253 gradient
248 input
604 input
606 input
248
604
606
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 198, "lazy_grad_sum": false}
backward
2 1
265 gradient
265 output
262
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 456, "lazy_grad_sum": false}
backward
2 1
268 gradient
268 output
261
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 203, "lazy_grad_sum": false}
backward
4 3
262 gradient
255 input
668 input
670 input
255
668
670
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 455, "lazy_grad_sum": false}
backward
4 3
263 gradient
256 input
608 input
609 input
256
608
609
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 201, "lazy_grad_sum": false}
backward
3 2
261 gradient
263 input
238 input
263
238
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 202, "lazy_grad_sum": false}
backward
3 2
512 gradient
517 input
831 input
517
831
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 464, "lazy_grad_sum": false}
backward
2 1
432 gradient
432 output
431
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 206, "lazy_grad_sum": false}
backward
2 1
502 gradient
502 output
496
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 459, "lazy_grad_sum": false}
backward
4 3
431 gradient
264 input
683 input
693 input
264
683
693
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 205, "lazy_grad_sum": false}
backward
3 2
267 gradient
265 input
812 input
265
812
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 457, "lazy_grad_sum": false}
backward
3 2
499 gradient
502 input
822 input
502
822
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 460, "lazy_grad_sum": false}
backward
4 3
496 gradient
267 input
817 input
820 input
267
817
820
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 458, "lazy_grad_sum": false}
backward
3 2
439 gradient
440 input
743 input
440
743
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 214, "lazy_grad_sum": false}
backward
2 1
284 gradient
284 output
279
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 263, "lazy_grad_sum": false}
backward
3 2
283 gradient
605 input
971 input
605
971
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 4, "lazy_grad_sum": false}
backward
4 3
280 gradient
272 input
407 input
410 input
272
407
410
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 261, "lazy_grad_sum": false}
backward
3 2
279 gradient
280 input
38 input
280
38
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 262, "lazy_grad_sum": false}
backward
2 1
290 gradient
290 output
287
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 266, "lazy_grad_sum": false}
backward
4 3
287 gradient
281 input
417 input
420 input
281
417
420
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 265, "lazy_grad_sum": false}
backward
3 2
91 gradient
98 input
487 input
98
487
Convolution2DFunction
{"sy": 2, "sx": 2, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 34, "lazy_grad_sum": false}
backward
4 3
288 gradient
283 input
975 input
978 input
283
975
978
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 5, "lazy_grad_sum": false}
backward
2 1
292 gradient
292 output
288
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 6, "lazy_grad_sum": false}
backward
3 2
444 gradient
447 input
507 input
447
507
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 274, "lazy_grad_sum": false}
backward
2 1
300 gradient
300 output
296
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 269, "lazy_grad_sum": false}
backward
3 2
291 gradient
290 input
423 input
290
423
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 267, "lazy_grad_sum": false}
backward
2 1
302 gradient
302 output
297
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 9, "lazy_grad_sum": false}
backward
3 2
294 gradient
292 input
981 input
292
981
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 7, "lazy_grad_sum": false}
backward
3 2
298 gradient
300 input
494 input
300
494
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 270, "lazy_grad_sum": false}
backward
3 2
301 gradient
302 input
306 input
302
306
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 10, "lazy_grad_sum": false}
backward
4 3
296 gradient
291 input
426 input
428 input
291
426
428
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 268, "lazy_grad_sum": false}
backward
4 3
297 gradient
294 input
985 input
304 input
294
985
304
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 8, "lazy_grad_sum": false}
backward
2 1
447 gradient
447 output
445
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 273, "lazy_grad_sum": false}
backward
4 3
769 gradient
764 input
240 input
327 input
764
240
327
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 5, "lazy_grad_sum": false}
backward
4 3
446 gradient
298 input
498 input
505 input
298
498
505
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 271, "lazy_grad_sum": false}
backward
4 3
766 gradient
301 input
308 input
310 input
301
308
310
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 11, "lazy_grad_sum": false}
backward
3 2
445 gradient
446 input
284 input
446
284
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 272, "lazy_grad_sum": false}
backward
3 2
764 gradient
605 input
312 input
605
312
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 4, "lazy_grad_sum": false}
backward
4 3
448 gradient
444 input
515 input
519 input
444
515
519
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 275, "lazy_grad_sum": false}
backward
2 1
361 gradient
361 output
350
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 383, "lazy_grad_sum": false}
backward
2 1
349 gradient
349 output
341
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 63, "lazy_grad_sum": false}
backward
2 1
356 gradient
356 output
352
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 316, "lazy_grad_sum": false}
backward
4 3
351 gradient
340 input
885 input
890 input
340
885
890
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 381, "lazy_grad_sum": false}
backward
3 2
350 gradient
351 input
141 input
351
141
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 382, "lazy_grad_sum": false}
backward
2 1
362 gradient
362 output
360
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 66, "lazy_grad_sum": false}
backward
3 2
389 gradient
394 input
197 input
394
197
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 324, "lazy_grad_sum": false}
backward
3 2
384 gradient
548 input
106 input
548
106
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 74, "lazy_grad_sum": false}
backward
2 1
369 gradient
369 output
366
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 386, "lazy_grad_sum": false}
backward
2 1
373 gradient
373 output
367
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 319, "lazy_grad_sum": false}
backward
4 3
366 gradient
355 input
900 input
906 input
355
900
906
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 385, "lazy_grad_sum": false}
backward
3 2
357 gradient
356 input
6 input
356
6
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 317, "lazy_grad_sum": false}
backward
3 2
372 gradient
373 input
9 input
373
9
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 320, "lazy_grad_sum": false}
backward
4 3
367 gradient
357 input
7 input
8 input
357
7
8
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 318, "lazy_grad_sum": false}
backward
2 1
378 gradient
378 output
374
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 69, "lazy_grad_sum": false}
backward
3 2
363 gradient
362 input
940 input
362
940
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 67, "lazy_grad_sum": false}
backward
3 2
547 gradient
557 input
21 input
557
21
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 394, "lazy_grad_sum": false}
backward
3 2
377 gradient
378 input
946 input
378
946
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 70, "lazy_grad_sum": false}
backward
4 3
374 gradient
363 input
942 input
945 input
363
942
945
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 68, "lazy_grad_sum": false}
backward
2 1
394 gradient
394 output
381
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 323, "lazy_grad_sum": false}
backward
2 1
390 gradient
390 output
383
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 389, "lazy_grad_sum": false}
backward
3 2
371 gradient
369 input
911 input
369
911
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 387, "lazy_grad_sum": false}
backward
4 3
382 gradient
372 input
10 input
11 input
372
10
11
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 321, "lazy_grad_sum": false}
backward
3 2
388 gradient
390 input
12 input
390
12
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 390, "lazy_grad_sum": false}
backward
3 2
381 gradient
382 input
346 input
382
346
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 322, "lazy_grad_sum": false}
backward
4 3
383 gradient
371 input
916 input
923 input
371
916
923
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 388, "lazy_grad_sum": false}
backward
2 1
548 gradient
548 output
387
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 73, "lazy_grad_sum": false}
backward
4 3
391 gradient
377 input
948 input
951 input
377
948
951
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 71, "lazy_grad_sum": false}
backward
3 2
387 gradient
391 input
349 input
391
349
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 72, "lazy_grad_sum": false}
backward
2 1
500 gradient
500 output
495
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 326, "lazy_grad_sum": false}
backward
2 1
557 gradient
557 output
549
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 393, "lazy_grad_sum": false}
backward
4 3
495 gradient
389 input
200 input
202 input
389
200
202
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 325, "lazy_grad_sum": false}
backward
4 3
550 gradient
388 input
16 input
19 input
388
16
19
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 391, "lazy_grad_sum": false}
backward
3 2
549 gradient
550 input
361 input
550
361
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 392, "lazy_grad_sum": false}
backward
2 1
558 gradient
558 output
556
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 76, "lazy_grad_sum": false}
backward
4 3
556 gradient
384 input
111 input
114 input
384
111
114
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 75, "lazy_grad_sum": false}
backward
3 2
525 gradient
531 input
225 input
531
225
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 334, "lazy_grad_sum": false}
backward
4 3
561 gradient
547 input
25 input
28 input
547
25
28
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 395, "lazy_grad_sum": false}
backward
3 2
223 gradient
214 input
61 input
214
61
SoftmaxCrossEntropy
{"normalize": true, "cache_score": true, "class_weight": null, "ignore_label": -1, "reduce": "mean", "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 507, "lazy_grad_sum": false}
backward
4 3
674 gradient
89 input
430 input
961 input
89
430
961
Convolution2DFunction
{"sy": 2, "sx": 2, "ph": 3, "pw": 3, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 0, "lazy_grad_sum": false}
backward
4 3
275 gradient
674 input
964 input
968 input
674
964
968
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 1, "lazy_grad_sum": false}
backward
2 1
277 gradient
277 output
275
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 2, "lazy_grad_sum": false}
backward
2 1
436 gradient
436 output
434
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 209, "lazy_grad_sum": false}
backward
3 2
433 gradient
432 input
696 input
432
696
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 207, "lazy_grad_sum": false}
backward
3 2
435 gradient
436 input
721 input
436
721
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 210, "lazy_grad_sum": false}
backward
4 3
434 gradient
433 input
706 input
717 input
433
706
717
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 208, "lazy_grad_sum": false}
backward
2 1
440 gradient
440 output
437
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 213, "lazy_grad_sum": false}
backward
4 3
438 gradient
435 input
727 input
738 input
435
727
738
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 211, "lazy_grad_sum": false}
backward
3 2
437 gradient
438 input
268 input
438
268
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 212, "lazy_grad_sum": false}
backward
2 1
442 gradient
442 output
441
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 216, "lazy_grad_sum": false}
backward
4 3
441 gradient
439 input
750 input
760 input
439
750
760
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 215, "lazy_grad_sum": false}
backward
3 2
705 gradient
716 input
897 input
716
897
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 224, "lazy_grad_sum": false}
backward
2 1
689 gradient
689 output
681
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 219, "lazy_grad_sum": false}
backward
3 2
443 gradient
442 input
867 input
442
867
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 217, "lazy_grad_sum": false}
backward
3 2
682 gradient
689 input
881 input
689
881
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 220, "lazy_grad_sum": false}
backward
4 3
681 gradient
443 input
871 input
878 input
443
871
878
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 218, "lazy_grad_sum": false}
backward
2 1
449 gradient
449 output
448
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 276, "lazy_grad_sum": false}
backward
3 2
456 gradient
457 input
677 input
457
677
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 284, "lazy_grad_sum": false}
backward
2 1
453 gradient
453 output
451
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 279, "lazy_grad_sum": false}
backward
3 2
450 gradient
449 input
520 input
449
520
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 277, "lazy_grad_sum": false}
backward
3 2
452 gradient
453 input
533 input
453
533
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 280, "lazy_grad_sum": false}
backward
4 3
451 gradient
450 input
526 input
532 input
450
526
532
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 278, "lazy_grad_sum": false}
backward
2 1
457 gradient
457 output
454
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 283, "lazy_grad_sum": false}
backward
4 3
455 gradient
452 input
537 input
544 input
452
537
544
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 281, "lazy_grad_sum": false}
backward
3 2
454 gradient
455 input
447 input
455
447
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 282, "lazy_grad_sum": false}
backward
2 1
553 gradient
553 output
551
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 286, "lazy_grad_sum": false}
backward
4 3
551 gradient
456 input
686 input
692 input
456
686
692
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 285, "lazy_grad_sum": false}
backward
3 2
577 gradient
583 input
745 input
583
745
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 294, "lazy_grad_sum": false}
backward
2 1
517 gradient
517 output
506
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 463, "lazy_grad_sum": false}
backward
2 1
516 gradient
516 output
511
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 329, "lazy_grad_sum": false}
backward
2 1
518 gradient
518 output
508
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 143, "lazy_grad_sum": false}
backward
3 2
503 gradient
500 input
205 input
500
205
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 327, "lazy_grad_sum": false}
backward
4 3
509 gradient
499 input
825 input
830 input
499
825
830
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 461, "lazy_grad_sum": false}
backward
4 3
510 gradient
501 input
887 input
892 input
501
887
892
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 141, "lazy_grad_sum": false}
backward
3 2
514 gradient
516 input
217 input
516
217
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 330, "lazy_grad_sum": false}
backward
3 2
506 gradient
509 input
259 input
509
259
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 462, "lazy_grad_sum": false}
backward
3 2
508 gradient
510 input
164 input
510
164
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 142, "lazy_grad_sum": false}
backward
4 3
511 gradient
503 input
209 input
212 input
503
209
212
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 328, "lazy_grad_sum": false}
backward
2 1
527 gradient
527 output
522
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 466, "lazy_grad_sum": false}
backward
2 1
528 gradient
528 output
524
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 146, "lazy_grad_sum": false}
backward
2 1
531 gradient
531 output
521
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 333, "lazy_grad_sum": false}
backward
4 3
522 gradient
512 input
836 input
840 input
512
836
840
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 465, "lazy_grad_sum": false}
backward
4 3
524 gradient
513 input
903 input
908 input
513
903
908
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 145, "lazy_grad_sum": false}
backward
4 3
523 gradient
514 input
220 input
222 input
514
220
222
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 331, "lazy_grad_sum": false}
backward
3 2
521 gradient
523 input
394 input
523
394
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 332, "lazy_grad_sum": false}
backward
4 3
699 gradient
545 input
963 input
966 input
545
963
966
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 475, "lazy_grad_sum": false}
backward
3 2
622 gradient
627 input
67 input
627
67
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 154, "lazy_grad_sum": false}
backward
2 1
704 gradient
704 output
699
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 476, "lazy_grad_sum": false}
backward
2 1
539 gradient
539 output
534
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 336, "lazy_grad_sum": false}
backward
2 1
541 gradient
541 output
535
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 469, "lazy_grad_sum": false}
backward
2 1
543 gradient
543 output
536
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 149, "lazy_grad_sum": false}
backward
3 2
529 gradient
527 input
841 input
527
841
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 467, "lazy_grad_sum": false}
backward
4 3
534 gradient
525 input
227 input
229 input
525
227
229
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 335, "lazy_grad_sum": false}
backward
3 2
530 gradient
528 input
913 input
528
913
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 147, "lazy_grad_sum": false}
backward
3 2
538 gradient
541 input
953 input
541
953
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 470, "lazy_grad_sum": false}
backward
3 2
540 gradient
543 input
53 input
543
53
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 150, "lazy_grad_sum": false}
backward
4 3
535 gradient
529 input
845 input
849 input
529
845
849
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 468, "lazy_grad_sum": false}
backward
4 3
536 gradient
530 input
919 input
926 input
530
919
926
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 148, "lazy_grad_sum": false}
backward
3 2
709 gradient
714 input
365 input
714
365
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 344, "lazy_grad_sum": false}
backward
2 1
690 gradient
690 output
676
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 473, "lazy_grad_sum": false}
backward
2 1
688 gradient
688 output
680
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 339, "lazy_grad_sum": false}
backward
2 1
627 gradient
627 output
623
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 153, "lazy_grad_sum": false}
backward
3 2
542 gradient
539 input
332 input
539
332
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 337, "lazy_grad_sum": false}
backward
4 3
678 gradient
538 input
956 input
957 input
538
956
957
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 471, "lazy_grad_sum": false}
backward
4 3
625 gradient
540 input
57 input
63 input
540
57
63
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 151, "lazy_grad_sum": false}
backward
3 2
685 gradient
688 input
348 input
688
348
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 340, "lazy_grad_sum": false}
backward
3 2
676 gradient
678 input
517 input
678
517
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 472, "lazy_grad_sum": false}
backward
3 2
623 gradient
625 input
518 input
625
518
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 152, "lazy_grad_sum": false}
backward
4 3
680 gradient
542 input
338 input
345 input
542
338
345
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 338, "lazy_grad_sum": false}
backward
4 3
630 gradient
622 input
73 input
76 input
622
73
76
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 155, "lazy_grad_sum": false}
backward
3 2
584 gradient
586 input
144 input
586
144
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 84, "lazy_grad_sum": false}
backward
2 1
567 gradient
567 output
562
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 289, "lazy_grad_sum": false}
backward
2 1
563 gradient
563 output
561
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 396, "lazy_grad_sum": false}
backward
3 2
554 gradient
553 input
698 input
553
698
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 287, "lazy_grad_sum": false}
backward
3 2
565 gradient
567 input
719 input
567
719
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 290, "lazy_grad_sum": false}
backward
4 3
562 gradient
554 input
710 input
715 input
554
710
715
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 288, "lazy_grad_sum": false}
backward
2 1
571 gradient
571 output
568
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 79, "lazy_grad_sum": false}
backward
3 2
559 gradient
558 input
117 input
558
117
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 77, "lazy_grad_sum": false}
backward
3 2
591 gradient
596 input
196 input
596
196
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 404, "lazy_grad_sum": false}
backward
3 2
570 gradient
571 input
129 input
571
129
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 80, "lazy_grad_sum": false}
backward
4 3
568 gradient
559 input
120 input
126 input
559
120
126
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 78, "lazy_grad_sum": false}
backward
2 1
580 gradient
580 output
575
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 399, "lazy_grad_sum": false}
backward
2 1
583 gradient
583 output
573
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 293, "lazy_grad_sum": false}
backward
3 2
566 gradient
563 input
30 input
563
30
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 397, "lazy_grad_sum": false}
backward
4 3
574 gradient
565 input
729 input
737 input
565
729
737
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 291, "lazy_grad_sum": false}
backward
3 2
578 gradient
580 input
41 input
580
41
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 400, "lazy_grad_sum": false}
backward
3 2
573 gradient
574 input
457 input
574
457
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 292, "lazy_grad_sum": false}
backward
4 3
575 gradient
566 input
35 input
37 input
566
35
37
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 398, "lazy_grad_sum": false}
backward
2 1
586 gradient
586 output
579
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 83, "lazy_grad_sum": false}
backward
4 3
581 gradient
570 input
135 input
140 input
570
135
140
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 81, "lazy_grad_sum": false}
backward
3 2
579 gradient
581 input
548 input
581
548
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 82, "lazy_grad_sum": false}
backward
2 1
592 gradient
592 output
589
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 296, "lazy_grad_sum": false}
backward
2 1
596 gradient
596 output
587
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 403, "lazy_grad_sum": false}
backward
4 3
589 gradient
577 input
754 input
761 input
577
754
761
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 295, "lazy_grad_sum": false}
backward
4 3
588 gradient
578 input
45 input
49 input
578
45
49
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 401, "lazy_grad_sum": false}
backward
3 2
587 gradient
588 input
557 input
588
557
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 402, "lazy_grad_sum": false}
backward
2 1
672 gradient
672 output
595
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 86, "lazy_grad_sum": false}
backward
4 3
595 gradient
584 input
150 input
154 input
584
150
154
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 85, "lazy_grad_sum": false}
backward
3 2
773 gradient
775 input
857 input
775
857
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 304, "lazy_grad_sum": false}
backward
3 2
718 gradient
720 input
318 input
720
318
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 94, "lazy_grad_sum": false}
backward
2 1
684 gradient
684 output
679
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 406, "lazy_grad_sum": false}
backward
2 1
768 gradient
768 output
765
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 299, "lazy_grad_sum": false}
backward
4 3
679 gradient
591 input
199 input
201 input
591
199
201
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 405, "lazy_grad_sum": false}
backward
3 2
593 gradient
592 input
851 input
592
851
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 297, "lazy_grad_sum": false}
backward
3 2
767 gradient
768 input
854 input
768
854
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 300, "lazy_grad_sum": false}
backward
4 3
765 gradient
593 input
852 input
853 input
593
852
853
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 298, "lazy_grad_sum": false}
backward
4 3
691 gradient
673 input
307 input
309 input
673
307
309
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 88, "lazy_grad_sum": false}
backward
3 2
673 gradient
672 input
305 input
672
305
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 87, "lazy_grad_sum": false}
backward
3 2
731 gradient
739 input
224 input
739
224
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 414, "lazy_grad_sum": false}
backward
3 2
694 gradient
695 input
311 input
695
311
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 90, "lazy_grad_sum": false}
backward
2 1
632 gradient
632 output
630
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 156, "lazy_grad_sum": false}
backward
3 2
644 gradient
646 input
270 input
646
270
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 164, "lazy_grad_sum": false}
backward
2 1
639 gradient
639 output
636
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 159, "lazy_grad_sum": false}
backward
3 2
633 gradient
632 input
78 input
632
78
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 157, "lazy_grad_sum": false}
backward
3 2
638 gradient
639 input
93 input
639
93
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 160, "lazy_grad_sum": false}
backward
4 3
636 gradient
633 input
84 input
88 input
633
84
88
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 158, "lazy_grad_sum": false}
backward
2 1
646 gradient
646 output
642
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 163, "lazy_grad_sum": false}
backward
4 3
643 gradient
638 input
97 input
102 input
638
97
102
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 161, "lazy_grad_sum": false}
backward
3 2
642 gradient
643 input
627 input
643
627
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 162, "lazy_grad_sum": false}
backward
2 1
818 gradient
818 output
816
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 166, "lazy_grad_sum": false}
backward
4 3
816 gradient
644 input
273 input
276 input
644
273
276
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 165, "lazy_grad_sum": false}
backward
3 2
835 gradient
839 input
295 input
839
295
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 174, "lazy_grad_sum": false}
backward
3 1
605 gradient
277 input
605 output
277
MaxPooling2D
{"kh": 3, "kw": 3, "sy": 2, "sx": 2, "ph": 0, "pw": 0, "cover_all": true, "return_indices": false, "_used_cudnn": true, "_input_indexes_to_retain": [0], "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 3, "lazy_grad_sum": false}
backward
2 1
695 gradient
695 output
691
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 89, "lazy_grad_sum": false}
backward
2 1
716 gradient
716 output
697
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 223, "lazy_grad_sum": false}
backward
2 1
712 gradient
712 output
702
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 409, "lazy_grad_sum": false}
backward
3 2
687 gradient
684 input
204 input
684
204
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 407, "lazy_grad_sum": false}
backward
2 1
714 gradient
714 output
700
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 343, "lazy_grad_sum": false}
backward
4 3
701 gradient
685 input
354 input
359 input
685
354
359
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 341, "lazy_grad_sum": false}
backward
4 3
703 gradient
682 input
886 input
891 input
682
886
891
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 221, "lazy_grad_sum": false}
backward
3 2
711 gradient
712 input
216 input
712
216
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 410, "lazy_grad_sum": false}
backward
3 2
700 gradient
701 input
531 input
701
531
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 342, "lazy_grad_sum": false}
backward
3 2
697 gradient
703 input
440 input
703
440
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 222, "lazy_grad_sum": false}
backward
4 3
702 gradient
687 input
208 input
211 input
687
208
211
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 408, "lazy_grad_sum": false}
backward
2 1
720 gradient
720 output
707
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 93, "lazy_grad_sum": false}
backward
4 3
713 gradient
694 input
314 input
315 input
694
314
315
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 91, "lazy_grad_sum": false}
backward
3 1
46 gradient
218 input
46 output
218
AveragePooling2D
{"kh": 7, "kw": 7, "sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "return_indices": false, "_used_cudnn": true, "_input_indexes_to_retain": [0], "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 504, "lazy_grad_sum": false}
backward
3 2
707 gradient
713 input
586 input
713
586
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 92, "lazy_grad_sum": false}
backward
2 1
730 gradient
730 output
723
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 479, "lazy_grad_sum": false}
backward
2 1
732 gradient
732 output
726
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 226, "lazy_grad_sum": false}
backward
3 2
708 gradient
704 input
970 input
704
970
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 477, "lazy_grad_sum": false}
backward
2 1
733 gradient
733 output
725
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 346, "lazy_grad_sum": false}
backward
4 3
726 gradient
705 input
902 input
907 input
705
902
907
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 225, "lazy_grad_sum": false}
backward
2 1
739 gradient
739 output
722
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 413, "lazy_grad_sum": false}
backward
4 3
725 gradient
709 input
370 input
376 input
709
370
376
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 345, "lazy_grad_sum": false}
backward
3 2
728 gradient
730 input
979 input
730
979
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 480, "lazy_grad_sum": false}
backward
4 3
724 gradient
711 input
219 input
221 input
711
219
221
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 411, "lazy_grad_sum": false}
backward
4 3
723 gradient
708 input
972 input
974 input
708
972
974
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 478, "lazy_grad_sum": false}
backward
3 2
722 gradient
724 input
596 input
724
596
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 412, "lazy_grad_sum": false}
backward
2 1
740 gradient
740 output
736
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 96, "lazy_grad_sum": false}
backward
4 3
736 gradient
718 input
320 input
322 input
718
320
322
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 95, "lazy_grad_sum": false}
backward
3 2
866 gradient
877 input
469 input
877
469
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 354, "lazy_grad_sum": false}
backward
3 2
813 gradient
821 input
65 input
821
65
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 234, "lazy_grad_sum": false}
backward
3 2
873 gradient
883 input
468 input
883
468
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 104, "lazy_grad_sum": false}
backward
4 3
762 gradient
742 input
171 input
172 input
742
171
172
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 475, "lazy_grad_sum": false}
backward
2 1
751 gradient
751 output
746
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 416, "lazy_grad_sum": false}
backward
2 1
758 gradient
758 output
748
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 229, "lazy_grad_sum": false}
backward
2 1
756 gradient
756 output
747
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 349, "lazy_grad_sum": false}
backward
3 2
735 gradient
732 input
912 input
732
912
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 227, "lazy_grad_sum": false}
backward
4 3
744 gradient
728 input
982 input
984 input
728
982
984
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 481, "lazy_grad_sum": false}
backward
4 3
746 gradient
731 input
226 input
228 input
731
226
228
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 415, "lazy_grad_sum": false}
backward
3 2
734 gradient
733 input
380 input
733
380
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 347, "lazy_grad_sum": false}
backward
3 2
742 gradient
690 input
170 input
690
170
Convolution2DFunction
{"sy": 2, "sx": 2, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 474, "lazy_grad_sum": false}
backward
3 2
752 gradient
756 input
458 input
756
458
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 350, "lazy_grad_sum": false}
backward
3 2
757 gradient
758 input
52 input
758
52
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 230, "lazy_grad_sum": false}
backward
4 3
747 gradient
734 input
386 input
393 input
734
386
393
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 348, "lazy_grad_sum": false}
backward
2 1
863 gradient
863 output
759
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 99, "lazy_grad_sum": false}
backward
4 3
748 gradient
735 input
918 input
925 input
735
918
925
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 228, "lazy_grad_sum": false}
backward
3 2
741 gradient
740 input
324 input
740
324
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 97, "lazy_grad_sum": false}
backward
3 2
936 gradient
938 input
364 input
938
364
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 424, "lazy_grad_sum": false}
backward
3 2
753 gradient
863 input
459 input
863
459
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 100, "lazy_grad_sum": false}
backward
3 2
13 gradient
744 input
762 input
744
762
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 482, "lazy_grad_sum": false}
backward
4 3
759 gradient
741 input
326 input
329 input
741
326
329
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 98, "lazy_grad_sum": false}
backward
2 1
22 gradient
22 output
20
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 486, "lazy_grad_sum": false}
backward
4 3
20 gradient
749 input
178 input
180 input
749
178
180
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 485, "lazy_grad_sum": false}
backward
2 1
821 gradient
821 output
814
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 233, "lazy_grad_sum": false}
backward
2 1
931 gradient
931 output
928
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 419, "lazy_grad_sum": false}
backward
3 2
755 gradient
751 input
331 input
751
331
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 417, "lazy_grad_sum": false}
backward
2 1
877 gradient
877 output
868
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 353, "lazy_grad_sum": false}
backward
4 3
869 gradient
752 input
461 input
465 input
752
461
465
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 351, "lazy_grad_sum": false}
backward
4 3
815 gradient
757 input
56 input
62 input
757
56
62
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 231, "lazy_grad_sum": false}
backward
3 2
930 gradient
931 input
347 input
931
347
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 420, "lazy_grad_sum": false}
backward
3 2
868 gradient
869 input
714 input
869
714
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 352, "lazy_grad_sum": false}
backward
3 2
814 gradient
815 input
716 input
815
716
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 232, "lazy_grad_sum": false}
backward
4 3
928 gradient
755 input
337 input
344 input
755
337
344
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 418, "lazy_grad_sum": false}
backward
4 3
893 gradient
873 input
471 input
475 input
873
471
475
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 105, "lazy_grad_sum": false}
backward
4 3
875 gradient
753 input
462 input
464 input
753
462
464
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 101, "lazy_grad_sum": false}
backward
2 1
15 gradient
15 output
13
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 483, "lazy_grad_sum": false}
backward
4 3
823 gradient
813 input
72 input
75 input
813
72
75
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 235, "lazy_grad_sum": false}
backward
4 3
884 gradient
866 input
472 input
474 input
866
472
474
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 355, "lazy_grad_sum": false}
backward
3 2
874 gradient
875 input
720 input
875
720
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 102, "lazy_grad_sum": false}
backward
3 2
749 gradient
15 input
176 input
15
176
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 484, "lazy_grad_sum": false}
backward
3 2
772 gradient
766 input
769 input
766
769
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 12, "lazy_grad_sum": false}
backward
2 1
775 gradient
775 output
770
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 303, "lazy_grad_sum": false}
backward
4 3
771 gradient
767 input
855 input
856 input
767
855
856
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 301, "lazy_grad_sum": false}
backward
2 1
778 gradient
778 output
776
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 16, "lazy_grad_sum": false}
backward
3 2
770 gradient
771 input
583 input
771
583
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 302, "lazy_grad_sum": false}
backward
2 1
774 gradient
774 output
772
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 13, "lazy_grad_sum": false}
backward
3 2
763 gradient
774 input
976 input
774
976
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 14, "lazy_grad_sum": false}
backward
2 1
780 gradient
780 output
777
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 306, "lazy_grad_sum": false}
backward
4 3
777 gradient
773 input
858 input
859 input
773
858
859
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 305, "lazy_grad_sum": false}
backward
4 3
776 gradient
763 input
313 input
316 input
763
313
316
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 15, "lazy_grad_sum": false}
backward
3 2
51 gradient
58 input
460 input
58
460
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 24, "lazy_grad_sum": false}
backward
3 2
333 gradient
346 input
3 input
346
3
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 314, "lazy_grad_sum": false}
backward
2 1
785 gradient
785 output
782
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 19, "lazy_grad_sum": false}
backward
3 2
779 gradient
778 input
317 input
778
317
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 17, "lazy_grad_sum": false}
backward
2 1
787 gradient
787 output
783
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 309, "lazy_grad_sum": false}
backward
3 2
784 gradient
785 input
323 input
785
323
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 20, "lazy_grad_sum": false}
backward
3 2
781 gradient
780 input
860 input
780
860
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 307, "lazy_grad_sum": false}
backward
4 3
782 gradient
779 input
319 input
321 input
779
319
321
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 18, "lazy_grad_sum": false}
backward
3 2
786 gradient
787 input
0 input
787
0
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 310, "lazy_grad_sum": false}
backward
4 3
783 gradient
781 input
861 input
862 input
781
861
862
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 308, "lazy_grad_sum": false}
backward
2 1
58 gradient
58 output
50
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 23, "lazy_grad_sum": false}
backward
4 3
54 gradient
784 input
325 input
328 input
784
325
328
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 21, "lazy_grad_sum": false}
backward
2 1
346 gradient
346 output
334
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 313, "lazy_grad_sum": false}
backward
3 2
50 gradient
54 input
774 input
54
774
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 22, "lazy_grad_sum": false}
backward
4 3
335 gradient
786 input
1 input
2 input
786
1
2
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 311, "lazy_grad_sum": false}
backward
3 2
334 gradient
335 input
775 input
335
775
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 312, "lazy_grad_sum": false}
backward
2 1
69 gradient
69 output
64
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 26, "lazy_grad_sum": false}
backward
4 3
64 gradient
51 input
463 input
466 input
51
463
466
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 25, "lazy_grad_sum": false}
backward
4 3
352 gradient
333 input
4 input
5 input
333
4
5
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 315, "lazy_grad_sum": false}
backward
2 1
829 gradient
829 output
824
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 169, "lazy_grad_sum": false}
backward
2 1
826 gradient
826 output
823
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 236, "lazy_grad_sum": false}
backward
3 2
819 gradient
818 input
278 input
818
278
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 167, "lazy_grad_sum": false}
backward
3 2
827 gradient
829 input
286 input
829
286
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 170, "lazy_grad_sum": false}
backward
4 3
824 gradient
819 input
282 input
285 input
819
282
285
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 168, "lazy_grad_sum": false}
backward
3 2
846 gradient
850 input
232 input
850
232
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 244, "lazy_grad_sum": false}
backward
2 1
838 gradient
838 output
834
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 239, "lazy_grad_sum": false}
backward
2 1
839 gradient
839 output
832
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 173, "lazy_grad_sum": false}
backward
3 2
828 gradient
826 input
77 input
826
77
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 237, "lazy_grad_sum": false}
backward
4 3
833 gradient
827 input
289 input
293 input
827
289
293
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 171, "lazy_grad_sum": false}
backward
3 2
837 gradient
838 input
92 input
838
92
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 240, "lazy_grad_sum": false}
backward
3 2
832 gradient
833 input
646 input
833
646
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 172, "lazy_grad_sum": false}
backward
4 3
834 gradient
828 input
83 input
87 input
828
83
87
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 238, "lazy_grad_sum": false}
backward
2 1
847 gradient
847 output
844
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 176, "lazy_grad_sum": false}
backward
2 1
850 gradient
850 output
842
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 243, "lazy_grad_sum": false}
backward
4 3
844 gradient
835 input
299 input
303 input
835
299
303
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 175, "lazy_grad_sum": false}
backward
4 3
843 gradient
837 input
96 input
101 input
837
96
101
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 241, "lazy_grad_sum": false}
backward
3 2
842 gradient
843 input
821 input
843
821
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 242, "lazy_grad_sum": false}
backward
3 2
71 gradient
74 input
415 input
74
415
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 184, "lazy_grad_sum": false}
backward
2 1
17 gradient
17 output
14
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 246, "lazy_grad_sum": false}
backward
2 1
60 gradient
60 output
55
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 179, "lazy_grad_sum": false}
backward
4 3
14 gradient
846 input
235 input
239 input
846
235
239
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 245, "lazy_grad_sum": false}
backward
3 2
848 gradient
847 input
396 input
847
396
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 177, "lazy_grad_sum": false}
backward
3 2
59 gradient
60 input
405 input
60
405
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 180, "lazy_grad_sum": false}
backward
4 3
55 gradient
848 input
399 input
402 input
848
399
402
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 178, "lazy_grad_sum": false}
backward
3 2
36 gradient
38 input
260 input
38
260
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 254, "lazy_grad_sum": false}
backward
2 1
883 gradient
883 output
874
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 103, "lazy_grad_sum": false}
backward
2 1
888 gradient
888 output
884
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 356, "lazy_grad_sum": false}
backward
2 1
894 gradient
894 output
893
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 106, "lazy_grad_sum": false}
backward
3 2
917 gradient
924 input
649 input
924
649
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 364, "lazy_grad_sum": false}
backward
4 3
110 gradient
921 input
611 input
612 input
921
611
612
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 115, "lazy_grad_sum": false}
backward
2 1
904 gradient
904 output
899
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 359, "lazy_grad_sum": false}
backward
3 2
889 gradient
888 input
478 input
888
478
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 357, "lazy_grad_sum": false}
backward
2 1
115 gradient
115 output
110
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 116, "lazy_grad_sum": false}
backward
3 2
901 gradient
904 input
485 input
904
485
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 360, "lazy_grad_sum": false}
backward
4 3
899 gradient
889 input
481 input
483 input
889
481
483
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 358, "lazy_grad_sum": false}
backward
2 1
910 gradient
910 output
905
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 109, "lazy_grad_sum": false}
backward
3 2
895 gradient
894 input
477 input
894
477
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 107, "lazy_grad_sum": false}
backward
3 2
909 gradient
910 input
486 input
910
486
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 110, "lazy_grad_sum": false}
backward
4 3
905 gradient
895 input
480 input
484 input
895
480
484
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 108, "lazy_grad_sum": false}
backward
2 1
924 gradient
924 output
914
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 363, "lazy_grad_sum": false}
backward
4 3
915 gradient
901 input
488 input
491 input
901
488
491
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 361, "lazy_grad_sum": false}
backward
3 2
914 gradient
915 input
877 input
915
877
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 362, "lazy_grad_sum": false}
backward
2 1
104 gradient
104 output
920
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 113, "lazy_grad_sum": false}
backward
4 3
922 gradient
909 input
489 input
492 input
909
489
492
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 111, "lazy_grad_sum": false}
backward
3 2
920 gradient
922 input
883 input
922
883
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 112, "lazy_grad_sum": false}
backward
2 1
109 gradient
109 output
108
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 366, "lazy_grad_sum": false}
backward
4 3
108 gradient
917 input
651 input
653 input
917
651
653
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 365, "lazy_grad_sum": false}
backward
3 2
136 gradient
141 input
667 input
141
667
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 374, "lazy_grad_sum": false}
backward
2 1
938 gradient
938 output
934
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 423, "lazy_grad_sum": false}
backward
4 3
935 gradient
930 input
353 input
358 input
930
353
358
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 421, "lazy_grad_sum": false}
backward
3 2
934 gradient
935 input
739 input
935
739
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 422, "lazy_grad_sum": false}
backward
2 1
943 gradient
943 output
941
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 426, "lazy_grad_sum": false}
backward
4 3
941 gradient
936 input
368 input
375 input
936
368
375
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 425, "lazy_grad_sum": false}
backward
3 2
103 gradient
113 input
560 input
113
560
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 434, "lazy_grad_sum": false}
backward
2 1
950 gradient
950 output
947
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 429, "lazy_grad_sum": false}
backward
3 2
944 gradient
943 input
379 input
943
379
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 427, "lazy_grad_sum": false}
backward
3 2
949 gradient
950 input
546 input
950
546
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 430, "lazy_grad_sum": false}
backward
4 3
947 gradient
944 input
385 input
392 input
944
385
392
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 428, "lazy_grad_sum": false}
backward
2 1
113 gradient
113 output
105
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 433, "lazy_grad_sum": false}
backward
4 3
107 gradient
949 input
552 input
555 input
949
552
555
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 431, "lazy_grad_sum": false}
backward
3 2
105 gradient
107 input
938 input
107
938
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 432, "lazy_grad_sum": false}
backward
4 3
118 gradient
103 input
564 input
569 input
103
564
569
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 435, "lazy_grad_sum": false}
backward
4 3
958 gradient
955 input
626 input
628 input
955
626
628
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 38, "lazy_grad_sum": false}
backward
3 2
960 gradient
962 input
629 input
962
629
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 40, "lazy_grad_sum": false}
backward
2 1
962 gradient
962 output
958
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 39, "lazy_grad_sum": false}
backward
4 3
973 gradient
967 input
637 input
640 input
967
637
640
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 35, "lazy_grad_sum": false}
backward
4 3
969 gradient
960 input
631 input
634 input
960
631
634
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 41, "lazy_grad_sum": false}
backward
3 2
967 gradient
98 input
635 input
98
635
Convolution2DFunction
{"sy": 2, "sx": 2, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 34, "lazy_grad_sum": false}
backward
3 2
977 gradient
969 input
973 input
969
973
Add
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": null, "_output_count": 1, "rank": 42, "lazy_grad_sum": false}
backward
2 1
168 gradient
168 output
983
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 46, "lazy_grad_sum": false}
backward
2 1
980 gradient
980 output
977
ReLU
{"_input_indexes_to_retain": null, "_output_indexes_to_retain": [0], "_output_count": 1, "rank": 43, "lazy_grad_sum": false}
backward
3 2
965 gradient
980 input
641 input
980
641
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 44, "lazy_grad_sum": false}
backward
4 3
983 gradient
965 input
645 input
647 input
965
645
647
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 45, "lazy_grad_sum": false}
backward
3 2
181 gradient
183 input
801 input
183
801
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 54, "lazy_grad_sum": false}
backward
4 3
173 gradient
169 input
790 input
792 input
169
790
792
BatchNormalization
{"eps": 2e-05, "decay": 0.9, "axis": [0, 2, 3], "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "key_axis": [1], "use_cudnn": true, "use_ideep": false, "_output_count": 1, "rank": 48, "lazy_grad_sum": false}
backward
3 2
169 gradient
168 input
788 input
168
788
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 1, "pw": 1, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 47, "lazy_grad_sum": false}
backward
3 2
174 gradient
175 input
794 input
175
794
Convolution2DFunction
{"sy": 1, "sx": 1, "ph": 0, "pw": 0, "cover_all": false, "dy": 1, "dx": 1, "groups": 1, "_input_indexes_to_retain": [0, 1], "_output_indexes_to_retain": null, "_output_count": 1, "rank": 50, "lazy_grad_sum": false}
